import os
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import matplotlib.pyplot as plt
import re
from scipy.optimize import minimize
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
import warnings

# –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Å—Ç–∞–Ω—Ç
from tree_solver_constants import (
    FINANCIAL,
    VALUATION_SCORES,
    RETURN_PREMIUMS,
    RISK_PREMIUMS,
    MODEL_CONSTANTS,
    TARGET_MAPPING,
    PORTFOLIO_CONSTANTS,
    FILE_CONSTANTS,
    SECTOR_KEYWORDS,
    SECTOR_NAMES,
    FORMATTING,
    CONVERSION,
    REPORT,
)

warnings.filterwarnings("ignore")

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ü–£–¢–ï–ô ====================


class PathConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º"""

    @staticmethod
    def setup_directories():
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        tree_solver_dir = f"{parent_dir}/../data/tree_solver"
        os.makedirs(tree_solver_dir, exist_ok=True)

        return {
            "parent_dir": parent_dir,
            "tree_solver_dir": tree_solver_dir,
            "file_path": f"{parent_dir}/../data/fundamentals_shares.xlsx",
            "decision_tree": f"{tree_solver_dir}/{FILE_CONSTANTS.DECISION_TREE_FILE}",
            "efficient_frontier": f"{tree_solver_dir}/{FILE_CONSTANTS.EFFICIENT_FRONTIER_FILE}",
            "portfolio_report": f"{tree_solver_dir}/{FILE_CONSTANTS.INVEST_PORTFOLIO_REPORT}",
            "optimal_portfolio": f"{tree_solver_dir}/{FILE_CONSTANTS.OPTIMAL_PORTFOLIO_FILE}",
        }


PATHS = PathConfig.setup_directories()

# ==================== –ö–õ–ê–°–°–´ –î–ê–ù–ù–´–• ====================


@dataclass
class MarketBenchmarks:
    """–†—ã–Ω–æ—á–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ–¥–∏–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""

    pe_median: float
    pb_median: float
    ps_median: float
    roe_median: float
    div_yield_median: float
    debt_capital_median: float
    beta_median: float


@dataclass
class PortfolioMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""

    expected_return: float
    risk: float
    sharpe_ratio: float
    diversification_score: float


# ==================== –ö–õ–ê–°–° –ó–ê–ì–†–£–ó–ß–ò–ö–ê –î–ê–ù–ù–´–• ====================


class DataLoader:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""

    @staticmethod
    def convert_to_float(value):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç—Ä–æ–∫ —Å —á–∏—Å–ª–∞–º–∏ –≤ float"""
        if pd.isna(value) or value == "" or value == 0:
            return np.nan
        if isinstance(value, (int, float)):
            return value

        value = str(value).strip()
        value = value.replace(CONVERSION.THOUSAND_SEPARATOR, "").replace(
            CONVERSION.DECIMAL_SEPARATOR, "."
        )

        if CONVERSION.BILLION_PATTERN in value:
            return float(re.sub(r"[^\d.]", "", value)) * CONVERSION.BILLION
        elif CONVERSION.MILLION_PATTERN in value:
            return float(re.sub(r"[^\d.]", "", value)) * CONVERSION.MILLION
        else:
            try:
                return float(re.sub(r"[^\d.-]", "", value))
            except:
                return np.nan

    @staticmethod
    def load_and_clean_data(filepath: str) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        df = pd.read_excel(filepath, sheet_name="Sheet1")

        numeric_columns = [
            "–†—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è",
            "EV",
            "–í—ã—Ä—É—á–∫–∞",
            "–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å",
            "EBITDA",
            "P/E",
            "P/B",
            "P/S",
            "P/FCF",
            "ROE",
            "ROA",
            "ROIC",
            "EV/EBITDA",
            "EV/S",
            "Payot Ratio",
            "NPM",
            "Debt",
            "Debt/Capital",
            "Net_Debt/EBITDA",
            "Debt/EBITDA",
            "EPS",
            "Averange_dividend_yield",
            "–°–≤–æ–±–æ–¥–Ω—ã–π –¥–µ–Ω–µ–∂–Ω—ã–π –ø–æ—Ç–æ–∫",
            "–ë–µ—Ç–∞",
            "–î–∏–≤–∏–¥–µ–Ω–¥ –Ω–∞ –∞–∫—Ü–∏—é",
        ]

        for col in numeric_columns:
            if col in df.columns:
                df[col] = df[col].apply(DataLoader.convert_to_float)

        return df


# ==================== –ö–õ–ê–°–° –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê –†–´–ù–ö–ê ====================


class MarketAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤"""

    @staticmethod
    def calculate_benchmarks(df: pd.DataFrame) -> MarketBenchmarks:
        """–†–∞—Å—á–µ—Ç –º–µ–¥–∏–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        return MarketBenchmarks(
            pe_median=df["P/E"].median(),
            pb_median=df["P/B"].median(),
            ps_median=df["P/S"].median(),
            roe_median=df["ROE"].median(),
            div_yield_median=df["Averange_dividend_yield"].median(),
            debt_capital_median=df["Debt/Capital"].median(),
            beta_median=df["–ë–µ—Ç–∞"].median(),
        )

    @staticmethod
    def assign_sector(name: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ç–æ—Ä–∞ –∫–æ–º–ø–∞–Ω–∏–∏"""
        name = str(name).lower()

        sector_mappings = [
            (SECTOR_KEYWORDS.BANKS, SECTOR_NAMES.BANKS),
            (SECTOR_KEYWORDS.OIL_GAS, SECTOR_NAMES.OIL_GAS),
            (SECTOR_KEYWORDS.METALS, SECTOR_NAMES.METALS),
            (SECTOR_KEYWORDS.ENERGY, SECTOR_NAMES.ENERGY),
            (SECTOR_KEYWORDS.TELECOM, SECTOR_NAMES.TELECOM),
            (SECTOR_KEYWORDS.RETAIL, SECTOR_NAMES.RETAIL),
            (SECTOR_KEYWORDS.CHEMICAL, SECTOR_NAMES.CHEMICAL),
            (SECTOR_KEYWORDS.IT, SECTOR_NAMES.IT),
        ]

        for keywords, sector_name in sector_mappings:
            if any(word in name for word in keywords):
                return sector_name

        return SECTOR_NAMES.OTHER

    @staticmethod
    def calculate_relative_valuation(
        row: pd.Series, benchmarks: MarketBenchmarks
    ) -> Dict:
        """–û—Ü–µ–Ω–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ–¥–∏–∞–Ω"""
        scores = {}

        # P/E –æ—Ü–µ–Ω–∫–∞
        if pd.notna(row.get("P/E")):
            pe_ratio = row["P/E"]
            if (
                pe_ratio
                < benchmarks.pe_median * FINANCIAL.STRONGLY_UNDERVALUED_THRESHOLD
                and pe_ratio > 0
            ):
                scores["pe_score"] = VALUATION_SCORES.STRONG_BUY
            elif (
                pe_ratio < benchmarks.pe_median * FINANCIAL.UNDERVALUED_THRESHOLD
                and pe_ratio > 0
            ):
                scores["pe_score"] = VALUATION_SCORES.BUY
            elif (
                pe_ratio > benchmarks.pe_median * FINANCIAL.OVERVALUED_THRESHOLD
                or pe_ratio < 0
            ):
                scores["pe_score"] = VALUATION_SCORES.SELL
            else:
                scores["pe_score"] = VALUATION_SCORES.HOLD
        else:
            scores["pe_score"] = VALUATION_SCORES.HOLD

        # P/S –æ—Ü–µ–Ω–∫–∞
        if pd.notna(row.get("P/S")):
            ps_ratio = row["P/S"]
            if (
                ps_ratio
                < benchmarks.ps_median * FINANCIAL.STRONGLY_UNDERVALUED_THRESHOLD
            ):
                scores["ps_score"] = VALUATION_SCORES.STRONG_BUY
            elif ps_ratio < benchmarks.ps_median * FINANCIAL.UNDERVALUED_THRESHOLD:
                scores["ps_score"] = VALUATION_SCORES.BUY
            elif ps_ratio > benchmarks.ps_median * FINANCIAL.OVERVALUED_THRESHOLD:
                scores["ps_score"] = VALUATION_SCORES.SELL
            else:
                scores["ps_score"] = VALUATION_SCORES.HOLD
        else:
            scores["ps_score"] = VALUATION_SCORES.HOLD

        # P/B –æ—Ü–µ–Ω–∫–∞
        if pd.notna(row.get("P/B")) and pd.notna(row.get("ROE")):
            pb_ratio = row["P/B"]
            if (
                pb_ratio < benchmarks.pb_median * FINANCIAL.PB_STRONG_THRESHOLD
                and row["ROE"] > 0
            ):
                scores["pb_score"] = VALUATION_SCORES.STRONG_BUY
            elif (
                pb_ratio < benchmarks.pb_median * FINANCIAL.UNDERVALUED_THRESHOLD
                and row["ROE"] > 0
            ):
                scores["pb_score"] = VALUATION_SCORES.BUY
            elif (
                pb_ratio > benchmarks.pb_median * FINANCIAL.PB_OVERVAULED_THRESHOLD
                and row["ROE"] > 0
            ):
                scores["pb_score"] = VALUATION_SCORES.SELL
            else:
                scores["pb_score"] = VALUATION_SCORES.HOLD
        else:
            scores["pb_score"] = VALUATION_SCORES.HOLD

        # ROE –æ—Ü–µ–Ω–∫–∞
        if pd.notna(row.get("ROE")):
            roe = row["ROE"]
            if roe > benchmarks.roe_median * FINANCIAL.ROE_STRONG_THRESHOLD and roe > 0:
                scores["roe_score"] = VALUATION_SCORES.STRONG_BUY
            elif roe > benchmarks.roe_median * FINANCIAL.ROE_GOOD_THRESHOLD and roe > 0:
                scores["roe_score"] = VALUATION_SCORES.BUY
            else:
                scores["roe_score"] = VALUATION_SCORES.HOLD
        else:
            scores["roe_score"] = VALUATION_SCORES.HOLD

        # –î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        if pd.notna(row.get("–î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å")):
            div_yield = row["–î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"]
            if (
                div_yield
                > benchmarks.div_yield_median * FINANCIAL.DIVIDEND_STRONG_THRESHOLD
            ):
                scores["div_score"] = VALUATION_SCORES.STRONG_BUY
            elif (
                div_yield
                > benchmarks.div_yield_median * FINANCIAL.DIVIDEND_GOOD_THRESHOLD
            ):
                scores["div_score"] = VALUATION_SCORES.BUY
            else:
                scores["div_score"] = VALUATION_SCORES.HOLD
        else:
            scores["div_score"] = VALUATION_SCORES.HOLD

        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        total_score = sum(scores.values())
        scores["total_score"] = total_score

        if total_score >= VALUATION_SCORES.STRONG_BUY_THRESHOLD:
            scores["valuation"] = TARGET_MAPPING.LABELS[
                TARGET_MAPPING.STRONG_UNDERVALUED
            ]
            scores["valuation_code"] = TARGET_MAPPING.STRONG_UNDERVALUED
        elif total_score >= VALUATION_SCORES.BUY_THRESHOLD:
            scores["valuation"] = TARGET_MAPPING.LABELS[TARGET_MAPPING.UNDERVALUED]
            scores["valuation_code"] = TARGET_MAPPING.UNDERVALUED
        elif total_score <= VALUATION_SCORES.SELL_THRESHOLD:
            scores["valuation"] = TARGET_MAPPING.LABELS[TARGET_MAPPING.OVERVALUED]
            scores["valuation_code"] = TARGET_MAPPING.OVERVALUED
        else:
            scores["valuation"] = TARGET_MAPPING.LABELS[TARGET_MAPPING.FAIR_VALUE]
            scores["valuation_code"] = TARGET_MAPPING.FAIR_VALUE

        return scores


# ==================== –ö–õ–ê–°–° –ú–û–î–ï–õ–ò –î–ï–†–ï–í–ê –†–ï–®–ï–ù–ò–ô ====================


class DecisionTreeModel:
    """–ú–æ–¥–µ–ª—å –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞–∫—Ü–∏–π"""

    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.feature_columns = [
            "P/E",
            "P/B",
            "P/S",
            "P/FCF",
            "ROE",
            "ROA",
            "Averange_dividend_yield",
            "–ë–µ—Ç–∞",
            "Debt/Capital",
            "NPM",
            "–°–µ–∫—Ç–æ—Ä_encoded",
        ]

    def prepare_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        df = df.copy()
        df["–°–µ–∫—Ç–æ—Ä"] = df["–ù–∞–∑–≤–∞–Ω–∏–µ"].apply(MarketAnalyzer.assign_sector)
        df["–°–µ–∫—Ç–æ—Ä_encoded"] = self.label_encoder.fit_transform(df["–°–µ–∫—Ç–æ—Ä"])
        return df

    def train(self, df: pd.DataFrame):
        """–û–±—É—á–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π"""
        df = self.prepare_features(df)
        df["–û—Ü–µ–Ω–∫–∞"] = df.apply(self._assign_target, axis=1)
        df_model = df[df["–û—Ü–µ–Ω–∫–∞"].notna()].copy()

        X = df_model[self.feature_columns].copy()
        y = df_model["–û—Ü–µ–Ω–∫–∞"]

        for col in X.columns:
            X[col] = X[col].fillna(X[col].median())

        X_scaled = self.scaler.fit_transform(X)

        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled,
            y,
            test_size=MODEL_CONSTANTS.TEST_SIZE,
            random_state=MODEL_CONSTANTS.RANDOM_STATE,
            stratify=y,
        )

        self.model = DecisionTreeClassifier(
            max_depth=MODEL_CONSTANTS.MAX_DEPTH,
            min_samples_split=MODEL_CONSTANTS.MIN_SAMPLES_SPLIT,
            min_samples_leaf=MODEL_CONSTANTS.MIN_SAMPLES_LEAF,
            random_state=MODEL_CONSTANTS.RANDOM_STATE,
        )

        self.model.fit(X_train, y_train)

        return {
            "train_accuracy": self.model.score(X_train, y_train),
            "test_accuracy": self.model.score(X_test, y_test),
            "feature_importance": dict(
                zip(self.feature_columns, self.model.feature_importances_)
            ),
        }

    def predict(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö –∞–∫—Ü–∏–π"""
        df = df.copy()
        df["–°–µ–∫—Ç–æ—Ä"] = df["–ù–∞–∑–≤–∞–Ω–∏–µ"].apply(MarketAnalyzer.assign_sector)
        df["–°–µ–∫—Ç–æ—Ä_encoded"] = self.label_encoder.transform(df["–°–µ–∫—Ç–æ—Ä"])

        X = df[self.feature_columns].copy()
        for col in X.columns:
            X[col] = X[col].fillna(X[col].median())

        X_scaled = self.scaler.transform(X)

        df["Predicted_–û—Ü–µ–Ω–∫–∞"] = self.model.predict(X_scaled)
        df["Predicted_–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"] = np.max(self.model.predict_proba(X_scaled), axis=1)
        df["Predicted_–û—Ü–µ–Ω–∫–∞_—Ç–µ–∫—Å—Ç"] = df["Predicted_–û—Ü–µ–Ω–∫–∞"].map(TARGET_MAPPING.LABELS)

        return df

    @staticmethod
    def _assign_target(row):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        if (
            pd.notna(row.get("P/E", np.nan))
            and pd.notna(row.get("P/B", np.nan))
            and pd.notna(row.get("ROE", np.nan))
        ):

            pe = row["P/E"]
            pb = row["P/B"]
            roe = row["ROE"]

            if (
                pe < MODEL_CONSTANTS.PE_STRONG_BUY_THRESHOLD
                and pb < MODEL_CONSTANTS.PB_STRONG_BUY_THRESHOLD
                and pe > 0
                and roe > 0
            ):
                return TARGET_MAPPING.STRONG_UNDERVALUED
            elif (
                pe < MODEL_CONSTANTS.PE_BUY_THRESHOLD
                and pb < MODEL_CONSTANTS.PB_BUY_THRESHOLD
                and roe > 0
            ):
                return TARGET_MAPPING.UNDERVALUED
            elif (
                pe > MODEL_CONSTANTS.PE_SELL_THRESHOLD
                or pb > MODEL_CONSTANTS.PB_SELL_THRESHOLD
                and roe > 0
            ):
                return TARGET_MAPPING.OVERVALUED
            else:
                return TARGET_MAPPING.FAIR_VALUE
        return np.nan

    def plot_tree(self, filename: str = None):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π"""
        if filename is None:
            filename = PATHS["decision_tree"]

        plt.figure(figsize=FILE_CONSTANTS.FIGURE_SIZE_TREE)
        plot_tree(
            self.model,
            feature_names=self.feature_columns,
            class_names=list(TARGET_MAPPING.LABELS.values()),
            filled=True,
            rounded=True,
            fontsize=FORMATTING.TREE_FONT_SIZE,
        )
        plt.title(
            "–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞–∫—Ü–∏–π", fontsize=FORMATTING.TITLE_FONT_SIZE
        )
        plt.tight_layout()
        plt.savefig(filename, dpi=FILE_CONSTANTS.DPI, bbox_inches="tight")
        plt.show()


# ==================== –ö–õ–ê–°–° –§–£–ù–î–ê–ú–ï–ù–¢–ê–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê ====================


class FundamentalAnalyzer:
    """–§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Ä–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏/—Ä–∏—Å–∫–∞"""

    def __init__(self, benchmarks: MarketBenchmarks):
        self.benchmarks = benchmarks

    def calculate_expected_return(self, row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π"""
        base_return = FINANCIAL.BASE_RETURN
        score = 0.0

        # P/E –ø—Ä–µ–º–∏—è
        if pd.notna(row.get("P/E")):
            pe = row["P/E"]
            if (
                pe
                < self.benchmarks.pe_median * FINANCIAL.STRONGLY_UNDERVALUED_THRESHOLD
                and pe > 0
            ):
                score += RETURN_PREMIUMS.STRONG_PE_PREMIUM
            elif (
                pe < self.benchmarks.pe_median * FINANCIAL.UNDERVALUED_THRESHOLD
                and pe > 0
            ):
                score += RETURN_PREMIUMS.PE_PREMIUM

        # P/S –ø—Ä–µ–º–∏—è
        if pd.notna(row.get("P/S")):
            ps = row["P/S"]
            if (
                ps
                < self.benchmarks.ps_median * FINANCIAL.STRONGLY_UNDERVALUED_THRESHOLD
                and ps > 0
            ):
                score += RETURN_PREMIUMS.STRONG_PS_PREMIUM
            elif (
                ps < self.benchmarks.ps_median * FINANCIAL.UNDERVALUED_THRESHOLD
                and ps > 0
            ):
                score += RETURN_PREMIUMS.PS_PREMIUM

        # P/B –ø—Ä–µ–º–∏—è
        if pd.notna(row.get("P/B")) and pd.notna(row.get("ROE")):
            pb = row["P/B"]
            if (
                pb < self.benchmarks.pb_median * FINANCIAL.PB_STRONG_THRESHOLD
                and row["ROE"] > 0
            ):
                score += RETURN_PREMIUMS.STRONG_PB_PREMIUM
            elif (
                pb < self.benchmarks.pb_median * FINANCIAL.UNDERVALUED_THRESHOLD
                and row["ROE"] > 0
            ):
                score += RETURN_PREMIUMS.PB_PREMIUM

        # ROE –ø—Ä–µ–º–∏—è
        if pd.notna(row.get("ROE")):
            roe = row["ROE"]
            if (
                roe > self.benchmarks.roe_median * FINANCIAL.ROE_STRONG_THRESHOLD
                and roe > 0
            ):
                score += RETURN_PREMIUMS.STRONG_ROE_PREMIUM
            elif (
                roe > self.benchmarks.roe_median * FINANCIAL.ROE_GOOD_THRESHOLD
                and roe > 0
            ):
                score += RETURN_PREMIUMS.ROE_PREMIUM

        # –î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –ø—Ä–µ–º–∏—è
        if pd.notna(row.get("–î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å")):
            div_yield = row["–î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"]
            if (
                div_yield
                > self.benchmarks.div_yield_median * FINANCIAL.DIVIDEND_STRONG_THRESHOLD
            ):
                score += RETURN_PREMIUMS.STRONG_DIVIDEND_PREMIUM
            elif (
                div_yield
                > self.benchmarks.div_yield_median * FINANCIAL.DIVIDEND_GOOD_THRESHOLD
            ):
                score += RETURN_PREMIUMS.DIVIDEND_PREMIUM

        # –ë–æ–Ω—É—Å –∑–∞ –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏
        if pd.notna(row.get("Predicted_–û—Ü–µ–Ω–∫–∞")):
            if row["Predicted_–û—Ü–µ–Ω–∫–∞"] == TARGET_MAPPING.STRONG_UNDERVALUED:
                score += RETURN_PREMIUMS.MODEL_STRONG_PREMIUM
            elif row["Predicted_–û—Ü–µ–Ω–∫–∞"] == TARGET_MAPPING.UNDERVALUED:
                score += RETURN_PREMIUMS.MODEL_PREMIUM

        return base_return + score

    def calculate_risk(self, row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–µ—Ç—ã, –¥–æ–ª–≥–∞ –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏"""
        base_risk = RISK_PREMIUMS.BASE_RISK

        # –ë–µ—Ç–∞ —Ä–∏—Å–∫
        if pd.notna(row.get("–ë–µ—Ç–∞")):
            beta = row["–ë–µ—Ç–∞"]
            if beta > self.benchmarks.beta_median * FINANCIAL.BETA_HIGH_THRESHOLD:
                base_risk += RISK_PREMIUMS.BETA_HIGH_PENALTY
            elif beta > self.benchmarks.beta_median * FINANCIAL.UNDERVALUED_THRESHOLD:
                base_risk += RISK_PREMIUMS.BETA_MEDIUM_PENALTY
            elif beta < self.benchmarks.beta_median * FINANCIAL.BETA_LOW_THRESHOLD:
                base_risk += RISK_PREMIUMS.BETA_LOW_BONUS

        # –î–æ–ª–≥–æ–≤–æ–π —Ä–∏—Å–∫
        if pd.notna(row.get("Debt/Capital")):
            debt = row["Debt/Capital"]
            if (
                debt
                > self.benchmarks.debt_capital_median * FINANCIAL.DEBT_HIGH_THRESHOLD
            ):
                base_risk += RISK_PREMIUMS.DEBT_HIGH_PENALTY
            elif (
                debt
                > self.benchmarks.debt_capital_median * FINANCIAL.UNDERVALUED_THRESHOLD
            ):
                base_risk += RISK_PREMIUMS.DEBT_MEDIUM_PENALTY

        # –®—Ç—Ä–∞—Ñ –∑–∞ –ø–µ—Ä–µ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å
        if pd.notna(row.get("Predicted_–û—Ü–µ–Ω–∫–∞")):
            if row["Predicted_–û—Ü–µ–Ω–∫–∞"] == TARGET_MAPPING.OVERVALUED:
                base_risk += RISK_PREMIUMS.OVERVALUED_PENALTY

        return max(RISK_PREMIUMS.MIN_RISK, min(RISK_PREMIUMS.MAX_RISK, base_risk))


# ==================== –ö–õ–ê–°–° –û–ü–¢–ò–ú–ò–ó–ê–¢–û–†–ê –ü–û–†–¢–§–ï–õ–Ø ====================


class PortfolioOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –ø–æ –ú–∞—Ä–∫–æ–≤–∏—Ü—É"""

    def __init__(self, min_weight: float = None, max_weight: float = None):
        self.min_weight = min_weight or PORTFOLIO_CONSTANTS.MIN_WEIGHT
        self.max_weight = max_weight or PORTFOLIO_CONSTANTS.MAX_WEIGHT

    def create_covariance_matrix(self, df: pd.DataFrame) -> np.ndarray:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–∏"""
        n = len(df)
        cov_matrix = np.zeros((n, n))
        risks = df["–†–∏—Å–∫"].values

        for i in range(n):
            for j in range(n):
                if i == j:
                    cov_matrix[i, j] = risks[i] ** 2
                else:
                    correlation = (
                        PORTFOLIO_CONSTANTS.INTRASECTOR_CORRELATION
                        if df.iloc[i]["–°–µ–∫—Ç–æ—Ä"] == df.iloc[j]["–°–µ–∫—Ç–æ—Ä"]
                        else PORTFOLIO_CONSTANTS.INTERSECTOR_CORRELATION
                    )
                    cov_matrix[i, j] = correlation * risks[i] * risks[j]

        return cov_matrix

    def optimize(self, expected_returns: np.ndarray, cov_matrix: np.ndarray) -> Dict:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        n = len(expected_returns)

        def neg_sharpe(weights):
            port_return = np.sum(expected_returns * weights)
            port_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
            return -port_return / port_risk if port_risk > 0 else -np.inf

        def portfolio_risk(weights):
            return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))

        constraints = [{"type": "eq", "fun": lambda x: np.sum(x) - 1}]
        bounds = tuple((self.min_weight, self.max_weight) for _ in range(n))
        init_guess = [1 / n] * n

        # –ú–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è –®–∞—Ä–ø–∞
        result_sharpe = minimize(
            neg_sharpe,
            init_guess,
            method="SLSQP",
            bounds=bounds,
            constraints=constraints,
        )

        # –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ä–∏—Å–∫–∞
        result_min_risk = minimize(
            portfolio_risk,
            init_guess,
            method="SLSQP",
            bounds=bounds,
            constraints=constraints,
        )

        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å
        combined_weights = (
            PORTFOLIO_CONSTANTS.SHARPE_PORTFOLIO_WEIGHT * result_sharpe.x
            + PORTFOLIO_CONSTANTS.MIN_RISK_PORTFOLIO_WEIGHT * result_min_risk.x
        )
        combined_weights = combined_weights / combined_weights.sum()

        return {
            "sharpe_weights": result_sharpe.x,
            "min_risk_weights": result_min_risk.x,
            "combined_weights": combined_weights,
            "cov_matrix": cov_matrix,
        }


# ==================== –ö–õ–ê–°–° –ü–û–†–¢–§–ï–õ–¨–ù–û–ì–û –ú–ï–ù–ï–î–ñ–ï–†–ê ====================


class PortfolioManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–º –∏ —Ä–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫"""

    def __init__(self, df: pd.DataFrame, weights: np.ndarray):
        self.df = df.copy()
        self.weights = weights
        self.df["weights"] = weights
        self.metrics = self._calculate_metrics()

    def _calculate_metrics(self) -> PortfolioMetrics:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        exp_return = np.sum(self.df["–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"] * self.weights)

        optimizer = PortfolioOptimizer()
        cov_matrix = optimizer.create_covariance_matrix(self.df)

        risk = np.sqrt(np.dot(self.weights.T, np.dot(cov_matrix, self.weights)))
        sharpe = exp_return / risk if risk > 0 else 0

        # –ò–Ω–¥–µ–∫—Å –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –•–µ—Ä—Ñ–∏–Ω–¥–∞–ª—è-–•–∏—Ä—à–º–∞–Ω–∞
        hhi = np.sum(self.weights**2)
        n = len(self.weights)
        if n > 1:
            diversification = 1 - (hhi - 1 / n) / (1 - 1 / n)
        else:
            diversification = 0

        return PortfolioMetrics(
            expected_return=exp_return,
            risk=risk,
            sharpe_ratio=sharpe,
            diversification_score=diversification,
        )

    def get_sector_allocation(self) -> pd.Series:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        return self.df.groupby("–°–µ–∫—Ç–æ—Ä")["weights"].sum()

    def get_top_positions(
        self, n: int = PORTFOLIO_CONSTANTS.TOP_POSITIONS_N
    ) -> pd.DataFrame:
        """–¢–æ–ø –ø–æ–∑–∏—Ü–∏–π –ø–æ –≤–µ—Å—É"""
        n = min(n, len(self.df))
        top_idx = np.argsort(self.weights)[::-1][:n]
        return self.df.iloc[top_idx].copy()


# ==================== –ö–õ–ê–°–° –í–ò–ó–£–ê–õ–ò–ó–ê–¢–û–†–ê ====================


class PortfolioVisualizer:
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""

    @staticmethod
    def plot_portfolio_summary(
        portfolio_df: pd.DataFrame,
        weights: np.ndarray,
        metrics: PortfolioMetrics,
        benchmarks: MarketBenchmarks,
        filename: str = None,
    ):
        """–°–≤–æ–¥–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        if filename is None:
            filename = PATHS["optimal_portfolio"]

        fig, axes = plt.subplots(2, 2, figsize=FILE_CONSTANTS.FIGURE_SIZE_SUMMARY)

        plot_df = portfolio_df.copy()
        plot_df["weights"] = weights
        plot_df = plot_df.reset_index(drop=True)

        n_positions = len(plot_df)

        # 1. Pie chart - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ - –ò–°–ü–†–ê–í–õ–ï–ù–û
        top_n = min(PORTFOLIO_CONSTANTS.TOP_PIE_N, len(plot_df))
        if top_n > 0:
            top_indices = np.argsort(weights)[::-1][:top_n]
            top_weights = weights[top_indices]
            top_tickers = plot_df.iloc[top_indices]["–¢–∏–∫–µ—Ä"].values

            other_weight = max(0, 1 - top_weights.sum())
            if other_weight > PORTFOLIO_CONSTANTS.MIN_WEIGHT and len(top_weights) < len(
                weights
            ):
                plot_weights = np.append(top_weights, other_weight)
                plot_labels = np.append(top_tickers, ["–î—Ä—É–≥–∏–µ"])
            else:
                plot_weights = top_weights
                plot_labels = top_tickers
                if abs(1 - plot_weights.sum()) > 0.01:
                    plot_weights = plot_weights / plot_weights.sum()

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º MATPLOTLIB_PERCENT –¥–ª—è autopct
            axes[0, 0].pie(
                plot_weights,
                labels=plot_labels,
                autopct=FORMATTING.MATPLOTLIB_PERCENT,  # '%1.1f%%'
                startangle=90,
                colors=plt.cm.get_cmap(FORMATTING.COLOR_PIE_CMAP)(
                    range(len(plot_weights))
                ),
            )
            axes[0, 0].set_title(
                f"–¢–æ–ø-{top_n} –ø–æ–∑–∏—Ü–∏–π –≤ –ø–æ—Ä—Ç—Ñ–µ–ª–µ",
                fontsize=FORMATTING.SUBTITLE_FONT_SIZE,
                fontweight="bold",
            )

        # 2. Risk-Return scatter
        axes[0, 1].scatter(
            plot_df["–†–∏—Å–∫"],
            plot_df["–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"],
            s=weights * 3000,
            alpha=0.6,
            c=FORMATTING.COLOR_PORTFOLIO_MARKER,
            edgecolors="black",
            linewidths=0.5,
        )

        for idx, row in plot_df.iterrows():
            if (
                idx < len(weights)
                and weights[idx] > PORTFOLIO_CONSTANTS.ANNOTATION_WEIGHT_THRESHOLD
            ):
                axes[0, 1].annotate(
                    row["–¢–∏–∫–µ—Ä"],
                    (row["–†–∏—Å–∫"], row["–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"]),
                    fontsize=FORMATTING.ANNOTATION_FONT_SIZE,
                    alpha=0.8,
                    fontweight="bold",
                    xytext=(5, 5),
                    textcoords="offset points",
                )

        axes[0, 1].axhline(
            y=metrics.expected_return,
            color="r",
            linestyle="--",
            alpha=0.5,
            label=f"–ü–æ—Ä—Ç—Ñ–µ–ª—å: {metrics.expected_return:.1%}",
        )
        axes[0, 1].axvline(x=metrics.risk, color="r", linestyle="--", alpha=0.5)
        axes[0, 1].set_xlabel(
            "–†–∏—Å–∫ (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)", fontsize=FORMATTING.AXIS_FONT_SIZE
        )
        axes[0, 1].set_ylabel(
            "–û–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å", fontsize=FORMATTING.AXIS_FONT_SIZE
        )
        axes[0, 1].set_title(
            "Risk-Return –ø—Ä–æ—Ñ–∏–ª—å",
            fontsize=FORMATTING.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].legend()

        # 3. –°–µ–∫—Ç–æ—Ä–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ - –ò–°–ü–†–ê–í–õ–ï–ù–û
        if len(plot_df) > 0 and "weights" in plot_df.columns:
            sector_weights = plot_df.groupby("–°–µ–∫—Ç–æ—Ä")["weights"].sum()
            if len(sector_weights) > 0:
                sector_weights = sector_weights.sort_values(ascending=False)
                colors = plt.cm.get_cmap(FORMATTING.COLOR_SECTOR_CMAP)(
                    np.linspace(0, 1, len(sector_weights))
                )
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º MATPLOTLIB_PERCENT –¥–ª—è autopct
                axes[1, 0].pie(
                    sector_weights.values,
                    labels=sector_weights.index,
                    autopct=FORMATTING.MATPLOTLIB_PERCENT,  # '%1.1f%%'
                    startangle=90,
                    colors=colors,
                )
                axes[1, 0].set_title(
                    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º",
                    fontsize=FORMATTING.SUBTITLE_FONT_SIZE,
                    fontweight="bold",
                )

        # 4. –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        axes[1, 1].axis("off")

        min_weight_val = (
            weights[weights > PORTFOLIO_CONSTANTS.MIN_WEIGHT].min()
            if any(weights > PORTFOLIO_CONSTANTS.MIN_WEIGHT)
            else 0
        )

        metrics_text = PortfolioVisualizer._format_metrics_text(
            metrics, benchmarks, n_positions, weights, min_weight_val
        )

        axes[1, 1].text(
            0.05,
            0.5,
            metrics_text,
            transform=axes[1, 1].transAxes,
            fontsize=FORMATTING.LABEL_FONT_SIZE,
            verticalalignment="center",
            family="monospace",
            bbox=dict(
                boxstyle="round",
                facecolor=FORMATTING.COLOR_PORTFOLIO_BG,
                edgecolor=FORMATTING.COLOR_PORTFOLIO_MARKER,
                alpha=0.9,
            ),
        )
        axes[1, 1].set_title(
            "–°–≤–æ–¥–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è", fontsize=FORMATTING.SUBTITLE_FONT_SIZE, fontweight="bold"
        )

        plt.suptitle(
            "–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å",
            fontsize=FORMATTING.TITLE_FONT_SIZE,
            fontweight="bold",
        )
        plt.tight_layout()
        plt.savefig(filename, dpi=FILE_CONSTANTS.DPI, bbox_inches="tight")
        plt.show()

    @staticmethod
    def _format_metrics_text(
        metrics: PortfolioMetrics,
        benchmarks: MarketBenchmarks,
        n_positions: int,
        weights: np.ndarray,
        min_weight: float,
    ) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""

        div_yield_str = (
            FORMATTING.PERCENT_FORMAT.format(benchmarks.div_yield_median / 100)
            if pd.notna(benchmarks.div_yield_median) and benchmarks.div_yield_median > 0
            else FORMATTING.NA_STRING
        )
        roe_str = (
            FORMATTING.PERCENT_FORMAT.format(benchmarks.roe_median / 100)
            if pd.notna(benchmarks.roe_median) and benchmarks.roe_median > 0
            else FORMATTING.NA_STRING
        )
        pe_str = (
            FORMATTING.FLOAT_FORMAT_1D.format(benchmarks.pe_median)
            if pd.notna(benchmarks.pe_median) and benchmarks.pe_median > 0
            else FORMATTING.NA_STRING
        )
        pb_str = (
            FORMATTING.FLOAT_FORMAT_2D.format(benchmarks.pb_median)
            if pd.notna(benchmarks.pb_median) and benchmarks.pb_median > 0
            else FORMATTING.NA_STRING
        )

        return (
            "\n        üìä –ú–ï–¢–†–ò–ö–ò –ü–û–†–¢–§–ï–õ–Ø\n        \n"
            f"        –û–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {FORMATTING.PERCENT_FORMAT.format(metrics.expected_return)}\n"
            f"        –†–∏—Å–∫ (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å): {FORMATTING.PERCENT_FORMAT.format(metrics.risk)}\n"
            f"        –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {FORMATTING.FLOAT_FORMAT_2D.format(metrics.sharpe_ratio)}\n"
            f"        –ò–Ω–¥–µ–∫—Å –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {FORMATTING.PERCENT_FORMAT.format(metrics.diversification_score)}\n"
            "        \n"
            "        üìà –°–û–°–¢–ê–í\n"
            f"        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∑–∏—Ü–∏–π: {n_positions}\n"
            f"        –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è: {FORMATTING.PERCENT_FORMAT.format(weights.max())}\n"
            f"        –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è: {FORMATTING.PERCENT_FORMAT.format(min_weight)}\n"
            "        \n"
            "        üìâ –†–´–ù–û–ß–ù–´–ï –ë–ï–ù–ß–ú–ê–†–ö–ò\n"
            f"        –ú–µ–¥–∏–∞–Ω–Ω—ã–π P/E: {pe_str}\n"
            f"        –ú–µ–¥–∏–∞–Ω–Ω—ã–π P/B: {pb_str}\n"
            f"        –ú–µ–¥–∏–∞–Ω–Ω—ã–π ROE: {roe_str}\n"
            f"        –ú–µ–¥. –¥–∏–≤. –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {div_yield_str}\n"
        )

    @staticmethod
    def plot_efficient_frontier(
        expected_returns: np.ndarray,
        cov_matrix: np.ndarray,
        optimal_weights: np.ndarray,
        optimal_return: float,
        optimal_risk: float,
        filename: str = None,
    ):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        if filename is None:
            filename = PATHS["efficient_frontier"]

        n_assets = len(expected_returns)

        if n_assets < 2:
            print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–∫—Ç–∏–≤–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞–Ω–∏—Ü—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
            return

        n_portfolios = PORTFOLIO_CONSTANTS.N_EFFICIENT_PORTFOLIOS
        returns = []
        risks = []
        sharpe_ratios = []

        for _ in range(n_portfolios):
            weights = np.random.random(n_assets)
            weights = weights / weights.sum()

            port_return = np.sum(expected_returns * weights)
            port_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))

            returns.append(port_return)
            risks.append(port_risk)
            sharpe_ratios.append(port_return / port_risk if port_risk > 0 else 0)

        plt.figure(figsize=FILE_CONSTANTS.FIGURE_SIZE_FRONTIER)

        scatter = plt.scatter(
            risks,
            returns,
            c=sharpe_ratios,
            cmap=FORMATTING.COLOR_RISK_RETURN_CMAP,
            alpha=0.3,
            s=15,
        )
        plt.colorbar(scatter, label="–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞")

        plt.scatter(
            optimal_risk,
            optimal_return,
            c=FORMATTING.COLOR_OPTIMAL_MARKER,
            s=200,
            marker="*",
            edgecolors="black",
            linewidths=2,
            label="–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å",
        )

        plt.xlabel("–†–∏—Å–∫ (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)", fontsize=FORMATTING.AXIS_FONT_SIZE)
        plt.ylabel("–û–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å", fontsize=FORMATTING.AXIS_FONT_SIZE)
        plt.title(
            "–ì—Ä–∞–Ω–∏—Ü–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ú–∞—Ä–∫–æ–≤–∏—Ü–∞",
            fontsize=FORMATTING.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(filename, dpi=FILE_CONSTANTS.DPI, bbox_inches="tight")
        plt.show()


# ==================== –ö–õ–ê–°–° –§–û–†–ú–ò–†–û–í–ê–¢–ï–õ–Ø –û–¢–ß–ï–¢–û–í ====================


class ReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""

    @staticmethod
    def generate_portfolio_report(
        portfolio_manager: PortfolioManager,
        benchmarks: MarketBenchmarks,
        filename: str = None,
    ):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel –æ—Ç—á–µ—Ç–∞"""
        if filename is None:
            filename = PATHS["portfolio_report"]

        try:
            with pd.ExcelWriter(filename, engine="openpyxl") as writer:
                # –°–æ—Å—Ç–∞–≤ –ø–æ—Ä—Ç—Ñ–µ–ª—è
                portfolio_df = portfolio_manager.df.copy()
                portfolio_df = portfolio_df.sort_values("weights", ascending=False)

                portfolio_display = portfolio_df[
                    [
                        "–¢–∏–∫–µ—Ä",
                        "–ù–∞–∑–≤–∞–Ω–∏–µ",
                        "–°–µ–∫—Ç–æ—Ä",
                        "weights",
                        "–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å",
                        "–†–∏—Å–∫",
                        "P/E",
                        "P/B",
                        "ROE",
                        "–î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å",
                        "Predicted_–û—Ü–µ–Ω–∫–∞_—Ç–µ–∫—Å—Ç",
                        "Predicted_–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å",
                    ]
                ].copy()

                portfolio_display.columns = [
                    REPORT.COLUMN_TICKER,
                    REPORT.COLUMN_NAME,
                    REPORT.COLUMN_SECTOR,
                    REPORT.COLUMN_WEIGHT,
                    REPORT.COLUMN_EXPECTED_RETURN,
                    REPORT.COLUMN_RISK,
                    REPORT.COLUMN_PE,
                    REPORT.COLUMN_PB,
                    REPORT.COLUMN_ROE,
                    REPORT.COLUMN_DIV_YIELD,
                    REPORT.COLUMN_RATING,
                    REPORT.COLUMN_CONFIDENCE,
                ]

                portfolio_display.to_excel(
                    writer, sheet_name=FILE_CONSTANTS.SHEET_PORTFOLIO, index=False
                )

                # –°–µ–∫—Ç–æ—Ä–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                sector_weights = portfolio_manager.get_sector_allocation()
                if len(sector_weights) > 0:
                    sector_df = pd.DataFrame(
                        {"–°–µ–∫—Ç–æ—Ä": sector_weights.index, "–î–æ–ª—è": sector_weights.values}
                    )
                    sector_df.to_excel(
                        writer, sheet_name=FILE_CONSTANTS.SHEET_SECTORS, index=False
                    )

                # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
                min_weight_val = (
                    portfolio_manager.weights[
                        portfolio_manager.weights > PORTFOLIO_CONSTANTS.MIN_WEIGHT
                    ].min()
                    if any(portfolio_manager.weights > PORTFOLIO_CONSTANTS.MIN_WEIGHT)
                    else 0
                )

                metrics_df = pd.DataFrame(
                    {
                        "–ú–µ—Ç—Ä–∏–∫–∞": [
                            REPORT.METRIC_EXPECTED_RETURN,
                            REPORT.METRIC_RISK,
                            REPORT.METRIC_SHARPE,
                            REPORT.METRIC_DIVERSIFICATION,
                            REPORT.METRIC_N_POSITIONS,
                            REPORT.METRIC_MAX_WEIGHT,
                            REPORT.METRIC_MIN_WEIGHT,
                        ],
                        "–ó–Ω–∞—á–µ–Ω–∏–µ": [
                            FORMATTING.PERCENT_FORMAT.format(
                                portfolio_manager.metrics.expected_return
                            ),
                            FORMATTING.PERCENT_FORMAT.format(
                                portfolio_manager.metrics.risk
                            ),
                            FORMATTING.FLOAT_FORMAT_2D.format(
                                portfolio_manager.metrics.sharpe_ratio
                            ),
                            FORMATTING.PERCENT_FORMAT.format(
                                portfolio_manager.metrics.diversification_score
                            ),
                            len(portfolio_manager.df),
                            FORMATTING.PERCENT_FORMAT.format(
                                portfolio_manager.weights.max()
                            ),
                            FORMATTING.PERCENT_FORMAT.format(min_weight_val),
                        ],
                    }
                )
                metrics_df.to_excel(
                    writer, sheet_name=FILE_CONSTANTS.SHEET_METRICS, index=False
                )

                # –†—ã–Ω–æ—á–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏
                benchmarks_df = pd.DataFrame(
                    {
                        "–ú—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä": [
                            REPORT.BENCHMARK_PE,
                            REPORT.BENCHMARK_PB,
                            REPORT.BENCHMARK_PS,
                            REPORT.BENCHMARK_ROE,
                            REPORT.BENCHMARK_DIV_YIELD,
                            REPORT.BENCHMARK_DEBT,
                            REPORT.BENCHMARK_BETA,
                        ],
                        "–ó–Ω–∞—á–µ–Ω–∏–µ": ReportGenerator._format_benchmark_values(
                            benchmarks
                        ),
                    }
                )
                benchmarks_df.to_excel(
                    writer, sheet_name=FILE_CONSTANTS.SHEET_BENCHMARKS, index=False
                )

            print(f"   ‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")

    @staticmethod
    def _format_benchmark_values(benchmarks: MarketBenchmarks) -> List[str]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –±–µ–Ω—á–º–∞—Ä–∫–æ–≤"""
        return [
            (
                FORMATTING.FLOAT_FORMAT_1D.format(benchmarks.pe_median)
                if pd.notna(benchmarks.pe_median)
                else FORMATTING.NA_STRING
            ),
            (
                FORMATTING.FLOAT_FORMAT_2D.format(benchmarks.pb_median)
                if pd.notna(benchmarks.pb_median)
                else FORMATTING.NA_STRING
            ),
            (
                FORMATTING.FLOAT_FORMAT_2D.format(benchmarks.ps_median)
                if pd.notna(benchmarks.ps_median)
                else FORMATTING.NA_STRING
            ),
            (
                FORMATTING.PERCENT_FORMAT.format(benchmarks.roe_median / 100)
                if pd.notna(benchmarks.roe_median)
                else FORMATTING.NA_STRING
            ),
            (
                FORMATTING.PERCENT_FORMAT.format(benchmarks.div_yield_median / 100)
                if pd.notna(benchmarks.div_yield_median)
                else FORMATTING.NA_STRING
            ),
            (
                FORMATTING.PERCENT_FORMAT.format(benchmarks.debt_capital_median / 100)
                if pd.notna(benchmarks.debt_capital_median)
                else FORMATTING.NA_STRING
            ),
            (
                FORMATTING.FLOAT_FORMAT_2D.format(benchmarks.beta_median)
                if pd.notna(benchmarks.beta_median)
                else FORMATTING.NA_STRING
            ),
        ]

    @staticmethod
    def print_recommendations(portfolio_manager: PortfolioManager):
        """–í—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ –∫–æ–Ω—Å–æ–ª—å"""
        print(FORMATTING.SEPARATOR)
        print("üéØ –ö–õ–Æ–ß–ï–í–´–ï –ò–ù–í–ï–°–¢–ò–¶–ò–û–ù–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
        print(FORMATTING.SEPARATOR)

        # –¢–æ–ø-3 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        top_n = min(
            PORTFOLIO_CONSTANTS.TOP_RECOMMENDATIONS_N, len(portfolio_manager.df)
        )
        top_positions = portfolio_manager.get_top_positions(top_n)

        print(f"\nüîπ –¢–û–ü-{top_n} –ê–ö–¶–ò–ò –î–õ–Ø –ü–û–ö–£–ü–ö–ò:")
        for _, row in top_positions.iterrows():
            print(f"   ‚Ä¢ {row['–¢–∏–∫–µ—Ä']} - {row['–ù–∞–∑–≤–∞–Ω–∏–µ']}")
            print(
                f"     –î–æ–ª—è: {FORMATTING.PERCENT_FORMAT.format(row['weights'])} | "
                f"–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {FORMATTING.PERCENT_FORMAT.format(row['–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å'])} | "
                f"–†–∏—Å–∫: {FORMATTING.PERCENT_FORMAT.format(row['–†–∏—Å–∫'])}"
            )
            print(
                f"     –û—Ü–µ–Ω–∫–∞: {row['Predicted_–û—Ü–µ–Ω–∫–∞_—Ç–µ–∫—Å—Ç']} "
                f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {FORMATTING.PERCENT_FORMAT.format(row['Predicted_–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'])})"
            )

        print("\nüî∏ –î–ò–í–ï–†–°–ò–§–ò–ö–ê–¶–ò–Ø:")
        print(
            f"   ‚Ä¢ –ò–Ω–¥–µ–∫—Å –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {FORMATTING.PERCENT_FORMAT.format(portfolio_manager.metrics.diversification_score)}"
        )
        sector_allocation = portfolio_manager.get_sector_allocation()
        print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–∫—Ç–æ—Ä–æ–≤: {len(sector_allocation)}")
        if len(sector_allocation) > 0:
            print(
                f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è —Å–µ–∫—Ç–æ—Ä–∞: {FORMATTING.PERCENT_FORMAT.format(sector_allocation.max())}"
            )

        print("\nüîπ –†–ò–°–ö-–ú–ï–ù–ï–î–ñ–ú–ï–ù–¢:")
        print(
            f"   ‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {FORMATTING.FLOAT_FORMAT_2D.format(portfolio_manager.metrics.sharpe_ratio)} "
            f"(–≤—ã—à–µ 1 - –æ—Ç–ª–∏—á–Ω–æ)"
        )
        print(
            f"   ‚Ä¢ –û–∂–∏–¥–∞–µ–º–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {FORMATTING.PERCENT_FORMAT.format(portfolio_manager.metrics.risk)}"
        )
        print(
            f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –æ–¥–Ω–æ–π –∞–∫—Ü–∏–∏: {FORMATTING.PERCENT_FORMAT.format(portfolio_manager.weights.max())} "
            f"(–ª–∏–º–∏—Ç {FORMATTING.PERCENT_FORMAT.format(PORTFOLIO_CONSTANTS.MAX_WEIGHT)})"
        )

        print("\nüî∏ –î–ê–õ–¨–ù–ï–ô–®–ò–ï –î–ï–ô–°–¢–í–ò–Ø:")
        print("   ‚Ä¢ –†–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è –∫–∞–∂–¥—ã–µ 3-6 –º–µ—Å—è—Ü–µ–≤")
        print("   ‚Ä¢ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –µ–∂–µ–∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ")
        print(
            f"   ‚Ä¢ Stop-loss: {FORMATTING.PERCENT_FORMAT.format(PORTFOLIO_CONSTANTS.STOP_LOSS_THRESHOLD)} –æ—Ç —Ü–µ–Ω—ã –ø–æ–∫—É–ø–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏"
        )
        print(
            f"   ‚Ä¢ Take-profit: +{FORMATTING.PERCENT_FORMAT.format(PORTFOLIO_CONSTANTS.TAKE_PROFIT_THRESHOLD)} –¥–ª—è –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö –∞–∫—Ü–∏–π"
        )

        print(FORMATTING.SEPARATOR)


# ==================== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –ö–õ–ê–°–° –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –ú–£–õ–¨–¢–ò–ü–õ–ò–ö–ê–¢–û–†–û–í ====================


class MultiplierAnalyzer:
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä–æ–≤"""

    @staticmethod
    def analyze_sector_multipliers(df: pd.DataFrame) -> pd.DataFrame:
        """–ê–Ω–∞–ª–∏–∑ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        sector_stats = []

        for sector in df["–°–µ–∫—Ç–æ—Ä"].unique():
            sector_df = df[df["–°–µ–∫—Ç–æ—Ä"] == sector]

            stats = {
                "–°–µ–∫—Ç–æ—Ä": sector,
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": len(sector_df),
                "P/E_–º–µ–¥–∏–∞–Ω–∞": sector_df["P/E"].median(),
                "P/B_–º–µ–¥–∏–∞–Ω–∞": sector_df["P/B"].median(),
                "ROE_–º–µ–¥–∏–∞–Ω–∞": sector_df["ROE"].median(),
                "–î–∏–≤.–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å_–º–µ–¥–∏–∞–Ω–∞": sector_df["–î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"].median(),
                "–ë–µ—Ç–∞_–º–µ–¥–∏–∞–Ω–∞": sector_df["–ë–µ—Ç–∞"].median(),
                "–ö–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è_–º–µ–¥–∏–∞–Ω–∞": sector_df["–†—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è"].median()
                / CONVERSION.BILLION,
            }
            sector_stats.append(stats)

        return pd.DataFrame(sector_stats)

    @staticmethod
    def find_best_values(df: pd.DataFrame) -> Dict:
        """–ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        best_values = {
            "–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π P/E": df[df["P/E"] > 0]["P/E"].min(),
            "–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π P/B": df[df["P/B"] > 0]["P/B"].min(),
            "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π ROE": df["ROE"].max(),
            "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–∏–≤.–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å": df["–î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"].max(),
            "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –±–µ—Ç–∞": df[df["–ë–µ—Ç–∞"] > 0]["–ë–µ—Ç–∞"].min(),
        }
        return best_values


# ==================== –û–°–ù–û–í–ù–û–ô –ü–ê–ô–ü–õ–ê–ô–ù ====================


def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""

    print("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è...")

    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    loader = DataLoader()
    df = loader.load_and_clean_data(PATHS["file_path"])

    # –®–∞–≥ 2: –†–∞—Å—á–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
    print("üìä –†–∞—Å—á–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤...")
    market_benchmarks = MarketAnalyzer.calculate_benchmarks(df)

    print(f"\nüìà –ú–ï–î–ò–ê–ù–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –ú–£–õ–¨–¢–ò–ü–õ–ò–ö–ê–¢–û–†–û–í:")
    print(f"   P/E: {FORMATTING.FLOAT_FORMAT_1D.format(market_benchmarks.pe_median)}")
    print(f"   P/B: {FORMATTING.FLOAT_FORMAT_2D.format(market_benchmarks.pb_median)}")
    print(f"   P/S: {FORMATTING.FLOAT_FORMAT_2D.format(market_benchmarks.ps_median)}")
    print(
        f"   ROE: {FORMATTING.PERCENT_FORMAT.format(market_benchmarks.roe_median / 100)}"
    )
    print(
        f"   –î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {FORMATTING.PERCENT_FORMAT.format(market_benchmarks.div_yield_median / 100)}"
    )
    print(
        f"   –î–æ–ª–≥/–ö–∞–ø–∏—Ç–∞–ª: {FORMATTING.PERCENT_FORMAT.format(market_benchmarks.debt_capital_median / 100)}"
    )
    print(
        f"   –ë–µ—Ç–∞: {FORMATTING.FLOAT_FORMAT_2D.format(market_benchmarks.beta_median)}"
    )

    # –®–∞–≥ 3: –û–±—É—á–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π
    print("\nüå≥ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π...")
    dt_model = DecisionTreeModel()
    training_results = dt_model.train(df)

    print(
        f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ: {FORMATTING.PERCENT_FORMAT.format(training_results['train_accuracy'])}"
    )
    print(
        f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {FORMATTING.PERCENT_FORMAT.format(training_results['test_accuracy'])}"
    )

    print("\nüîç –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –º–æ–¥–µ–ª–∏:")
    feature_importance = sorted(
        training_results["feature_importance"].items(), key=lambda x: x[1], reverse=True
    )
    for feature, importance in feature_importance[:5]:
        if importance > 0.01:
            print(f"   {feature}: {FORMATTING.PERCENT_FORMAT.format(importance)}")

    # –®–∞–≥ 4: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö –∞–∫—Ü–∏–π
    print("\nüéØ –û—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –∞–∫—Ü–∏–π...")
    df = dt_model.predict(df)

    # –®–∞–≥ 5: –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    print("üìâ –†–∞—Å—á–µ—Ç —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∏ —Ä–∏—Å–∫–∞...")
    fundamental_analyzer = FundamentalAnalyzer(market_benchmarks)

    df["–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"] = df.apply(
        fundamental_analyzer.calculate_expected_return, axis=1
    )
    df["–†–∏—Å–∫"] = df.apply(fundamental_analyzer.calculate_risk, axis=1)

    # –®–∞–≥ 6: –û—Ç–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ –ø–æ—Ä—Ç—Ñ–µ–ª—å
    print("üéØ –û—Ç–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ –ø–æ—Ä—Ç—Ñ–µ–ª—å...")

    candidates = df[
        (
            df["Predicted_–û—Ü–µ–Ω–∫–∞"].isin(
                [TARGET_MAPPING.STRONG_UNDERVALUED, TARGET_MAPPING.UNDERVALUED]
            )
        )
        & (df["–†—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è"].fillna(0) > PORTFOLIO_CONSTANTS.MIN_MARKET_CAP)
        & (
            df["–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"].fillna(0)
            > PORTFOLIO_CONSTANTS.MIN_EXPECTED_RETURN
        )
        & (df["–†–∏—Å–∫"].fillna(1) < PORTFOLIO_CONSTANTS.MAX_RISK)
    ].copy()

    if len(candidates) < 5:
        print("   ‚ö†Ô∏è –ú–∞–ª–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, —Ä–∞—Å—à–∏—Ä—è–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–∏...")
        candidates = df[
            (
                df["Predicted_–û—Ü–µ–Ω–∫–∞"].isin(
                    [
                        TARGET_MAPPING.STRONG_UNDERVALUED,
                        TARGET_MAPPING.UNDERVALUED,
                        TARGET_MAPPING.FAIR_VALUE,
                    ]
                )
            )
            & (
                df["–†—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è"].fillna(0)
                > PORTFOLIO_CONSTANTS.MIN_MARKET_CAP_LOOSE
            )
            & (
                df["–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"].fillna(0)
                > PORTFOLIO_CONSTANTS.MIN_EXPECTED_RETURN_LOOSE
            )
        ].copy()

    if len(candidates) > PORTFOLIO_CONSTANTS.MAX_CANDIDATES:
        candidates = candidates.nlargest(
            PORTFOLIO_CONSTANTS.MAX_CANDIDATES, "Predicted_–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
        )

    print(f"   –û—Ç–æ–±—Ä–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(candidates)}")

    if len(candidates) < 2:
        print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è!")
        return None

    # –®–∞–≥ 7: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è
    print("üìê –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –ø–æ –ú–∞—Ä–∫–æ–≤–∏—Ü—É...")
    optimizer = PortfolioOptimizer(
        min_weight=PORTFOLIO_CONSTANTS.MIN_WEIGHT,
        max_weight=(
            PORTFOLIO_CONSTANTS.MAX_WEIGHT_LOOSE
            if len(candidates) < 10
            else PORTFOLIO_CONSTANTS.MAX_WEIGHT
        ),
    )

    try:
        cov_matrix = optimizer.create_covariance_matrix(candidates)

        optimization_result = optimizer.optimize(
            candidates["–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"].values, cov_matrix
        )

        # –®–∞–≥ 8: –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        print("üíº –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è...")
        portfolio_manager = PortfolioManager(
            candidates, optimization_result["combined_weights"]
        )

        # –®–∞–≥ 9: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        print("üìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")
        visualizer = PortfolioVisualizer()

        dt_model.plot_tree(PATHS["decision_tree"])

        visualizer.plot_portfolio_summary(
            candidates,
            optimization_result["combined_weights"],
            portfolio_manager.metrics,
            market_benchmarks,
            PATHS["optimal_portfolio"],
        )

        visualizer.plot_efficient_frontier(
            candidates["–û–∂–∏–¥–∞–µ–º–∞—è_–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"].values,
            cov_matrix,
            optimization_result["combined_weights"],
            portfolio_manager.metrics.expected_return,
            portfolio_manager.metrics.risk,
            PATHS["efficient_frontier"],
        )

        # –®–∞–≥ 10: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
        print("üìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤...")
        report_generator = ReportGenerator()
        report_generator.generate_portfolio_report(
            portfolio_manager, market_benchmarks, PATHS["portfolio_report"]
        )

        # –®–∞–≥ 11: –í—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        report_generator.print_recommendations(portfolio_manager)

        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
        print(f"   ‚Ä¢ {PATHS['portfolio_report']} - –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç")
        print(f"   ‚Ä¢ {PATHS['optimal_portfolio']} - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è")
        print(f"   ‚Ä¢ {PATHS['efficient_frontier']} - –≥—Ä–∞–Ω–∏—Ü–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
        print(f"   ‚Ä¢ {PATHS['decision_tree']} - –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π")

        return portfolio_manager

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {e}")
        return None


# ==================== –ó–ê–ü–£–°–ö –° –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ú –ê–ù–ê–õ–ò–ó–û–ú ====================

if __name__ == "__main__":
    portfolio = main()

    if portfolio is not None:
        print(FORMATTING.SEPARATOR)
        print("üìä –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ú–£–õ–¨–¢–ò–ü–õ–ò–ö–ê–¢–û–†–û–í")
        print(FORMATTING.SEPARATOR)

        loader = DataLoader()
        df_full = loader.load_and_clean_data(PATHS["file_path"])
        df_full["–°–µ–∫—Ç–æ—Ä"] = df_full["–ù–∞–∑–≤–∞–Ω–∏–µ"].apply(MarketAnalyzer.assign_sector)

        multiplier_analyzer = MultiplierAnalyzer()
        sector_multipliers = multiplier_analyzer.analyze_sector_multipliers(df_full)

        print("\nüìà –ú–£–õ–¨–¢–ò–ü–õ–ò–ö–ê–¢–û–†–´ –ü–û –°–ï–ö–¢–û–†–ê–ú:")
        print(sector_multipliers.round(2).to_string(index=False))

        best_values = multiplier_analyzer.find_best_values(df_full)
        print("\nüèÜ –õ–£–ß–®–ò–ï –ó–ù–ê–ß–ï–ù–ò–Ø –ù–ê –†–´–ù–ö–ï:")
        for key, value in best_values.items():
            if pd.notna(value):
                if "–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å" in key.lower():
                    print(f"   {key}: {FORMATTING.PERCENT_FORMAT.format(value / 100)}")
                elif "–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è" in key.lower():
                    print(
                        f"   {key}: {FORMATTING.BILLIONS_FORMAT.format(value / CONVERSION.BILLION)}"
                    )
                else:
                    print(f"   {key}: {FORMATTING.FLOAT_FORMAT_2D.format(value)}")
