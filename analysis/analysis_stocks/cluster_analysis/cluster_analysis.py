import os
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from scipy.optimize import minimize
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
import warnings

# –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Å—Ç–∞–Ω—Ç
from cluster_constants import (
    CLUSTER,
    CLUSTER_THRESHOLDS,
    CLUSTER_SCORES,
    PORTFOLIO_CLUSTER,
    RETURN_PREMIUMS_CLUSTER,
    RISK_PREMIUMS_CLUSTER,
    SECTOR_KEYWORDS_CLUSTER,
    SECTOR_NAMES_CLUSTER,
    SCORING,
    CLUSTER_FILES,
    CLUSTER_FORMAT,
    CLUSTER_REPORT,
)

warnings.filterwarnings("ignore")

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ü–£–¢–ï–ô ====================


class ClusterPathConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""

    @staticmethod
    def setup_directories():
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        cluster_dir = f"{parent_dir}/../data/cluster_analysis"
        os.makedirs(cluster_dir, exist_ok=True)

        return {
            "cluster_dir": cluster_dir,
            "data_path": f"{parent_dir}/../data/fundamentals_shares.xlsx",
            "cluster_analysis": f"{cluster_dir}/{CLUSTER_FILES.CLUSTER_ANALYSIS_FILE}",
            "cluster_optimization": f"{cluster_dir}/{CLUSTER_FILES.CLUSTER_OPTIMIZATION_FILE}",
            "portfolio_comparison": f"{cluster_dir}/{CLUSTER_FILES.PORTFOLIO_COMPARISON_FILE}",
            "cluster_allocation": f"{cluster_dir}/{CLUSTER_FILES.CLUSTER_ALLOCATION_FILE}",
            "clustered_companies": f"{cluster_dir}/{CLUSTER_FILES.CLUSTERED_COMPANIES_FILE}",
            "investment_cluster_report": f"{cluster_dir}/{CLUSTER_FILES.INVESTMENT_CLUSTER_REPORT}",
        }


CLUSTER_PATHS = ClusterPathConfig.setup_directories()

# ==================== –ö–õ–ê–°–°–´ –î–ê–ù–ù–´–• ====================


@dataclass
class ClusterCharacteristics:
    """–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞"""

    cluster_id: int
    size: int
    avg_pe: float
    avg_pb: float
    avg_roe: float
    avg_div_yield: float
    avg_risk: float
    description: str
    recommendation: str


@dataclass
class PortfolioMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""

    expected_return: float
    risk: float
    sharpe_ratio: float
    diversification_score: float


# ==================== –ö–õ–ê–°–° –ó–ê–ì–†–£–ó–ß–ò–ö–ê –î–ê–ù–ù–´–• ====================


class DataLoader:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""

    @staticmethod
    def convert_to_float(value):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç—Ä–æ–∫ —Å —á–∏—Å–ª–∞–º–∏ –≤ float"""
        if pd.isna(value) or value == "" or value == 0:
            return np.nan
        if isinstance(value, (int, float)):
            return value

        value = str(value).strip()
        value = value.replace(" ", "").replace(",", ".")

        if "–º–ª—Ä–¥" in value:
            return float(re.sub(r"[^\d.]", "", value)) * 1e9
        elif "–º–ª–Ω" in value:
            return float(re.sub(r"[^\d.]", "", value)) * 1e6
        else:
            try:
                return float(re.sub(r"[^\d.-]", "", value))
            except:
                return np.nan

    @staticmethod
    def load_and_clean_data(filepath: str) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        df = pd.read_excel(filepath, sheet_name="Sheet1")

        column_mapping = {
            "–¢–∏–∫–µ—Ä": "Ticker",
            "–ù–∞–∑–≤–∞–Ω–∏–µ": "Company",
            "–†—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è": "Market_Cap",
            "P/E": "PE",
            "P/B": "PB",
            "P/S": "PS",
            "P/FCF": "PFCF",
            "ROE": "ROE",
            "ROA": "ROA",
            "ROIC": "ROIC",
            "EV/EBITDA": "EV_EBITDA",
            "Averange_dividend_yield": "Div_Yield",
            "–ë–µ—Ç–∞": "Beta",
            "Debt/Capital": "Debt_Capital",
            "–°–≤–æ–±–æ–¥–Ω—ã–π –¥–µ–Ω–µ–∂–Ω—ã–π –ø–æ—Ç–æ–∫": "FCF",
            "–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å": "Net_Income",
            "–í—ã—Ä—É—á–∫–∞": "Revenue",
        }

        rename_dict = {k: v for k, v in column_mapping.items() if k in df.columns}
        df.rename(columns=rename_dict, inplace=True)

        numeric_columns = [
            "Market_Cap",
            "PE",
            "PB",
            "PS",
            "PFCF",
            "ROE",
            "ROA",
            "ROIC",
            "EV_EBITDA",
            "Div_Yield",
            "Beta",
            "Debt_Capital",
            "FCF",
            "Net_Income",
            "Revenue",
        ]

        for col in numeric_columns:
            if col in df.columns:
                df[col] = df[col].apply(DataLoader.convert_to_float)

        df["Sector"] = df["Company"].apply(DataLoader.assign_sector)

        return df

    @staticmethod
    def assign_sector(name: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ç–æ—Ä–∞ –∫–æ–º–ø–∞–Ω–∏–∏"""
        if pd.isna(name):
            return SECTOR_NAMES_CLUSTER.OTHER

        name = str(name).lower()

        sector_mappings = [
            (SECTOR_KEYWORDS_CLUSTER.BANKS, SECTOR_NAMES_CLUSTER.BANKS),
            (SECTOR_KEYWORDS_CLUSTER.OIL_GAS, SECTOR_NAMES_CLUSTER.OIL_GAS),
            (SECTOR_KEYWORDS_CLUSTER.METALS, SECTOR_NAMES_CLUSTER.METALS),
            (SECTOR_KEYWORDS_CLUSTER.ENERGY, SECTOR_NAMES_CLUSTER.ENERGY),
            (SECTOR_KEYWORDS_CLUSTER.TELECOM, SECTOR_NAMES_CLUSTER.TELECOM),
            (SECTOR_KEYWORDS_CLUSTER.RETAIL, SECTOR_NAMES_CLUSTER.RETAIL),
            (SECTOR_KEYWORDS_CLUSTER.CHEMICAL, SECTOR_NAMES_CLUSTER.CHEMICAL),
            (SECTOR_KEYWORDS_CLUSTER.IT, SECTOR_NAMES_CLUSTER.IT),
        ]

        for keywords, sector_name in sector_mappings:
            if any(word in name for word in keywords):
                return sector_name

        return SECTOR_NAMES_CLUSTER.OTHER


# ==================== –ö–õ–ê–°–° –ö–õ–ê–°–¢–ï–†–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê ====================


class ClusterAnalyzer:
    """–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–º–ø–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä–æ–≤"""

    def __init__(self, n_clusters: int = None):
        self.n_clusters = n_clusters or CLUSTER.DEFAULT_N_CLUSTERS
        self.scaler = StandardScaler()
        self.kmeans = None
        self.pca = PCA(n_components=CLUSTER.PCA_COMPONENTS)
        self.cluster_profiles = None
        self.feature_names = []

    def find_optimal_clusters(
        self, df: pd.DataFrame, features: List[str], max_clusters: int = None
    ) -> Tuple[int, pd.DataFrame]:
        """–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        max_clusters = max_clusters or CLUSTER.MAX_CLUSTERS

        df_clean = df[features].dropna()

        if len(df_clean) < CLUSTER.MIN_DATA_FOR_CLUSTERING:
            print(
                f"   ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏. "
                f"–î–æ—Å—Ç—É–ø–Ω–æ: {len(df_clean)} –∫–æ–º–ø–∞–Ω–∏–π"
            )
            return min(CLUSTER.MIN_CLUSTERS, len(df_clean)), pd.DataFrame()

        scaled_data = self.scaler.fit_transform(df_clean)

        inertias = []
        silhouette_scores = []
        max_k = min(max_clusters + 1, len(df_clean))

        for k in range(CLUSTER.MIN_CLUSTERS, max_k):
            kmeans = KMeans(
                n_clusters=k, random_state=CLUSTER.RANDOM_STATE, n_init=CLUSTER.N_INIT
            )
            labels = kmeans.fit_predict(scaled_data)
            inertias.append(kmeans.inertia_)

            if len(set(labels)) > 1:
                silhouette_scores.append(silhouette_score(scaled_data, labels))
            else:
                silhouette_scores.append(0)

        self._plot_optimization(inertias, silhouette_scores)

        optimal_k = (
            np.argmax(silhouette_scores) + CLUSTER.MIN_CLUSTERS
            if silhouette_scores
            else CLUSTER.MIN_CLUSTERS
        )

        print(f"   –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {optimal_k}")

        return optimal_k, pd.DataFrame(
            {
                "clusters": range(CLUSTER.MIN_CLUSTERS, max_k),
                "inertia": inertias,
                "silhouette": silhouette_scores
                + [0] * (len(inertias) - len(silhouette_scores)),
            }
        )

    def _plot_optimization(self, inertias: List[float], silhouette_scores: List[float]):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        fig, axes = plt.subplots(1, 2, figsize=CLUSTER_FILES.FIGURE_SIZE_OPTIMIZATION)

        k_range = range(CLUSTER.MIN_CLUSTERS, CLUSTER.MIN_CLUSTERS + len(inertias))

        axes[0].plot(k_range, inertias, marker="o", linewidth=2)
        axes[0].set_xlabel(
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE
        )
        axes[0].set_ylabel("Inertia", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        axes[0].set_title(
            "–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è", fontsize=CLUSTER_FORMAT.SUBTITLE_FONT_SIZE, fontweight="bold"
        )
        axes[0].grid(True, alpha=CLUSTER.GRID_ALPHA)

        axes[1].plot(
            k_range[: len(silhouette_scores)],
            silhouette_scores,
            marker="o",
            linewidth=2,
            color="green",
        )
        axes[1].set_xlabel(
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE
        )
        axes[1].set_ylabel("Silhouette Score", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        axes[1].set_title(
            "–ê–Ω–∞–ª–∏–∑ —Å–∏–ª—É—ç—Ç–æ–≤",
            fontsize=CLUSTER_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        axes[1].grid(True, alpha=CLUSTER.GRID_ALPHA)

        plt.suptitle(
            "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤",
            fontsize=CLUSTER_FORMAT.TITLE_FONT_SIZE,
            fontweight="bold",
        )
        plt.tight_layout()
        plt.savefig(
            CLUSTER_PATHS["cluster_optimization"],
            dpi=CLUSTER_FILES.DPI,
            bbox_inches="tight",
        )
        plt.show()

    def fit_predict(
        self, df: pd.DataFrame, features: List[str], n_clusters: int = None
    ) -> pd.DataFrame:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        if n_clusters:
            self.n_clusters = n_clusters

        df_clean = df[df[features].notna().all(axis=1)].copy()
        self.feature_names = features

        if len(df_clean) < self.n_clusters:
            print(
                f"   ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏. "
                f"–£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–æ {len(df_clean)}"
            )
            self.n_clusters = max(CLUSTER.MIN_CLUSTERS, len(df_clean))

        scaled_data = self.scaler.fit_transform(df_clean[features])

        self.kmeans = KMeans(
            n_clusters=self.n_clusters,
            random_state=CLUSTER.RANDOM_STATE,
            n_init=CLUSTER.N_INIT,
        )
        df_clean["Cluster"] = self.kmeans.fit_predict(scaled_data)

        pca_result = self.pca.fit_transform(scaled_data)
        df_clean["PCA1"] = pca_result[:, 0]
        df_clean["PCA2"] = pca_result[:, 1]

        return df_clean

    def analyze_clusters(self, df: pd.DataFrame) -> List[ClusterCharacteristics]:
        """–ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        cluster_profiles = []

        for cluster_id in range(self.n_clusters):
            cluster_data = df[df["Cluster"] == cluster_id]

            if len(cluster_data) == 0:
                continue

            avg_pe = cluster_data["PE"].median() if "PE" in cluster_data else 0
            avg_pb = cluster_data["PB"].median() if "PB" in cluster_data else 0
            avg_roe = cluster_data["ROE"].median() if "ROE" in cluster_data else 0
            avg_div = (
                cluster_data["Div_Yield"].median() if "Div_Yield" in cluster_data else 0
            )

            risk_factors = []
            if "Beta" in cluster_data:
                risk_factors.append(cluster_data["Beta"].mean())
            if "Debt_Capital" in cluster_data:
                risk_factors.append(cluster_data["Debt_Capital"].mean() / 100)

            avg_risk = (
                np.mean(risk_factors) if risk_factors else PORTFOLIO_CLUSTER.BASE_RISK
            )

            description = self._describe_cluster(avg_pe, avg_pb, avg_roe)
            recommendation = self._get_recommendation(avg_pe, avg_pb, avg_roe, avg_div)

            cluster_profiles.append(
                ClusterCharacteristics(
                    cluster_id=cluster_id,
                    size=len(cluster_data),
                    avg_pe=avg_pe,
                    avg_pb=avg_pb,
                    avg_roe=avg_roe,
                    avg_div_yield=avg_div,
                    avg_risk=avg_risk,
                    description=description,
                    recommendation=recommendation,
                )
            )

        self.cluster_profiles = cluster_profiles
        return cluster_profiles

    def _describe_cluster(self, avg_pe: float, avg_pb: float, avg_roe: float) -> str:
        """–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–∞"""
        if (
            avg_pe < CLUSTER_THRESHOLDS.PE_DEEP_VALUE
            and avg_pb < CLUSTER_THRESHOLDS.PB_DEEP_VALUE
        ):
            return CLUSTER_REPORT.DESC_DEEP_VALUE
        elif (
            avg_pe < CLUSTER_THRESHOLDS.PE_VALUE
            and avg_pb < CLUSTER_THRESHOLDS.PB_VALUE
        ):
            return CLUSTER_REPORT.DESC_VALUE
        elif (
            avg_pe > CLUSTER_THRESHOLDS.PE_GROWTH
            and avg_pb > CLUSTER_THRESHOLDS.PB_GROWTH
        ):
            return CLUSTER_REPORT.DESC_GROWTH_OVER
        elif avg_roe > CLUSTER_THRESHOLDS.ROE_HIGH:
            return CLUSTER_REPORT.DESC_HIGH_PROFIT
        elif avg_roe > CLUSTER_THRESHOLDS.ROE_GOOD:
            return CLUSTER_REPORT.DESC_PROFIT
        else:
            return CLUSTER_REPORT.DESC_FAIR

    def _get_recommendation(
        self, avg_pe: float, avg_pb: float, avg_roe: float, avg_div: float
    ) -> str:
        """–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞"""
        score = 0

        if avg_pe < CLUSTER_THRESHOLDS.PE_VALUE:
            score += CLUSTER_SCORES.PE_VALUE_SCORE
        if avg_pb < CLUSTER_THRESHOLDS.PB_VALUE:
            score += CLUSTER_SCORES.PB_VALUE_SCORE
        if avg_roe > CLUSTER_THRESHOLDS.ROE_GOOD:
            score += CLUSTER_SCORES.ROE_GOOD_SCORE
        if avg_div > CLUSTER_THRESHOLDS.DIV_GOOD:
            score += CLUSTER_SCORES.DIV_GOOD_SCORE

        if score >= CLUSTER_SCORES.AGGRESSIVE_BUY_THRESHOLD:
            return CLUSTER_REPORT.REC_AGGRESSIVE_BUY
        elif score >= CLUSTER_SCORES.BUY_THRESHOLD:
            return CLUSTER_REPORT.REC_BUY
        elif score >= CLUSTER_SCORES.HOLD_THRESHOLD:
            return CLUSTER_REPORT.REC_HOLD
        else:
            return CLUSTER_REPORT.REC_AVOID

    def plot_clusters(self, df: pd.DataFrame, save_path: str = None):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        if save_path is None:
            save_path = CLUSTER_PATHS["cluster_analysis"]

        fig, axes = plt.subplots(2, 2, figsize=CLUSTER_FILES.FIGURE_SIZE_CLUSTERS)

        self._plot_pca_clusters(df, axes[0, 0])
        self._plot_pb_roe_clusters(df, axes[0, 1])
        self._plot_cluster_sizes(df, axes[1, 0])
        self._plot_cluster_profiles(axes[1, 1])

        plt.suptitle(
            "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–ø–∞–Ω–∏–π",
            fontsize=CLUSTER_FORMAT.TITLE_FONT_SIZE,
            fontweight="bold",
        )
        plt.tight_layout()
        plt.savefig(save_path, dpi=CLUSTER_FILES.DPI, bbox_inches="tight")
        plt.show()

    def _plot_pca_clusters(self, df: pd.DataFrame, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è PCA –ø—Ä–æ–µ–∫—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        if "PCA1" in df.columns and "PCA2" in df.columns:
            scatter = ax.scatter(
                df["PCA1"],
                df["PCA2"],
                c=df["Cluster"],
                cmap=CLUSTER_FORMAT.COLOR_CLUSTER_CMAP,
                s=CLUSTER.SCATTER_POINT_SIZE,
                alpha=CLUSTER.SCATTER_ALPHA,
                edgecolors="black",
                linewidths=0.5,
            )

            if self.kmeans is not None:
                centroids = self.pca.transform(self.kmeans.cluster_centers_)
                ax.scatter(
                    centroids[:, 0],
                    centroids[:, 1],
                    marker="X",
                    s=CLUSTER.CENTROID_POINT_SIZE,
                    c=CLUSTER_FORMAT.COLOR_CENTROID,
                    edgecolors="black",
                    linewidths=2,
                    label="–¶–µ–Ω—Ç—Ä–æ–∏–¥—ã",
                )

            ax.set_xlabel("PCA Component 1", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
            ax.set_ylabel("PCA Component 2", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
            ax.set_title(
                "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–∞–Ω–∏–π (PCA –ø—Ä–æ–µ–∫—Ü–∏—è)",
                fontsize=CLUSTER_FORMAT.SUBTITLE_FONT_SIZE,
                fontweight="bold",
            )
            ax.grid(True, alpha=CLUSTER.GRID_ALPHA)
            ax.legend()

            cbar = plt.colorbar(scatter, ax=ax)
            cbar.set_label("–ö–ª–∞—Å—Ç–µ—Ä", fontsize=CLUSTER_FORMAT.LABEL_FONT_SIZE)

    def _plot_pb_roe_clusters(self, df: pd.DataFrame, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ P/B –∏ ROE"""
        for cluster_id in df["Cluster"].unique():
            cluster_data = df[df["Cluster"] == cluster_id]
            if "PB" in cluster_data and "ROE" in cluster_data:
                ax.scatter(
                    cluster_data["PB"],
                    cluster_data["ROE"],
                    label=f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}",
                    s=CLUSTER.SCATTER_POINT_SIZE,
                    alpha=CLUSTER.SCATTER_ALPHA,
                    edgecolors="black",
                    linewidths=0.5,
                )

        ax.set_xlabel("P/B", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("ROE, %", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: P/B vs ROE",
            fontsize=CLUSTER_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        ax.legend()
        ax.grid(True, alpha=CLUSTER.GRID_ALPHA)

    def _plot_cluster_sizes(self, df: pd.DataFrame, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        cluster_sizes = df["Cluster"].value_counts().sort_index()
        colors = plt.cm.get_cmap(CLUSTER_FORMAT.COLOR_CLUSTER_CMAP)(
            np.linspace(0, 1, len(cluster_sizes))
        )
        bars = ax.bar(
            cluster_sizes.index.astype(str),
            cluster_sizes.values,
            color=colors,
            edgecolor="black",
        )

        for bar, size in zip(bars, cluster_sizes.values):
            ax.text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + CLUSTER.BAR_TEXT_OFFSET,
                str(size),
                ha="center",
                va="bottom",
                fontsize=CLUSTER_FORMAT.BAR_TEXT_FONT_SIZE,
                fontweight="bold",
            )

        ax.set_xlabel("–ö–ª–∞—Å—Ç–µ—Ä", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–∞–Ω–∏–π", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "–†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤",
            fontsize=CLUSTER_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        ax.grid(True, alpha=CLUSTER.GRID_ALPHA, axis="y")

    def _plot_cluster_profiles(self, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        ax.axis("off")

        if self.cluster_profiles:
            profile_text = "–ü–†–û–§–ò–õ–ò –ö–õ–ê–°–¢–ï–†–û–í:\n\n"
            for profile in self.cluster_profiles[:5]:
                profile_text += f"–ö–ª–∞—Å—Ç–µ—Ä {profile.cluster_id} ({profile.size} —à—Ç.):\n"
                profile_text += f"  ‚Ä¢ {profile.description}\n"
                profile_text += (
                    f"  ‚Ä¢ P/E: {profile.avg_pe:.1f} | P/B: {profile.avg_pb:.2f}\n"
                )
                profile_text += f"  ‚Ä¢ ROE: {profile.avg_roe:.1f}% | –î–∏–≤.: {profile.avg_div_yield:.1f}%\n"
                profile_text += f"  ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {profile.recommendation}\n\n"

            ax.text(
                0.05,
                0.95,
                profile_text,
                transform=ax.transAxes,
                fontsize=CLUSTER_FORMAT.LABEL_FONT_SIZE,
                verticalalignment="top",
                family="monospace",
                bbox=dict(
                    boxstyle="round",
                    facecolor=CLUSTER_FORMAT.COLOR_PORTFOLIO_BG,
                    edgecolor=CLUSTER_FORMAT.COLOR_PORTFOLIO_EDGE,
                    alpha=0.9,
                ),
            )


# ==================== –ö–õ–ê–°–° –§–£–ù–î–ê–ú–ï–ù–¢–ê–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê ====================


class FundamentalAnalyzer:
    """–†–∞—Å—á–µ—Ç —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏ —Å–∫–æ—Ä–∏–Ω–≥–∞"""

    @staticmethod
    def calculate_value_score(row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (0-100)"""
        score = SCORING.BASE_SCORE

        if pd.notna(row.get("PE")) and row["PE"] > 0:
            if row["PE"] < CLUSTER_THRESHOLDS.SCORE_PE_STRONG:
                score += SCORING.PE_DEEP_VALUE_BONUS
            elif row["PE"] < CLUSTER_THRESHOLDS.SCORE_PE_MEDIUM:
                score += SCORING.PE_VALUE_BONUS
            elif row["PE"] < CLUSTER_THRESHOLDS.SCORE_PE_WEAK:
                score += SCORING.PE_FAIR_BONUS
            elif row["PE"] > CLUSTER_THRESHOLDS.SCORE_PE_OVER:
                score += SCORING.PE_OVER_PENALTY

        if pd.notna(row.get("PB")) and row["PB"] > 0:
            if row["PB"] < CLUSTER_THRESHOLDS.SCORE_PB_STRONG:
                score += SCORING.PB_DEEP_VALUE_BONUS
            elif row["PB"] < CLUSTER_THRESHOLDS.SCORE_PB_MEDIUM:
                score += SCORING.PB_VALUE_BONUS
            elif row["PB"] < CLUSTER_THRESHOLDS.SCORE_PB_WEAK:
                score += SCORING.PB_FAIR_BONUS
            elif row["PB"] > CLUSTER_THRESHOLDS.SCORE_PB_OVER:
                score += SCORING.PB_OVER_PENALTY

        return max(SCORING.MIN_SCORE, min(SCORING.MAX_SCORE, score))

    @staticmethod
    def calculate_quality_score(row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (0-100)"""
        score = SCORING.BASE_SCORE

        if pd.notna(row.get("ROE")):
            if row["ROE"] > CLUSTER_THRESHOLDS.SCORE_ROE_HIGH:
                score += SCORING.ROE_HIGH_BONUS
            elif row["ROE"] > CLUSTER_THRESHOLDS.SCORE_ROE_GOOD:
                score += SCORING.ROE_GOOD_BONUS
            elif row["ROE"] > CLUSTER_THRESHOLDS.SCORE_ROE_MEDIUM:
                score += SCORING.ROE_MEDIUM_BONUS
            elif row["ROE"] > CLUSTER_THRESHOLDS.SCORE_ROE_LOW:
                score += SCORING.ROE_LOW_BONUS
            elif row["ROE"] < 0:
                score += SCORING.ROE_NEGATIVE_PENALTY

        if pd.notna(row.get("Debt_Capital")):
            if row["Debt_Capital"] < CLUSTER_THRESHOLDS.SCORE_DEBT_LOW:
                score += SCORING.DEBT_LOW_BONUS
            elif row["Debt_Capital"] < CLUSTER_THRESHOLDS.SCORE_DEBT_MEDIUM:
                score += SCORING.DEBT_MEDIUM_BONUS
            elif row["Debt_Capital"] < CLUSTER_THRESHOLDS.SCORE_DEBT_HIGH:
                score += SCORING.DEBT_HIGH_BONUS
            elif row["Debt_Capital"] > CLUSTER_THRESHOLDS.SCORE_DEBT_CRITICAL:
                score += SCORING.DEBT_CRITICAL_PENALTY

        return max(SCORING.MIN_SCORE, min(SCORING.MAX_SCORE, score))

    @staticmethod
    def calculate_growth_score(row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∞ —Ä–æ—Å—Ç–∞ (0-100)"""
        score = SCORING.BASE_SCORE

        if pd.notna(row.get("ROE")):
            if row["ROE"] > CLUSTER_THRESHOLDS.SCORE_ROE_GOOD:
                score += SCORING.ROE_GOOD_BONUS
            elif row["ROE"] > CLUSTER_THRESHOLDS.SCORE_ROE_MEDIUM:
                score += SCORING.ROE_MEDIUM_BONUS
            elif row["ROE"] > CLUSTER_THRESHOLDS.SCORE_ROE_LOW:
                score += SCORING.ROE_LOW_BONUS

        if pd.notna(row.get("PS")) and row["PS"] > 0:
            if row["PS"] > CLUSTER_THRESHOLDS.SCORE_PB_OVER:
                score += SCORING.PS_HIGH_BONUS
            elif row["PS"] > CLUSTER_THRESHOLDS.SCORE_PB_WEAK:
                score += SCORING.PS_GOOD_BONUS
            elif row["PS"] > CLUSTER_THRESHOLDS.SCORE_PB_MEDIUM:
                score += SCORING.PS_MEDIUM_BONUS

        return max(SCORING.MIN_SCORE, min(SCORING.MAX_SCORE, score))

    @staticmethod
    def calculate_income_score(row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∞ –¥–∏–≤–∏–¥–µ–Ω–¥–Ω–æ–≥–æ –¥–æ—Ö–æ–¥–∞ (0-100)"""
        score = SCORING.BASE_SCORE

        if pd.notna(row.get("Div_Yield")):
            dy = row["Div_Yield"]
            if dy > CLUSTER_THRESHOLDS.SCORE_DIV_HIGH:
                score += SCORING.DIV_HIGH_BONUS
            elif dy > CLUSTER_THRESHOLDS.SCORE_DIV_GOOD:
                score += SCORING.DIV_GOOD_BONUS
            elif dy > CLUSTER_THRESHOLDS.SCORE_DIV_MEDIUM:
                score += SCORING.DIV_MEDIUM_BONUS
            elif dy > CLUSTER_THRESHOLDS.SCORE_DIV_LOW:
                score += SCORING.DIV_LOW_BONUS
            elif dy > CLUSTER_THRESHOLDS.SCORE_DIV_POOR:
                score += SCORING.DIV_POOR_BONUS
            elif dy < CLUSTER_THRESHOLDS.SCORE_DIV_MIN:
                score += SCORING.DIV_MIN_PENALTY

        return max(SCORING.MIN_SCORE, min(SCORING.MAX_SCORE, score))

    @staticmethod
    def calculate_expected_return(row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏"""
        base_return = PORTFOLIO_CLUSTER.BASE_EXPECTED_RETURN

        if pd.notna(row.get("PE")) and row["PE"] > 0:
            if row["PE"] < CLUSTER_THRESHOLDS.PE_DEEP_VALUE:
                base_return += RETURN_PREMIUMS_CLUSTER.PE_DEEP_PREMIUM
            elif row["PE"] < CLUSTER_THRESHOLDS.PE_VALUE:
                base_return += RETURN_PREMIUMS_CLUSTER.PE_VALUE_PREMIUM
            elif row["PE"] < CLUSTER_THRESHOLDS.PE_FAIR:
                base_return += RETURN_PREMIUMS_CLUSTER.PE_FAIR_PREMIUM

        if pd.notna(row.get("PB")) and row["PB"] > 0:
            if row["PB"] < CLUSTER_THRESHOLDS.PB_DEEP_VALUE:
                base_return += RETURN_PREMIUMS_CLUSTER.PB_DEEP_PREMIUM
            elif row["PB"] < CLUSTER_THRESHOLDS.PB_VALUE:
                base_return += RETURN_PREMIUMS_CLUSTER.PB_VALUE_PREMIUM
            elif row["PB"] < CLUSTER_THRESHOLDS.PB_FAIR:
                base_return += RETURN_PREMIUMS_CLUSTER.PB_FAIR_PREMIUM

        if pd.notna(row.get("ROE")):
            if row["ROE"] > CLUSTER_THRESHOLDS.ROE_HIGH:
                base_return += RETURN_PREMIUMS_CLUSTER.ROE_HIGH_PREMIUM
            elif row["ROE"] > CLUSTER_THRESHOLDS.ROE_GOOD:
                base_return += RETURN_PREMIUMS_CLUSTER.ROE_GOOD_PREMIUM
            elif row["ROE"] > CLUSTER_THRESHOLDS.ROE_GOOD * 0.75:
                base_return += RETURN_PREMIUMS_CLUSTER.ROE_MEDIUM_PREMIUM

        if pd.notna(row.get("Div_Yield")):
            base_return += (
                row["Div_Yield"] / 100
            ) * RETURN_PREMIUMS_CLUSTER.DIVIDEND_PREMIUM_FACTOR

        return min(RETURN_PREMIUMS_CLUSTER.MAX_RETURN, base_return)

    @staticmethod
    def calculate_risk(row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–∞"""
        base_risk = PORTFOLIO_CLUSTER.BASE_RISK

        if pd.notna(row.get("Beta")):
            base_risk += (row["Beta"] - 1) * RISK_PREMIUMS_CLUSTER.BETA_RISK_FACTOR

        if pd.notna(row.get("Debt_Capital")):
            if row["Debt_Capital"] > CLUSTER_THRESHOLDS.SCORE_DEBT_CRITICAL:
                base_risk += RISK_PREMIUMS_CLUSTER.DEBT_CRITICAL_PENALTY
            elif row["Debt_Capital"] > CLUSTER_THRESHOLDS.SCORE_DEBT_HIGH:
                base_risk += RISK_PREMIUMS_CLUSTER.DEBT_HIGH_PENALTY
            elif row["Debt_Capital"] > CLUSTER_THRESHOLDS.SCORE_DEBT_MEDIUM:
                base_risk += RISK_PREMIUMS_CLUSTER.DEBT_MEDIUM_PENALTY

        if pd.notna(row.get("PE")):
            if row["PE"] < 0 or row["PE"] > CLUSTER_THRESHOLDS.PE_GROWTH * 3:
                base_risk += RISK_PREMIUMS_CLUSTER.PE_EXTREME_PENALTY
            elif pd.isna(row["PE"]):
                base_risk += RISK_PREMIUMS_CLUSTER.PE_MISSING_PENALTY

        return max(
            PORTFOLIO_CLUSTER.MIN_RISK, min(PORTFOLIO_CLUSTER.MAX_RISK, base_risk)
        )


# ==================== –ö–õ–ê–°–° –û–ü–¢–ò–ú–ò–ó–ê–¢–û–†–ê –ü–û–†–¢–§–ï–õ–Ø ====================


class PortfolioOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –ø–æ –ú–∞—Ä–∫–æ–≤–∏—Ü—É —Å —É—á–µ—Ç–æ–º –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""

    def __init__(self, min_weight: float = None, max_weight: float = None):
        self.min_weight = min_weight or PORTFOLIO_CLUSTER.MIN_WEIGHT
        self.max_weight = max_weight or PORTFOLIO_CLUSTER.MAX_WEIGHT

    def create_covariance_matrix(
        self,
        df: pd.DataFrame,
        intra_cluster_corr: float = None,
        inter_cluster_corr: float = None,
    ) -> np.ndarray:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        intra_cluster_corr = (
            intra_cluster_corr or PORTFOLIO_CLUSTER.INTRA_CLUSTER_CORRELATION
        )
        inter_cluster_corr = (
            inter_cluster_corr or PORTFOLIO_CLUSTER.INTER_CLUSTER_CORRELATION
        )

        n = len(df)
        cov_matrix = np.zeros((n, n))
        risks = df["Risk"].values

        for i in range(n):
            for j in range(n):
                if i == j:
                    cov_matrix[i, j] = risks[i] ** 2
                else:
                    correlation = (
                        intra_cluster_corr
                        if "Cluster" in df.columns
                        and df.iloc[i]["Cluster"] == df.iloc[j]["Cluster"]
                        else inter_cluster_corr
                    )
                    cov_matrix[i, j] = correlation * risks[i] * risks[j]

        return cov_matrix

    def optimize_multi_portfolio(
        self, df: pd.DataFrame, strategies: List[str] = None
    ) -> Dict:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
        if strategies is None:
            strategies = list(PORTFOLIO_CLUSTER.DEFAULT_STRATEGIES)

        portfolios = {}
        strategy_map = {
            "aggressive": self._optimize_for_max_return,
            "conservative": self._optimize_for_min_risk,
            "balanced": self._optimize_balanced,
            "value": self._optimize_value_portfolio,
            "growth": self._optimize_growth_portfolio,
            "dividend": self._optimize_dividend_portfolio,
            "cluster_based": self._optimize_cluster_based,
        }

        name_map = {
            "aggressive": "–ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π",
            "conservative": "–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π",
            "balanced": "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π",
            "value": "–°—Ç–æ–∏–º–æ—Å—Ç–Ω–æ–π",
            "growth": "–†–æ—Å—Ç–∞",
            "dividend": "–î–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–π",
            "cluster_based": "–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π",
        }

        for strategy in strategies:
            try:
                if strategy in strategy_map:
                    weights = strategy_map[strategy](df)
                    portfolios[name_map[strategy]] = weights
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {strategy}: {e}")

        return portfolios

    def _optimize_for_max_return(self, df: pd.DataFrame) -> np.ndarray:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏"""
        expected_returns = df["Expected_Return"].values
        weights = expected_returns / expected_returns.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()

    def _optimize_for_min_risk(self, df: pd.DataFrame) -> np.ndarray:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∏—Å–∫–∞"""
        risks = df["Risk"].values
        inv_risk = 1 / risks
        weights = inv_risk / inv_risk.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()

    def _optimize_balanced(self, df: pd.DataFrame) -> np.ndarray:
        """–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è"""
        scores = (df["Value_Score"] + df["Quality_Score"]) / 2
        weights = scores / scores.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()

    def _optimize_value_portfolio(self, df: pd.DataFrame) -> np.ndarray:
        """–°—Ç–æ–∏–º–æ—Å—Ç–Ω–æ–π –ø–æ—Ä—Ç—Ñ–µ–ª—å"""
        weights = df["Value_Score"].values / df["Value_Score"].values.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()

    def _optimize_growth_portfolio(self, df: pd.DataFrame) -> np.ndarray:
        """–ü–æ—Ä—Ç—Ñ–µ–ª—å —Ä–æ—Å—Ç–∞"""
        weights = df["Growth_Score"].values / df["Growth_Score"].values.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()

    def _optimize_dividend_portfolio(self, df: pd.DataFrame) -> np.ndarray:
        """–î–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å"""
        weights = df["Income_Score"].values / df["Income_Score"].values.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()

    def _optimize_cluster_based(self, df: pd.DataFrame) -> np.ndarray:
        """–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å - —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º"""
        n = len(df)
        weights = np.zeros(n)
        unique_clusters = df["Cluster"].unique()
        n_clusters = len(unique_clusters)

        for cluster in unique_clusters:
            cluster_indices = df[df["Cluster"] == cluster].index
            cluster_weight = 1 / n_clusters
            per_stock_weight = cluster_weight / len(cluster_indices)
            weights[cluster_indices] = per_stock_weight

        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()


# ==================== –ö–õ–ê–°–° –ü–û–†–¢–§–ï–õ–¨–ù–û–ì–û –ú–ï–ù–ï–î–ñ–ï–†–ê ====================


class PortfolioManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–º –∏ —Ä–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫"""

    def __init__(self, name: str, df: pd.DataFrame, weights: np.ndarray):
        self.name = name
        self.df = df.copy()
        self.weights = weights
        self.df["Weight"] = weights
        self.metrics = self._calculate_metrics()

    def _calculate_metrics(self) -> PortfolioMetrics:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        exp_return = np.sum(self.df["Expected_Return"] * self.weights)

        optimizer = PortfolioOptimizer()
        cov_matrix = optimizer.create_covariance_matrix(self.df)

        risk = np.sqrt(np.dot(self.weights.T, np.dot(cov_matrix, self.weights)))
        sharpe = exp_return / risk if risk > 0 else 0

        hhi = np.sum(self.weights**2)
        n = len(self.weights)
        diversification = 1 - (hhi - 1 / n) / (1 - 1 / n) if n > 1 else 0

        return PortfolioMetrics(
            expected_return=exp_return,
            risk=risk,
            sharpe_ratio=sharpe,
            diversification_score=diversification,
        )

    def get_sector_allocation(self) -> pd.Series:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        if "Sector" in self.df.columns:
            return self.df.groupby("Sector")["Weight"].sum()
        return pd.Series()

    def get_cluster_allocation(self) -> pd.Series:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º"""
        if "Cluster" in self.df.columns:
            return self.df.groupby("Cluster")["Weight"].sum()
        return pd.Series()

    def get_top_positions(self, n: int = None) -> pd.DataFrame:
        """–¢–æ–ø –ø–æ–∑–∏—Ü–∏–π –ø–æ –≤–µ—Å—É"""
        n = n or PORTFOLIO_CLUSTER.TOP_POSITIONS_N
        n = min(n, len(self.df))
        top_idx = np.argsort(self.weights)[::-1][:n]
        return self.df.iloc[top_idx].copy()


# ==================== –ö–õ–ê–°–° –í–ò–ó–£–ê–õ–ò–ó–ê–¢–û–†–ê ====================


class PortfolioVisualizer:
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

    @staticmethod
    def plot_portfolio_comparison(
        portfolios: Dict[str, PortfolioManager],
        filename: str = None,
    ):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π"""
        if not portfolios:
            print("   ‚ö†Ô∏è –ù–µ—Ç –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return

        if filename is None:
            filename = CLUSTER_PATHS["portfolio_comparison"]

        n_portfolios = len(portfolios)
        fig, axes = plt.subplots(2, 2, figsize=CLUSTER_FILES.FIGURE_SIZE_COMPARISON)

        names = []
        returns = []
        risks = []
        sharpe = []

        for name, pm in portfolios.items():
            names.append(name)
            returns.append(pm.metrics.expected_return)
            risks.append(pm.metrics.risk)
            sharpe.append(pm.metrics.sharpe_ratio)

        PortfolioVisualizer._plot_risk_return_comparison(
            axes[0, 0], names, returns, risks, sharpe
        )
        PortfolioVisualizer._plot_sharpe_comparison(axes[0, 1], names, sharpe)
        PortfolioVisualizer._plot_diversification_comparison(
            axes[1, 0], names, portfolios
        )
        PortfolioVisualizer._plot_best_portfolio_summary(axes[1, 1], portfolios)

        plt.suptitle(
            "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π",
            fontsize=CLUSTER_FORMAT.TITLE_FONT_SIZE,
            fontweight="bold",
        )
        plt.tight_layout()
        plt.savefig(filename, dpi=CLUSTER_FILES.DPI, bbox_inches="tight")
        plt.show()

    @staticmethod
    def _plot_risk_return_comparison(ax, names, returns, risks, sharpe):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∏—Å–∫-–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"""
        scatter = ax.scatter(
            risks,
            returns,
            c=sharpe,
            cmap=CLUSTER_FORMAT.COLOR_SHARPE_CMAP,
            s=200,
            edgecolors="black",
            linewidths=1.5,
        )

        for i, name in enumerate(names):
            ax.annotate(
                name,
                (risks[i], returns[i]),
                xytext=(5, 5),
                textcoords="offset points",
                fontsize=CLUSTER_FORMAT.ANNOTATION_FONT_SIZE,
                fontweight="bold",
            )

        ax.set_xlabel("–†–∏—Å–∫", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("–û–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π: Risk-Return",
            fontsize=CLUSTER_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        ax.grid(True, alpha=CLUSTER.GRID_ALPHA)

        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞", fontsize=CLUSTER_FORMAT.LABEL_FONT_SIZE)

    @staticmethod
    def _plot_sharpe_comparison(ax, names, sharpe):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –®–∞—Ä–ø–∞"""
        sharpe_array = np.array(sharpe)
        sharpe_min, sharpe_max = sharpe_array.min(), sharpe_array.max()
        sharpe_range = sharpe_max - sharpe_min + 0.001

        colors = plt.cm.get_cmap(CLUSTER_FORMAT.COLOR_SHARPE_CMAP)(
            (sharpe_array - sharpe_min) / sharpe_range
        )

        bars = ax.bar(names, sharpe, color=colors, edgecolor="black")
        ax.axhline(
            y=1,
            color=CLUSTER_FORMAT.COLOR_SHARPE_TARGET,
            linestyle="--",
            alpha=CLUSTER.SCATTER_ALPHA,
            label="–¶–µ–ª–µ–≤–æ–π –®–∞—Ä–ø = 1",
        )
        ax.set_xlabel("–ü–æ—Ä—Ç—Ñ–µ–ª—å", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –®–∞—Ä–ø–∞",
            fontsize=CLUSTER_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        ax.legend()
        ax.grid(True, alpha=CLUSTER.GRID_ALPHA, axis="y")

        for bar, value in zip(bars, sharpe):
            ax.text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.02,
                f"{value:.2f}",
                ha="center",
                va="bottom",
                fontsize=CLUSTER_FORMAT.BAR_TEXT_FONT_SIZE,
                fontweight="bold",
            )

    @staticmethod
    def _plot_diversification_comparison(ax, names, portfolios):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        diversifications = [
            pm.metrics.diversification_score for pm in portfolios.values()
        ]
        bars = ax.bar(
            names,
            diversifications,
            color=CLUSTER_FORMAT.COLOR_DIVERSIFICATION,
            edgecolor="black",
        )
        ax.set_xlabel("–ü–æ—Ä—Ç—Ñ–µ–ª—å", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("–ò–Ω–¥–µ–∫—Å –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏", fontsize=CLUSTER_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "–£—Ä–æ–≤–µ–Ω—å –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            fontsize=CLUSTER_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        ax.grid(True, alpha=CLUSTER.GRID_ALPHA, axis="y")

        for bar, value in zip(bars, diversifications):
            ax.text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.01,
                f"{value:.1%}",
                ha="center",
                va="bottom",
                fontsize=CLUSTER_FORMAT.BAR_TEXT_FONT_SIZE,
                fontweight="bold",
            )

    @staticmethod
    def _plot_best_portfolio_summary(ax, portfolios):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª—É—á—à–µ–º –ø–æ—Ä—Ç—Ñ–µ–ª–µ"""
        ax.axis("off")

        best_portfolio = max(portfolios.values(), key=lambda p: p.metrics.sharpe_ratio)
        top_n = min(PORTFOLIO_CLUSTER.TOP_POSITIONS_RECOMMEND, len(best_portfolio.df))
        top_positions = best_portfolio.get_top_positions(top_n)

        text = f"üèÜ –õ–£–ß–®–ò–ô –ü–û–†–¢–§–ï–õ–¨: {best_portfolio.name}\n\n"
        text += f"–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {best_portfolio.metrics.expected_return:.1%}\n"
        text += f"–†–∏—Å–∫: {best_portfolio.metrics.risk:.1%}\n"
        text += f"–®–∞—Ä–ø: {best_portfolio.metrics.sharpe_ratio:.2f}\n\n"
        text += f"–¢–û–ü-{top_n} –ü–û–ó–ò–¶–ò–ô:\n"

        for _, row in top_positions.iterrows():
            text += f"‚Ä¢ {row['Ticker']}: {row['Weight']:.1%}\n"

        ax.text(
            0.05,
            0.95,
            text,
            transform=ax.transAxes,
            fontsize=CLUSTER_FORMAT.LABEL_FONT_SIZE,
            verticalalignment="top",
            family="monospace",
            bbox=dict(
                boxstyle="round",
                facecolor=CLUSTER_FORMAT.COLOR_PORTFOLIO_BG,
                edgecolor=CLUSTER_FORMAT.COLOR_PORTFOLIO_EDGE,
                alpha=0.9,
            ),
        )

    @staticmethod
    def plot_cluster_portfolio_allocation(
        portfolio_manager: PortfolioManager, filename: str = None
    ):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º"""
        if filename is None:
            filename = CLUSTER_PATHS["cluster_allocation"]

        fig, axes = plt.subplots(1, 2, figsize=CLUSTER_FILES.FIGURE_SIZE_ALLOCATION)

        cluster_weights = portfolio_manager.get_cluster_allocation()

        if len(cluster_weights) == 0:
            print("   ‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            plt.close()
            return

        colors = plt.cm.get_cmap(CLUSTER_FORMAT.COLOR_CLUSTER_CMAP)(
            np.linspace(0, 1, len(cluster_weights))
        )

        explode = [CLUSTER_FORMAT.PIE_EXPLODE_FACTOR] * len(cluster_weights)

        axes[0].pie(
            cluster_weights.values,
            labels=[f"–ö–ª–∞—Å—Ç–µ—Ä {int(i)}" for i in cluster_weights.index],
            autopct=CLUSTER_FORMAT.MATPLOTLIB_PERCENT,
            startangle=90,
            colors=colors,
            explode=explode,
        )
        axes[0].set_title(
            "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º",
            fontsize=CLUSTER_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )

        axes[1].axis("off")

        text = PortfolioVisualizer._format_cluster_allocation_text(
            portfolio_manager, cluster_weights
        )

        axes[1].text(
            0.05,
            0.95,
            text,
            transform=axes[1].transAxes,
            fontsize=CLUSTER_FORMAT.LABEL_FONT_SIZE,
            verticalalignment="top",
            family="monospace",
            bbox=dict(
                boxstyle="round",
                facecolor=CLUSTER_FORMAT.COLOR_PORTFOLIO_BG,
                edgecolor=CLUSTER_FORMAT.COLOR_PORTFOLIO_EDGE,
                alpha=0.9,
            ),
        )

        plt.suptitle(
            f"–ê–Ω–∞–ª–∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {portfolio_manager.name}",
            fontsize=CLUSTER_FORMAT.TITLE_FONT_SIZE,
            fontweight="bold",
        )
        plt.tight_layout()
        plt.savefig(filename, dpi=CLUSTER_FILES.DPI, bbox_inches="tight")
        plt.show()

    @staticmethod
    def _format_cluster_allocation_text(
        pm: PortfolioManager, cluster_weights: pd.Series
    ) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º"""
        text = f"üìä –°–û–°–¢–ê–í –ü–û–†–¢–§–ï–õ–Ø –ü–û –ö–õ–ê–°–¢–ï–†–ê–ú: {pm.name}\n\n"

        for cluster_id in cluster_weights.index:
            cluster_data = pm.df[pm.df["Cluster"] == cluster_id]
            weight = cluster_weights[cluster_id]

            text += f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id} - {weight:.1%}\n"
            text += f"  –ö–æ–º–ø–∞–Ω–∏–π: {len(cluster_data)}\n"
            text += f"  –°—Ä–µ–¥–Ω–∏–π P/E: {cluster_data['PE'].mean():.1f}\n"
            text += f"  –°—Ä–µ–¥–Ω–∏–π ROE: {cluster_data['ROE'].mean():.1f}%\n"

            if len(cluster_data) > 0:
                top_n = min(PORTFOLIO_CLUSTER.TOP_IN_CLUSTER_N, len(cluster_data))
                top_in_cluster = cluster_data.nlargest(top_n, "Weight")
                text += f"  –¢–æ–ø: {top_in_cluster.iloc[0]['Ticker']} ({top_in_cluster.iloc[0]['Weight']:.1%})"
                if len(top_in_cluster) > 1:
                    text += f", {top_in_cluster.iloc[1]['Ticker']} ({top_in_cluster.iloc[1]['Weight']:.1%})"
            text += "\n\n"

        return text


# ==================== –ö–õ–ê–°–° –§–û–†–ú–ò–†–û–í–ê–¢–ï–õ–Ø –û–¢–ß–ï–¢–û–í ====================


class ReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""

    @staticmethod
    def generate_full_report(
        portfolios: Dict[str, PortfolioManager],
        cluster_profiles: List[ClusterCharacteristics],
        df_original: pd.DataFrame,
        filename: str = None,
    ):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        if filename is None:
            filename = CLUSTER_PATHS["investment_cluster_report"]

        with pd.ExcelWriter(filename, engine="openpyxl") as writer:
            ReportGenerator._write_portfolio_summary(writer, portfolios)
            ReportGenerator._write_portfolio_details(writer, portfolios)
            ReportGenerator._write_cluster_profiles(writer, cluster_profiles)
            ReportGenerator._write_all_companies(writer, df_original)

        print(f"   ‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

    @staticmethod
    def _write_portfolio_summary(writer, portfolios):
        """–ó–∞–ø–∏—Å—å —Å–≤–æ–¥–∫–∏ –ø–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è–º"""
        if portfolios:
            summary_data = []
            for name, pm in portfolios.items():
                summary_data.append(
                    {
                        CLUSTER_REPORT.COL_PORTFOLIO: name,
                        CLUSTER_REPORT.COL_RETURN: f"{pm.metrics.expected_return:.2%}",
                        CLUSTER_REPORT.COL_RISK: f"{pm.metrics.risk:.2%}",
                        CLUSTER_REPORT.COL_SHARPE: f"{pm.metrics.sharpe_ratio:.2f}",
                        CLUSTER_REPORT.COL_DIVERSIFICATION: f"{pm.metrics.diversification_score:.2%}",
                        CLUSTER_REPORT.COL_N_POSITIONS: len(pm.df),
                    }
                )

            pd.DataFrame(summary_data).to_excel(
                writer, sheet_name=CLUSTER_FILES.SHEET_PORTFOLIO_SUMMARY, index=False
            )

    @staticmethod
    def _write_portfolio_details(writer, portfolios):
        """–ó–∞–ø–∏—Å—å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –ø–æ—Ä—Ç—Ñ–µ–ª—é"""
        for name, pm in portfolios.items():
            portfolio_df = pm.df.sort_values("Weight", ascending=False)
            cols = [
                "Ticker",
                "Company",
                "Sector",
                "Cluster",
                "Weight",
                "Expected_Return",
                "Risk",
                "PE",
                "PB",
                "ROE",
                "Div_Yield",
                "Value_Score",
                "Quality_Score",
            ]
            available_cols = [c for c in cols if c in portfolio_df.columns]

            portfolio_display = portfolio_df[available_cols].copy()
            sheet_name = f"–ü–æ—Ä—Ç—Ñ–µ–ª—å_{name[:12]}"
            portfolio_display.to_excel(writer, sheet_name=sheet_name, index=False)

    @staticmethod
    def _write_cluster_profiles(writer, cluster_profiles):
        """–ó–∞–ø–∏—Å—å –ø—Ä–æ—Ñ–∏–ª–µ–π –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        if cluster_profiles:
            cluster_data = []
            for profile in cluster_profiles:
                cluster_data.append(
                    {
                        CLUSTER_REPORT.COL_CLUSTER: profile.cluster_id,
                        CLUSTER_REPORT.COL_CLUSTER_SIZE: profile.size,
                        CLUSTER_REPORT.COL_AVG_PE: f"{profile.avg_pe:.1f}",
                        CLUSTER_REPORT.COL_AVG_PB: f"{profile.avg_pb:.2f}",
                        CLUSTER_REPORT.COL_AVG_ROE: f"{profile.avg_roe:.1f}%",
                        CLUSTER_REPORT.COL_AVG_DIV: f"{profile.avg_div_yield:.1f}%",
                        CLUSTER_REPORT.COL_RISK_CLUSTER: f"{profile.avg_risk:.1%}",
                        CLUSTER_REPORT.COL_DESCRIPTION: profile.description,
                        CLUSTER_REPORT.COL_RECOMMENDATION: profile.recommendation,
                    }
                )

            pd.DataFrame(cluster_data).to_excel(
                writer, sheet_name=CLUSTER_FILES.SHEET_CLUSTERS, index=False
            )

    @staticmethod
    def _write_all_companies(writer, df_original):
        """–ó–∞–ø–∏—Å—å –≤—Å–µ—Ö –∫–æ–º–ø–∞–Ω–∏–π —Å –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏"""
        df_original.to_excel(
            writer, sheet_name=CLUSTER_FILES.SHEET_ALL_COMPANIES, index=False
        )


# ==================== –û–°–ù–û–í–ù–û–ô –ü–ê–ô–ü–õ–ê–ô–ù ====================


def create_model_cluster_analysis_with_portfolio():
    """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–µ–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π"""

    print(CLUSTER_FORMAT.SEPARATOR)
    print("üöÄ –ó–ê–ü–£–°–ö –ö–õ–ê–°–¢–ï–†–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –ò –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò –ü–û–†–¢–§–ï–õ–Ø")
    print(CLUSTER_FORMAT.SEPARATOR)

    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

    if not os.path.exists(CLUSTER_PATHS["data_path"]):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {CLUSTER_PATHS['data_path']}")
        return None, None

    loader = DataLoader()
    df = loader.load_and_clean_data(CLUSTER_PATHS["data_path"])

    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(df)}")

    # –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    print("\nüî¨ –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")

    cluster_features = list(CLUSTER.DEFAULT_CLUSTER_FEATURES)
    available_features = [f for f in cluster_features if f in df.columns]

    print(f"   –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {available_features}")

    df_cluster = df[df[available_features].notna().all(axis=1)].copy()
    print(f"   –î–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {len(df_cluster)} –∫–æ–º–ø–∞–Ω–∏–π")

    if len(df_cluster) < CLUSTER.MIN_DATA_FOR_CLUSTERING:
        print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
        return None, None

    cluster_analyzer = ClusterAnalyzer()
    optimal_k, _ = cluster_analyzer.find_optimal_clusters(
        df_cluster, available_features, max_clusters=CLUSTER.MAX_CLUSTERS
    )

    df_clustered = cluster_analyzer.fit_predict(
        df_cluster, available_features, n_clusters=optimal_k
    )

    cluster_profiles = cluster_analyzer.analyze_clusters(df_clustered)

    print(f"   –°–æ–∑–¥–∞–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(cluster_profiles)}")
    for profile in cluster_profiles:
        print(
            f"   –ö–ª–∞—Å—Ç–µ—Ä {profile.cluster_id}: {profile.size} –∫–æ–º–ø–∞–Ω–∏–π - {profile.description}"
        )

    cluster_analyzer.plot_clusters(df_clustered, CLUSTER_PATHS["cluster_analysis"])

    # –®–∞–≥ 3: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    df_with_clusters = df.merge(
        df_clustered[["Ticker", "Cluster", "PCA1", "PCA2"]], on="Ticker", how="left"
    )

    # –®–∞–≥ 4: –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    print("\nüìä –†–∞—Å—á–µ—Ç —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫...")

    df_with_clusters["Value_Score"] = df_with_clusters.apply(
        FundamentalAnalyzer.calculate_value_score, axis=1
    )
    df_with_clusters["Quality_Score"] = df_with_clusters.apply(
        FundamentalAnalyzer.calculate_quality_score, axis=1
    )
    df_with_clusters["Growth_Score"] = df_with_clusters.apply(
        FundamentalAnalyzer.calculate_growth_score, axis=1
    )
    df_with_clusters["Income_Score"] = df_with_clusters.apply(
        FundamentalAnalyzer.calculate_income_score, axis=1
    )
    df_with_clusters["Expected_Return"] = df_with_clusters.apply(
        FundamentalAnalyzer.calculate_expected_return, axis=1
    )
    df_with_clusters["Risk"] = df_with_clusters.apply(
        FundamentalAnalyzer.calculate_risk, axis=1
    )

    # –®–∞–≥ 5: –û—Ç–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    print("\nüéØ –û—Ç–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ –ø–æ—Ä—Ç—Ñ–µ–ª–∏...")

    candidates = df_with_clusters[
        (df_with_clusters["Cluster"].notna())
        & (df_with_clusters["Market_Cap"].fillna(0) > PORTFOLIO_CLUSTER.MIN_MARKET_CAP)
        & (
            df_with_clusters["Expected_Return"].fillna(0)
            > PORTFOLIO_CLUSTER.MIN_EXPECTED_RETURN
        )
        & (df_with_clusters["Risk"].fillna(1) < PORTFOLIO_CLUSTER.MAX_RISK_THRESHOLD)
    ].copy()

    if len(candidates) == 0:
        print("‚ö†Ô∏è –ù–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, —Ä–∞—Å—à–∏—Ä—è–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–∏...")
        candidates = df_with_clusters[
            (df_with_clusters["Cluster"].notna())
            & (
                df_with_clusters["Market_Cap"].fillna(0)
                > PORTFOLIO_CLUSTER.MIN_MARKET_CAP_LOOSE
            )
        ].copy()

    if len(candidates) > PORTFOLIO_CLUSTER.MAX_CANDIDATES:
        candidates["Total_Score"] = (
            candidates["Value_Score"] * PORTFOLIO_CLUSTER.VALUE_SCORE_WEIGHT
            + candidates["Quality_Score"] * PORTFOLIO_CLUSTER.QUALITY_SCORE_WEIGHT
            + candidates["Income_Score"] * PORTFOLIO_CLUSTER.INCOME_SCORE_WEIGHT
            + candidates["Expected_Return"]
            * PORTFOLIO_CLUSTER.RETURN_SCORE_MULTIPLIER
            * PORTFOLIO_CLUSTER.RETURN_SCORE_WEIGHT
        )
        candidates = candidates.nlargest(
            PORTFOLIO_CLUSTER.MAX_CANDIDATES, "Total_Score"
        )

    print(f"   –û—Ç–æ–±—Ä–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(candidates)}")

    if len(candidates) < CLUSTER.MIN_CLUSTERS:
        print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è")
        return None, None

    # –®–∞–≥ 6: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π
    print("\nüìê –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º...")

    optimizer = PortfolioOptimizer(
        min_weight=PORTFOLIO_CLUSTER.MIN_WEIGHT_LOOSE,
        max_weight=PORTFOLIO_CLUSTER.MAX_WEIGHT_LOOSE,
    )

    portfolio_managers = {}
    weights_dict = optimizer.optimize_multi_portfolio(
        candidates.reset_index(drop=True), list(PORTFOLIO_CLUSTER.DEFAULT_STRATEGIES)
    )

    for port_name, weights in weights_dict.items():
        pm = PortfolioManager(port_name, candidates.reset_index(drop=True), weights)
        portfolio_managers[port_name] = pm
        print(
            f"   ‚úÖ {port_name}: –®–∞—Ä–ø={pm.metrics.sharpe_ratio:.2f}, "
            f"–î–æ—Ö={pm.metrics.expected_return:.1%}, –†–∏—Å–∫={pm.metrics.risk:.1%}"
        )

    # –®–∞–≥ 7: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    print("\nüìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")

    if portfolio_managers:
        PortfolioVisualizer.plot_portfolio_comparison(
            portfolio_managers, CLUSTER_PATHS["portfolio_comparison"]
        )

        if "–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π" in portfolio_managers:
            PortfolioVisualizer.plot_cluster_portfolio_allocation(
                portfolio_managers["–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π"], CLUSTER_PATHS["cluster_allocation"]
            )

    # –®–∞–≥ 8: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
    print("\nüìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤...")

    ReportGenerator.generate_full_report(
        portfolio_managers,
        cluster_profiles,
        df_with_clusters,
        CLUSTER_PATHS["investment_cluster_report"],
    )

    df_with_clusters.to_excel(CLUSTER_PATHS["clustered_companies"], index=False)

    # –®–∞–≥ 9: –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\n" + CLUSTER_FORMAT.SEPARATOR)
    print("üéØ –ò–¢–û–ì–û–í–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
    print(CLUSTER_FORMAT.SEPARATOR)

    if portfolio_managers:
        best_portfolio = max(
            portfolio_managers.values(), key=lambda p: p.metrics.sharpe_ratio
        )

        print(f"\nüèÜ –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ô –ü–û–†–¢–§–ï–õ–¨: {best_portfolio.name}")
        print(f"   –û–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {best_portfolio.metrics.expected_return:.1%}")
        print(f"   –†–∏—Å–∫: {best_portfolio.metrics.risk:.1%}")
        print(f"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {best_portfolio.metrics.sharpe_ratio:.2f}")

        print(
            f"\nüìà –¢–û–ü-{PORTFOLIO_CLUSTER.TOP_POSITIONS_RECOMMEND} –ü–û–ó–ò–¶–ò–ô –í –ü–û–†–¢–§–ï–õ–ï:"
        )
        top_n = min(PORTFOLIO_CLUSTER.TOP_POSITIONS_RECOMMEND, len(best_portfolio.df))
        top_positions = best_portfolio.get_top_positions(top_n)

        for _, row in top_positions.iterrows():
            ticker = row.get("Ticker", "N/A")
            weight = row.get("Weight", 0)
            company = row.get("Company", "")[:30]
            pe = row.get("PE", 0)
            pb = row.get("PB", 0)
            roe = row.get("ROE", 0)
            print(f"   ‚Ä¢ {ticker}: {weight:.1%} - {company}")
            print(f"     P/E: {pe:.1f}, P/B: {pb:.2f}, ROE: {roe:.1f}%")

    print("\n" + CLUSTER_FORMAT.SEPARATOR)
    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
    print(f"   ‚Ä¢ {CLUSTER_FILES.INVESTMENT_CLUSTER_REPORT} - –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç")
    print(f"   ‚Ä¢ {CLUSTER_FILES.CLUSTERED_COMPANIES_FILE} - –∫–æ–º–ø–∞–Ω–∏–∏ —Å –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏")
    print(f"   ‚Ä¢ {CLUSTER_FILES.CLUSTER_ANALYSIS_FILE} - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
    print(f"   ‚Ä¢ {CLUSTER_FILES.PORTFOLIO_COMPARISON_FILE} - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π")
    print(CLUSTER_FORMAT.SEPARATOR)

    return portfolio_managers, cluster_profiles


# ==================== –ó–ê–ü–£–°–ö ====================

if __name__ == "__main__":
    portfolios, clusters = create_model_cluster_analysis_with_portfolio()
