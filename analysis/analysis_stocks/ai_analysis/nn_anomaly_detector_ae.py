import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from scipy.optimize import minimize
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler
import warnings

# –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Å—Ç–∞–Ω—Ç
from ae_constants import (
    AE_ARCH,
    AE_THRESHOLD,
    AE_PORTFOLIO,
    AE_SCORING,
    AE_FEATURE,
    AE_COLUMN,
    AE_FILES,
    AE_FORMAT,
    AE_REC,
)

warnings.filterwarnings("ignore")


# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ü–£–¢–ï–ô ====================


class AEPathConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""

    @staticmethod
    def setup_directories():
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        nn_ae_detector_dir = f"{parent_dir}/../data/nn_ae_anomaly_detector"
        os.makedirs(nn_ae_detector_dir, exist_ok=True)

        return {
            "parent_dir": parent_dir,
            "nn_ae_detector_dir": nn_ae_detector_dir,
            "input_file": f"{parent_dir}/../data/fundamentals_shares.xlsx",
            "output_file": f"{nn_ae_detector_dir}/{AE_FILES.AE_PORTFOLIO_RESULTS}",
            "ae_anomaly_file": f"{nn_ae_detector_dir}/{AE_FILES.AE_ANOMALY_ANALYSIS}",
            "ae_portfolio_comparison": f"{nn_ae_detector_dir}/{AE_FILES.AE_PORTFOLIO_COMPARISON}",
            "ae_portfolio_optimal": f"{nn_ae_detector_dir}/{AE_FILES.AE_PORTFOLIO_OPTIMAL}",
            "ae_portfolio_summary": f"{nn_ae_detector_dir}/{AE_FILES.AE_PORTFOLIO_SUMMARY}",
        }


AE_PATHS = AEPathConfig.setup_directories()


# ==================== –ö–õ–ê–°–°–´ –î–ê–ù–ù–´–• ====================


@dataclass
class PortfolioMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""

    expected_return: float
    risk: float
    sharpe_ratio: float
    diversification_score: float
    var_95: float
    cvar_95: float


@dataclass
class StockRecommendation:
    """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ –∞–∫—Ü–∏–∏"""

    ticker: str
    name: str
    undervalued_score: float
    anomaly_score: float
    expected_return: float
    volatility: float
    allocation_max: float
    risk_category: str


# ==================== –ö–õ–ê–°–° –ê–í–¢–û–≠–ù–ö–û–î–ï–†–ê ====================


class AnomalyDetectorAE(nn.Module):
    """–ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä–∞—Ö"""

    def __init__(self, input_size):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_size, AE_ARCH.ENCODER_LAYER_1),
            nn.ReLU(),
            nn.Linear(AE_ARCH.ENCODER_LAYER_1, AE_ARCH.ENCODER_LAYER_2),
            nn.ReLU(),
            nn.Linear(AE_ARCH.ENCODER_LAYER_2, AE_ARCH.ENCODER_LAYER_3),
            nn.ReLU(),
            nn.Linear(AE_ARCH.ENCODER_LAYER_3, AE_ARCH.ENCODER_LAYER_4),
        )

        self.decoder = nn.Sequential(
            nn.Linear(AE_ARCH.ENCODER_LAYER_4, AE_ARCH.DECODER_LAYER_1),
            nn.ReLU(),
            nn.Linear(AE_ARCH.DECODER_LAYER_1, AE_ARCH.DECODER_LAYER_2),
            nn.ReLU(),
            nn.Linear(AE_ARCH.DECODER_LAYER_2, AE_ARCH.DECODER_LAYER_3),
            nn.ReLU(),
            nn.Linear(AE_ARCH.DECODER_LAYER_3, input_size),
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return encoded, decoded


# ==================== –ö–õ–ê–°–° –û–ü–¢–ò–ú–ò–ó–ê–¢–û–†–ê –ü–û–†–¢–§–ï–õ–Ø ====================


class AEPortfolioOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""

    def __init__(
        self,
        min_weight: float = None,
        max_weight: float = None,
        risk_free_rate: float = None,
    ):
        self.min_weight = min_weight or AE_PORTFOLIO.MIN_WEIGHT
        self.max_weight = max_weight or AE_PORTFOLIO.MAX_WEIGHT
        self.risk_free_rate = risk_free_rate or AE_PORTFOLIO.RISK_FREE_RATE

    def calculate_expected_return(self, row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""
        base_return = AE_PORTFOLIO.BASE_RETURN

        undervalued_score = row.get("AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å", 0.5)
        base_return += undervalued_score * AE_PORTFOLIO.UNDERVALUED_SCORE_PREMIUM

        if row.get("AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ", False):
            base_return += AE_PORTFOLIO.TOP_UNDERVALUED_PREMIUM

        if row.get("AE_–ê–Ω–æ–º–∞–ª–∏—è", False):
            base_return += AE_PORTFOLIO.ANOMALY_PENALTY
        if row.get("AE_–°–∏–ª—å–Ω–∞—è_–∞–Ω–æ–º–∞–ª–∏—è", False):
            base_return += AE_PORTFOLIO.STRONG_ANOMALY_PENALTY

        if pd.notna(row.get("P_E")) and row["P_E"] > 0:
            if row["P_E"] < AE_THRESHOLD.PE_STRONG_UNDERVALUED:
                base_return += AE_PORTFOLIO.PE_STRONG_PREMIUM
            elif row["P_E"] < AE_THRESHOLD.PE_UNDERVALUED:
                base_return += AE_PORTFOLIO.PE_MEDIUM_PREMIUM
            elif row["P_E"] > AE_THRESHOLD.PE_OVERVALUED:
                base_return += AE_PORTFOLIO.PE_OVER_PENALTY

        if pd.notna(row.get("P_B")) and row["P_B"] > 0:
            if row["P_B"] < AE_THRESHOLD.PB_STRONG_UNDERVALUED:
                base_return += AE_PORTFOLIO.PB_STRONG_PREMIUM
            elif row["P_B"] < AE_THRESHOLD.PB_UNDERVALUED:
                base_return += AE_PORTFOLIO.PB_MEDIUM_PREMIUM

        if pd.notna(row.get("ROE")):
            if row["ROE"] > AE_THRESHOLD.ROE_HIGH:
                base_return += AE_PORTFOLIO.ROE_HIGH_PREMIUM
            elif row["ROE"] > AE_THRESHOLD.ROE_MEDIUM:
                base_return += AE_PORTFOLIO.ROE_MEDIUM_PREMIUM

        if pd.notna(row.get("dividend_yield")):
            base_return += row["dividend_yield"] * AE_PORTFOLIO.DIVIDEND_PREMIUM_FACTOR
        elif pd.notna(row.get("Averange_dividend_yield")):
            div_yield = row["Averange_dividend_yield"] / 100
            base_return += div_yield * AE_PORTFOLIO.DIVIDEND_PREMIUM_FACTOR

        return max(AE_PORTFOLIO.MIN_RETURN, min(AE_PORTFOLIO.MAX_RETURN, base_return))

    def calculate_volatility(self, row: pd.Series) -> float:
        """–†–∞—Å—á–µ—Ç –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""
        base_vol = AE_PORTFOLIO.BASE_VOLATILITY

        recon_error = row.get("AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", 0.1)
        base_vol += recon_error * AE_PORTFOLIO.ERROR_VOL_FACTOR

        if row.get("AE_–ê–Ω–æ–º–∞–ª–∏—è", False):
            base_vol += AE_PORTFOLIO.ANOMALY_VOL_PENALTY
        if row.get("AE_–°–∏–ª—å–Ω–∞—è_–∞–Ω–æ–º–∞–ª–∏—è", False):
            base_vol += AE_PORTFOLIO.STRONG_ANOMALY_VOL_PENALTY

        if row.get("AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ", False):
            base_vol += AE_PORTFOLIO.TOP_UNDERVALUED_VOL_BONUS

        if pd.notna(row.get("–ë–µ—Ç–∞")):
            beta = row["–ë–µ—Ç–∞"]
            base_vol *= (
                AE_PORTFOLIO.BETA_VOL_FACTOR_MIN
                + AE_PORTFOLIO.BETA_VOL_FACTOR_MAX * beta
            )

        if pd.notna(row.get("debt_capital")):
            debt = row["debt_capital"]
            base_vol *= (
                AE_PORTFOLIO.DEBT_VOL_FACTOR_MIN
                + AE_PORTFOLIO.DEBT_VOL_FACTOR_MAX
                * (debt / AE_PORTFOLIO.DEBT_NORMALIZATION)
            )

        return max(
            AE_PORTFOLIO.MIN_VOLATILITY, min(AE_PORTFOLIO.MAX_VOLATILITY, base_vol)
        )

    def create_covariance_matrix(self, df: pd.DataFrame) -> np.ndarray:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π"""
        n = len(df)
        cov_matrix = np.zeros((n, n))
        risks = df["AE_Volatility"].values

        recon_errors = df["AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"].values
        error_median = np.median(recon_errors)

        for i in range(n):
            for j in range(n):
                if i == j:
                    cov_matrix[i, j] = risks[i] ** 2
                else:
                    error_diff = abs(recon_errors[i] - recon_errors[j])
                    if error_diff < error_median * AE_PORTFOLIO.ERROR_DIFF_LOW:
                        corr = AE_PORTFOLIO.ERROR_CORR_HIGH
                    elif error_diff < error_median * AE_PORTFOLIO.ERROR_DIFF_MEDIUM:
                        corr = AE_PORTFOLIO.ERROR_CORR_MEDIUM
                    else:
                        corr = AE_PORTFOLIO.ERROR_CORR_LOW
                    cov_matrix[i, j] = corr * risks[i] * risks[j]

        return cov_matrix

    def calculate_portfolio_metrics(
        self, weights: np.ndarray, expected_returns: np.ndarray, cov_matrix: np.ndarray
    ) -> PortfolioMetrics:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        port_return = np.sum(expected_returns * weights)
        port_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        sharpe = (port_return - self.risk_free_rate) / port_risk if port_risk > 0 else 0

        var_95 = port_return - AE_PORTFOLIO.VAR_95_COEFF * port_risk
        cvar_95 = port_return - AE_PORTFOLIO.CVAR_95_COEFF * port_risk

        hhi = np.sum(weights**2)
        n = len(weights)
        diversification = 1 - (hhi - 1 / n) / (1 - 1 / n) if n > 1 else 0

        return PortfolioMetrics(
            expected_return=port_return,
            risk=port_risk,
            sharpe_ratio=sharpe,
            diversification_score=diversification,
            var_95=var_95,
            cvar_95=cvar_95,
        )

    def optimize_portfolio(
        self,
        expected_returns: np.ndarray,
        cov_matrix: np.ndarray,
        undervalued_boost: bool = True,
    ) -> Dict:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ü–µ–ª—è–º–∏"""
        n = len(expected_returns)

        def neg_sharpe(weights):
            port_return = np.sum(expected_returns * weights)
            port_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
            return (
                -(port_return - self.risk_free_rate) / port_risk if port_risk > 0 else 0
            )

        def portfolio_risk(weights):
            return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))

        def negative_return(weights):
            return -np.sum(expected_returns * weights)

        constraints = [{"type": "eq", "fun": lambda x: np.sum(x) - 1}]
        bounds = tuple((self.min_weight, self.max_weight) for _ in range(n))
        init_guess = np.array([1 / n] * n)

        result_sharpe = minimize(
            neg_sharpe,
            init_guess,
            method="SLSQP",
            bounds=bounds,
            constraints=constraints,
            options={"maxiter": AE_PORTFOLIO.OPTIMIZER_MAX_ITER},
        )

        result_min_risk = minimize(
            portfolio_risk,
            init_guess,
            method="SLSQP",
            bounds=bounds,
            constraints=constraints,
            options={"maxiter": AE_PORTFOLIO.OPTIMIZER_MAX_ITER},
        )

        result_max_return = minimize(
            negative_return,
            init_guess,
            method="SLSQP",
            bounds=bounds,
            constraints=constraints,
            options={"maxiter": AE_PORTFOLIO.OPTIMIZER_MAX_ITER},
        )

        if undervalued_boost:
            combined_weights = (
                AE_PORTFOLIO.SHARPE_WEIGHT_BOOST * result_sharpe.x
                + AE_PORTFOLIO.MIN_RISK_WEIGHT_BOOST * result_min_risk.x
                + AE_PORTFOLIO.MAX_RETURN_WEIGHT_BOOST * result_max_return.x
            )
        else:
            combined_weights = (
                AE_PORTFOLIO.SHARPE_WEIGHT_NORMAL * result_sharpe.x
                + AE_PORTFOLIO.MIN_RISK_WEIGHT_NORMAL * result_min_risk.x
                + AE_PORTFOLIO.MAX_RETURN_WEIGHT_NORMAL * result_max_return.x
            )

        combined_weights = combined_weights / combined_weights.sum()

        return {
            "sharpe_weights": result_sharpe.x,
            "min_risk_weights": result_min_risk.x,
            "max_return_weights": result_max_return.x,
            "combined_weights": combined_weights,
            "cov_matrix": cov_matrix,
        }

    def create_ae_based_portfolios(self, df: pd.DataFrame) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""
        portfolios = {}

        undervalued = df[df["AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] == True].copy()
        if len(undervalued) > 0:
            weights = self._score_weighted_allocation(undervalued, "AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å")
            portfolios["–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] = (undervalued, weights)

        no_anomalies = df[df["AE_–ê–Ω–æ–º–∞–ª–∏—è"] == False].copy()
        if len(no_anomalies) > 0:
            weights = self._risk_weighted_allocation(no_anomalies)
            portfolios["–ë–µ–∑_–∞–Ω–æ–º–∞–ª–∏–π"] = (no_anomalies, weights)

        combined = df[
            (df["AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] == True)
            | (
                (df["AE_–ê–Ω–æ–º–∞–ª–∏—è"] == False)
                & (df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"] > df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"].median())
            )
        ].copy()
        if len(combined) > 0:
            weights = self._combined_score_allocation(combined)
            portfolios["–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π"] = (combined, weights)

        dividend = df[
            (df["AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] == True)
            & (df["dividend_yield"].fillna(0) > AE_PORTFOLIO.DIVIDEND_YIELD_THRESHOLD)
        ].copy()
        if len(dividend) > 0:
            weights = self._dividend_weighted_allocation(dividend)
            portfolios["–î–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–π"] = (dividend, weights)

        return portfolios

    def _score_weighted_allocation(
        self, df: pd.DataFrame, score_col: str
    ) -> np.ndarray:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫–æ—Ä–∞"""
        scores = df[score_col].values
        weights = scores / scores.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()

    def _risk_weighted_allocation(self, df: pd.DataFrame) -> np.ndarray:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∏—Å–∫–∞"""
        risks = df["AE_Volatility"].values
        inv_risks = 1 / risks
        weights = inv_risks / inv_risks.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()

    def _dividend_weighted_allocation(self, df: pd.DataFrame) -> np.ndarray:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–≤–∏–¥–µ–Ω–¥–Ω–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏"""
        div_yield = df["dividend_yield"].fillna(0).values
        weights = div_yield / div_yield.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()

    def _combined_score_allocation(self, df: pd.DataFrame) -> np.ndarray:
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å + 1/—Ä–∏—Å–∫)"""
        scores = df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"].values
        inv_risks = 1 / df["AE_Volatility"].values

        scores_norm = scores / scores.sum()
        risks_norm = inv_risks / inv_risks.sum()

        weights = (
            AE_PORTFOLIO.UNDERVALUED_WEIGHT * scores_norm
            + AE_PORTFOLIO.RISK_WEIGHT * risks_norm
        )
        weights = weights / weights.sum()
        weights = np.clip(weights, self.min_weight, self.max_weight)
        return weights / weights.sum()


# ==================== –ö–õ–ê–°–° –£–ü–†–ê–í–õ–ï–ù–ò–Ø –ü–û–†–¢–§–ï–õ–ï–ú ====================


class AEPortfolioManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""

    def __init__(
        self,
        name: str,
        df: pd.DataFrame,
        weights: np.ndarray,
        optimizer: AEPortfolioOptimizer,
    ):
        self.name = name
        self.df = df.copy()
        self.weights = weights
        self.df["Weight"] = weights
        self.optimizer = optimizer

        expected_returns = self.df["AE_Expected_Return"].values
        cov_matrix = optimizer.create_covariance_matrix(self.df)

        self.metrics = optimizer.calculate_portfolio_metrics(
            weights, expected_returns, cov_matrix
        )

    def get_top_positions(self, n: int = None) -> pd.DataFrame:
        """–¢–æ–ø –ø–æ–∑–∏—Ü–∏–π –ø–æ –≤–µ—Å—É"""
        n = n or AE_FORMAT.TOP_POSITIONS_SUMMARY
        n = min(n, len(self.df))
        top_idx = np.argsort(self.weights)[::-1][:n]
        return self.df.iloc[top_idx].copy()

    def get_risk_contribution(self) -> pd.Series:
        """–í–∫–ª–∞–¥ –≤ —Ä–∏—Å–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        if len(self.df) == 0:
            return pd.Series()

        weights = self.weights
        risks = self.df["AE_Volatility"].values
        risk_contribution = weights * risks / np.sum(weights * risks)

        tickers = self.df.get("–¢–∏–∫–µ—Ä", self.df.index)
        return pd.Series(risk_contribution, index=tickers)

    def get_anomaly_allocation(self) -> Dict:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ç–∞—Ç—É—Å—É –∞–Ω–æ–º–∞–ª–∏–π"""
        anomaly_mask = self.df["AE_–ê–Ω–æ–º–∞–ª–∏—è"] == True
        top_mask = self.df["AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] == True

        return {
            AE_REC.CATEGORY_ANOMALIES: (
                self.weights[anomaly_mask].sum() if anomaly_mask.any() else 0
            ),
            AE_REC.CATEGORY_TOP_UNDERVALUED: (
                self.weights[top_mask].sum() if top_mask.any() else 0
            ),
            AE_REC.CATEGORY_NORMAL: self.weights[~(anomaly_mask | top_mask)].sum(),
        }


# ==================== –ö–õ–ê–°–° –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò ====================


class AEPortfolioVisualizer:
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""

    @staticmethod
    def plot_portfolio_summary(
        portfolio_manager: AEPortfolioManager,
        filename: str = None,
    ):
        """–°–≤–æ–¥–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        if filename is None:
            filename = (
                f"{AE_PATHS['ae_portfolio_optimal']}_{portfolio_manager.name}.png"
            )

        fig, axes = plt.subplots(2, 2, figsize=AE_FILES.FIGURE_SIZE_SUMMARY)

        AEPortfolioVisualizer._plot_anomaly_allocation(portfolio_manager, axes[0, 0])
        AEPortfolioVisualizer._plot_risk_return_scatter(portfolio_manager, axes[0, 1])
        AEPortfolioVisualizer._plot_risk_contribution(portfolio_manager, axes[1, 0])
        AEPortfolioVisualizer._plot_portfolio_metrics(portfolio_manager, axes[1, 1])

        plt.suptitle(
            f"–ü–æ—Ä—Ç—Ñ–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞: {portfolio_manager.name}",
            fontsize=AE_FORMAT.TITLE_FONT_SIZE,
            fontweight="bold",
        )
        plt.tight_layout()
        plt.savefig(filename, dpi=AE_FILES.DPI, bbox_inches="tight")
        plt.show()

    @staticmethod
    def _plot_anomaly_allocation(pm: AEPortfolioManager, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Å—Ç–∞—Ç—É—Å—É –∞–Ω–æ–º–∞–ª–∏–π"""
        anomaly_alloc = pm.get_anomaly_allocation()

        if sum(anomaly_alloc.values()) > 0:
            labels = []
            sizes = []
            colors = []

            for key, value in anomaly_alloc.items():
                if value > AE_THRESHOLD.SIGNIFICANT_WEIGHT_THRESHOLD:
                    labels.append(key)
                    sizes.append(value)
                    colors.append(
                        AE_REC.CATEGORY_COLORS.get(key, AE_FORMAT.COLOR_NORMAL)
                    )

            if sizes:
                ax.pie(
                    sizes,
                    labels=labels,
                    autopct=AE_FORMAT.MATPLOTLIB_PERCENT,
                    startangle=90,
                    colors=colors,
                    explode=[AE_FORMAT.PIE_EXPLODE_FACTOR] * len(sizes),
                )
                ax.set_title(
                    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º",
                    fontsize=AE_FORMAT.SUBTITLE_FONT_SIZE,
                    fontweight="bold",
                )

    @staticmethod
    def _plot_risk_return_scatter(pm: AEPortfolioManager, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∏—Å–∫-–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –ø–æ–∑–∏—Ü–∏–π"""
        scatter = ax.scatter(
            pm.df["AE_Volatility"],
            pm.df["AE_Expected_Return"],
            s=pm.weights * AE_FORMAT.WEIGHT_SCALE_FACTOR,
            c=pm.df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"],
            cmap=AE_FORMAT.COLOR_CONFIDENCE_CMAP,
            alpha=0.6,
            edgecolors="black",
            linewidths=0.5,
        )

        top_n = min(AE_FORMAT.TOP_POSITIONS_SUMMARY, len(pm.df))
        top_positions = pm.get_top_positions(top_n)

        for _, row in top_positions.iterrows():
            ax.annotate(
                row.get("–¢–∏–∫–µ—Ä", "N/A"),
                (row["AE_Volatility"], row["AE_Expected_Return"]),
                xytext=(5, 5),
                textcoords="offset points",
                fontsize=AE_FORMAT.ANNOTATION_FONT_SIZE,
                fontweight="bold",
            )

        ax.scatter(
            pm.metrics.risk,
            pm.metrics.expected_return,
            s=AE_FORMAT.SCATTER_POINT_SIZE_PORTFOLIO,
            c=AE_FORMAT.COLOR_OPTIMAL_MARKER,
            marker="*",
            edgecolors="black",
            linewidths=2,
            label=f"–ü–æ—Ä—Ç—Ñ–µ–ª—å (–®–∞—Ä–ø: {pm.metrics.sharpe_ratio:.2f})",
        )

        ax.set_xlabel("–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("–û–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "Risk-Return –ø—Ä–æ—Ñ–∏–ª—å",
            fontsize=AE_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        ax.grid(True, alpha=AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER / 5)
        ax.legend()

        plt.colorbar(scatter, ax=ax, label="–°–∫–æ—Ä –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç–∏")

    @staticmethod
    def _plot_risk_contribution(pm: AEPortfolioManager, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∫–ª–∞–¥–∞ –≤ —Ä–∏—Å–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        risk_contrib = pm.get_risk_contribution()

        if len(risk_contrib) > 0:
            top_n = min(AE_FORMAT.TOP_RISK_CONTRIBUTION, len(risk_contrib))
            top_risk = risk_contrib.nlargest(top_n)

            colors = plt.cm.get_cmap(AE_FORMAT.COLOR_RISK_CONTRIBUTION_CMAP)(
                np.linspace(0.2, 0.8, len(top_risk))
            )
            bars = ax.barh(
                range(len(top_risk)), top_risk.values, color=colors, edgecolor="black"
            )

            ax.set_yticks(range(len(top_risk)))
            ax.set_yticklabels(top_risk.index)
            ax.set_xlabel("–í–∫–ª–∞–¥ –≤ —Ä–∏—Å–∫", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
            ax.set_title(
                "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞",
                fontsize=AE_FORMAT.SUBTITLE_FONT_SIZE,
                fontweight="bold",
            )
            ax.grid(True, alpha=AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER / 5, axis="x")

            for bar, value in zip(bars, top_risk.values):
                ax.text(
                    bar.get_width() + 0.01,
                    bar.get_y() + bar.get_height() / 2,
                    f"{value:.1%}",
                    ha="left",
                    va="center",
                    fontsize=AE_FORMAT.BAR_TEXT_FONT_SIZE,
                )

    @staticmethod
    def _plot_portfolio_metrics(pm: AEPortfolioManager, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        ax.axis("off")

        metrics_text = f"""
        üìä –ú–ï–¢–†–ò–ö–ò –ü–û–†–¢–§–ï–õ–Ø: {pm.name}
        
        –û–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {AE_FORMAT.PERCENT_FORMAT.format(pm.metrics.expected_return)}
        –†–∏—Å–∫ (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å): {AE_FORMAT.PERCENT_FORMAT.format(pm.metrics.risk)}
        –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {AE_FORMAT.FLOAT_FORMAT_2D.format(pm.metrics.sharpe_ratio)}
        
        üìà –†–ò–°–ö-–ú–ï–¢–†–ò–ö–ò
        VaR (95%): {AE_FORMAT.PERCENT_FORMAT.format(pm.metrics.var_95)}
        CVaR (95%): {AE_FORMAT.PERCENT_FORMAT.format(pm.metrics.cvar_95)}
        
        üìä –î–ò–í–ï–†–°–ò–§–ò–ö–ê–¶–ò–Ø
        –ò–Ω–¥–µ–∫—Å –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {AE_FORMAT.PERCENT_FORMAT.format(pm.metrics.diversification_score)}
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∑–∏—Ü–∏–π: {len(pm.df)}
        –ú–∞–∫—Å. –¥–æ–ª—è: {AE_FORMAT.PERCENT_FORMAT.format(pm.weights.max())}
        
        ü§ñ –ê–í–¢–û–≠–ù–ö–û–î–ï–†
        –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {AE_FORMAT.FLOAT_FORMAT_6D.format(pm.df['AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏'].mean())}
        –¢–æ–ø-–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö: {pm.df['AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ'].sum()}
        """

        ax.text(
            0.05,
            0.95,
            metrics_text,
            transform=ax.transAxes,
            fontsize=AE_FORMAT.LABEL_FONT_SIZE,
            verticalalignment="top",
            family="monospace",
            bbox=dict(
                boxstyle="round",
                facecolor=AE_FORMAT.COLOR_ANOMALY_BG,
                edgecolor=AE_FORMAT.COLOR_ANOMALY_EDGE,
                alpha=0.9,
            ),
        )

    @staticmethod
    def plot_portfolio_comparison(
        portfolios: Dict[str, AEPortfolioManager],
        filename: str = None,
    ):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π"""
        if not portfolios:
            return

        if filename is None:
            filename = AE_PATHS["ae_portfolio_comparison"]

        fig, axes = plt.subplots(2, 2, figsize=AE_FILES.FIGURE_SIZE_COMPARISON)

        names = []
        returns = []
        risks = []
        sharpes = []
        var_95s = []

        for name, pm in portfolios.items():
            names.append(name)
            returns.append(pm.metrics.expected_return)
            risks.append(pm.metrics.risk)
            sharpes.append(pm.metrics.sharpe_ratio)
            var_95s.append(pm.metrics.var_95)

        AEPortfolioVisualizer._plot_risk_return_comparison(
            axes[0, 0], names, returns, risks, sharpes
        )
        AEPortfolioVisualizer._plot_sharpe_comparison(axes[0, 1], names, sharpes)
        AEPortfolioVisualizer._plot_var_comparison(axes[1, 0], names, var_95s)
        AEPortfolioVisualizer._plot_best_portfolio_summary(axes[1, 1], portfolios)

        plt.suptitle(
            "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞",
            fontsize=AE_FORMAT.TITLE_FONT_SIZE,
            fontweight="bold",
        )
        plt.tight_layout()
        plt.savefig(filename, dpi=AE_FILES.DPI, bbox_inches="tight")
        plt.show()

    @staticmethod
    def _plot_risk_return_comparison(ax, names, returns, risks, sharpes):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∏—Å–∫-–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"""
        scatter = ax.scatter(
            risks,
            returns,
            c=sharpes,
            s=AE_FORMAT.SCATTER_POINT_SIZE_PORTFOLIO,
            cmap=AE_FORMAT.COLOR_SHARPE_CMAP,
            edgecolors="black",
            linewidths=1.5,
        )

        for i, name in enumerate(names):
            ax.annotate(
                name,
                (risks[i], returns[i]),
                xytext=(5, 5),
                textcoords="offset points",
                fontsize=AE_FORMAT.ANNOTATION_FONT_SIZE,
                fontweight="bold",
            )

        ax.set_xlabel("–†–∏—Å–∫", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "Risk-Return", fontsize=AE_FORMAT.SUBTITLE_FONT_SIZE, fontweight="bold"
        )
        ax.grid(True, alpha=AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER / 5)

        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞", fontsize=AE_FORMAT.LABEL_FONT_SIZE)

    @staticmethod
    def _plot_sharpe_comparison(ax, names, sharpes):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –®–∞—Ä–ø–∞"""
        sharpe_array = np.array(sharpes)
        sharpe_range = sharpe_array.max() - sharpe_array.min() + 0.001

        colors = plt.cm.get_cmap(AE_FORMAT.COLOR_SHARPE_CMAP)(
            (sharpe_array - sharpe_array.min()) / sharpe_range
        )

        bars = ax.bar(names, sharpes, color=colors, edgecolor="black")
        ax.axhline(
            y=1,
            color=AE_FORMAT.COLOR_OPTIMAL_MARKER,
            linestyle="--",
            alpha=0.5,
            label="–®–∞—Ä–ø = 1",
        )
        ax.set_xlabel("–ü–æ—Ä—Ç—Ñ–µ–ª—å", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –®–∞—Ä–ø–∞", fontsize=AE_FORMAT.SUBTITLE_FONT_SIZE, fontweight="bold"
        )
        ax.legend()
        ax.grid(True, alpha=AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER / 5, axis="y")

        for bar, value in zip(bars, sharpes):
            ax.text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.02,
                f"{value:.2f}",
                ha="center",
                va="bottom",
                fontsize=AE_FORMAT.BAR_TEXT_FONT_SIZE,
                fontweight="bold",
            )

    @staticmethod
    def _plot_var_comparison(ax, names, var_95s):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è Value at Risk"""
        bars = ax.bar(
            names, var_95s, color=AE_FORMAT.COLOR_DIVERSIFICATION, edgecolor="black"
        )
        ax.set_xlabel("–ü–æ—Ä—Ç—Ñ–µ–ª—å", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("VaR (95%)", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "Value at Risk", fontsize=AE_FORMAT.SUBTITLE_FONT_SIZE, fontweight="bold"
        )
        ax.grid(True, alpha=AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER / 5, axis="y")

        for bar, value in zip(bars, var_95s):
            ax.text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() - 0.01,
                f"{value:.1%}",
                ha="center",
                va="top",
                fontsize=AE_FORMAT.BAR_TEXT_FONT_SIZE,
                fontweight="bold",
                color="white",
            )

    @staticmethod
    def _plot_best_portfolio_summary(ax, portfolios):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª—É—á—à–µ–º –ø–æ—Ä—Ç—Ñ–µ–ª–µ"""
        ax.axis("off")

        best_portfolio = max(portfolios.values(), key=lambda p: p.metrics.sharpe_ratio)
        top_n = min(AE_FORMAT.TOP_POSITIONS_BEST, len(best_portfolio.df))
        top_positions = best_portfolio.get_top_positions(top_n)

        text = f"üèÜ –õ–£–ß–®–ò–ô –ü–û–†–¢–§–ï–õ–¨: {best_portfolio.name}\n\n"
        text += f"–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {AE_FORMAT.PERCENT_FORMAT.format(best_portfolio.metrics.expected_return)}\n"
        text += (
            f"–†–∏—Å–∫: {AE_FORMAT.PERCENT_FORMAT.format(best_portfolio.metrics.risk)}\n"
        )
        text += f"–®–∞—Ä–ø: {AE_FORMAT.FLOAT_FORMAT_2D.format(best_portfolio.metrics.sharpe_ratio)}\n"
        text += (
            f"VaR: {AE_FORMAT.PERCENT_FORMAT.format(best_portfolio.metrics.var_95)}\n\n"
        )
        text += f"üìà –¢–û–ü-{top_n} –ü–û–ó–ò–¶–ò–ô:\n"

        for _, row in top_positions.iterrows():
            ticker = row.get("–¢–∏–∫–µ—Ä", "N/A")
            weight = row.get("Weight", 0)
            score = row.get("AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å", 0)
            text += f"‚Ä¢ {ticker}: {AE_FORMAT.PERCENT_FORMAT.format(weight)} (—Å–∫–æ—Ä: {score:.2f})\n"

        ax.text(
            0.05,
            0.95,
            text,
            transform=ax.transAxes,
            fontsize=AE_FORMAT.LABEL_FONT_SIZE,
            verticalalignment="top",
            family="monospace",
            bbox=dict(
                boxstyle="round",
                facecolor=AE_FORMAT.COLOR_ANOMALY_BG,
                edgecolor=AE_FORMAT.COLOR_ANOMALY_EDGE,
                alpha=0.9,
            ),
        )

    @staticmethod
    def plot_anomaly_analysis(df: pd.DataFrame, filename: str = None):
        """–ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π –∏ –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö –∞–∫—Ü–∏–π"""
        if filename is None:
            filename = AE_PATHS["ae_anomaly_file"]

        fig, axes = plt.subplots(2, 2, figsize=AE_FILES.FIGURE_SIZE_ANOMALY)

        AEPortfolioVisualizer._plot_error_distribution(df, axes[0, 0])
        AEPortfolioVisualizer._plot_score_vs_error(df, axes[0, 1])
        AEPortfolioVisualizer._plot_pe_vs_pb(df, axes[1, 0])
        AEPortfolioVisualizer._plot_ae_statistics(df, axes[1, 1])

        plt.suptitle(
            "–ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π –∏ –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö –∞–∫—Ü–∏–π",
            fontsize=AE_FORMAT.TITLE_FONT_SIZE,
            fontweight="bold",
        )
        plt.tight_layout()
        plt.savefig(filename, dpi=AE_FILES.DPI, bbox_inches="tight")
        plt.show()

    @staticmethod
    def _plot_error_distribution(df: pd.DataFrame, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"""
        errors = df["AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"].dropna()

        ax.hist(
            errors,
            bins=AE_FORMAT.HISTOGRAM_BINS,
            edgecolor="black",
            alpha=0.7,
            color=AE_FORMAT.COLOR_ANOMALY_EDGE,
        )
        ax.axvline(
            errors.median(),
            color=AE_FORMAT.COLOR_OPTIMAL_MARKER,
            linestyle="--",
            label=f"–ú–µ–¥–∏–∞–Ω–∞: {errors.median():.4f}",
        )
        ax.axvline(
            errors.quantile(AE_THRESHOLD.Q3_PERCENTILE / 100)
            + AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER
            * (
                errors.quantile(AE_THRESHOLD.Q3_PERCENTILE / 100)
                - errors.quantile(AE_THRESHOLD.Q1_PERCENTILE / 100)
            ),
            color=AE_REC.CATEGORY_COLORS.get(AE_REC.CATEGORY_ANOMALIES),
            linestyle="--",
            label="–ü–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–π",
        )
        ax.set_xlabel("–û—à–∏–±–∫–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏",
            fontsize=AE_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        ax.legend()
        ax.grid(True, alpha=AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER / 5)

    @staticmethod
    def _plot_score_vs_error(df: pd.DataFrame, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç–∏ vs –æ—à–∏–±–∫–∞"""
        scatter = ax.scatter(
            df["AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"],
            df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"],
            c=df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"],
            cmap=AE_FORMAT.COLOR_CONFIDENCE_CMAP,
            s=AE_FORMAT.SCATTER_POINT_SIZE,
            alpha=0.6,
            edgecolors="black",
            linewidths=0.5,
        )

        top_mask = df["AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] == True
        if top_mask.any():
            ax.scatter(
                df[top_mask]["AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"],
                df[top_mask]["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"],
                s=AE_FORMAT.SCATTER_POINT_SIZE_LARGE,
                c=AE_REC.CATEGORY_COLORS.get(AE_REC.CATEGORY_TOP_UNDERVALUED),
                marker="*",
                edgecolors="black",
                linewidths=1,
                label="–¢–æ–ø-–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ",
            )

        ax.set_xlabel("–û—à–∏–±–∫–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("–°–∫–æ—Ä –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç–∏", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å vs –û—à–∏–±–∫–∞",
            fontsize=AE_FORMAT.SUBTITLE_FONT_SIZE,
            fontweight="bold",
        )
        ax.legend()
        ax.grid(True, alpha=AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER / 5)

        plt.colorbar(scatter, ax=ax, label="–°–∫–æ—Ä –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç–∏")

    @staticmethod
    def _plot_pe_vs_pb(df: pd.DataFrame, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è P/E vs P/B"""
        ax.scatter(
            df["P_B"],
            df["P_E"],
            c=df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"],
            cmap=AE_FORMAT.COLOR_CONFIDENCE_CMAP,
            s=AE_FORMAT.SCATTER_POINT_SIZE,
            alpha=0.6,
            edgecolors="black",
            linewidths=0.5,
        )

        top_mask = df["AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] == True
        if top_mask.any():
            ax.scatter(
                df[top_mask]["P_B"],
                df[top_mask]["P_E"],
                s=AE_FORMAT.SCATTER_POINT_SIZE_LARGE,
                c=AE_REC.CATEGORY_COLORS.get(AE_REC.CATEGORY_TOP_UNDERVALUED),
                marker="*",
                edgecolors="black",
                linewidths=1,
                label="–¢–æ–ø-–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ",
            )

        ax.set_xlabel("P/B", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_ylabel("P/E", fontsize=AE_FORMAT.AXIS_FONT_SIZE)
        ax.set_title(
            "P/E vs P/B", fontsize=AE_FORMAT.SUBTITLE_FONT_SIZE, fontweight="bold"
        )
        ax.legend()
        ax.grid(True, alpha=AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER / 5)

    @staticmethod
    def _plot_ae_statistics(df: pd.DataFrame, ax):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""
        ax.axis("off")

        top_mask = df["AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] == True

        text = f"""
        üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–í–¢–û–≠–ù–ö–û–î–ï–†–ê
        
        –í—Å–µ–≥–æ –∞–∫—Ü–∏–π: {len(df)}
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {df['AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏'].notna().sum()}
        
        üö® –ê–ù–û–ú–ê–õ–ò–ò
        –ê–Ω–æ–º–∞–ª–∏–∏ (IQR): {df['AE_–ê–Ω–æ–º–∞–ª–∏—è'].sum()}
        –°–∏–ª—å–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏: {df['AE_–°–∏–ª—å–Ω–∞—è_–∞–Ω–æ–º–∞–ª–∏—è'].sum()}
        
        üéØ –ù–ï–î–û–û–¶–ï–ù–ï–ù–ù–´–ï
        –¢–æ–ø-–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö: {df['AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ'].sum()}
        –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä: {df['AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å'].mean():.3f}
        –ú–µ–¥–∏–∞–Ω–Ω—ã–π —Å–∫–æ—Ä: {df['AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å'].median():.3f}
        
        üìà –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –¢–û–ü-–ù–ï–î–û–û–¶–ï–ù–ï–ù–ù–´–•
        –°—Ä–µ–¥–Ω–∏–π P/E: {df[top_mask]['P_E'].mean():.1f}
        –°—Ä–µ–¥–Ω–∏–π P/B: {df[top_mask]['P_B'].mean():.2f}
        –°—Ä–µ–¥–Ω–∏–π ROE: {df[top_mask]['ROE'].mean():.1f}%
        """

        ax.text(
            0.05,
            0.95,
            text,
            transform=ax.transAxes,
            fontsize=AE_FORMAT.LABEL_FONT_SIZE,
            verticalalignment="top",
            family="monospace",
            bbox=dict(
                boxstyle="round",
                facecolor=AE_FORMAT.COLOR_ANOMALY_BG,
                edgecolor=AE_FORMAT.COLOR_ANOMALY_EDGE,
                alpha=0.9,
            ),
        )


# ==================== –§–£–ù–ö–¶–ò–ò –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–• ====================


class AEDataLoader:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""

    @staticmethod
    def load_and_prepare_excel_data(file_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel —Ñ–∞–π–ª–∞"""
        df = pd.read_excel(file_path, sheet_name="Sheet1")

        for col in AE_COLUMN.NUMERIC_COLUMNS:
            if col in df.columns:
                df[col] = (
                    df[col]
                    .astype(str)
                    .str.replace(
                        AE_COLUMN.BILLION_SUFFIX, AE_COLUMN.BILLION_REPLACE, regex=False
                    )
                )
                df[col] = (
                    df[col]
                    .astype(str)
                    .str.replace(
                        AE_COLUMN.MILLION_SUFFIX, AE_COLUMN.MILLION_REPLACE, regex=False
                    )
                )
                df[col] = df[col].astype(str).str.replace(",", ".")
                df[col] = pd.to_numeric(df[col], errors="coerce")

        df["dividend_yield"] = df["–î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å"] / 100

        for old_col, new_col in AE_COLUMN.COLUMN_MAPPING.items():
            if old_col in df.columns:
                df[new_col] = df[old_col]

        return df


# ==================== –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò ====================


def detect_anomalies_with_ae(df):
    """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –∏ –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö –∞–∫—Ü–∏–π —Å –ø–æ–º–æ—â—å—é –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""

    available_cols = [col for col in AE_FEATURE.DEFAULT_FEATURES if col in df.columns]
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {available_cols}")

    feature_data = []
    valid_indices = []
    tickers = []

    for idx, row in df.iterrows():
        feature_vector = []
        valid = True

        for col in available_cols:
            val = row.get(col, None)
            if pd.isna(val):
                valid = False
                break
            feature_vector.append(float(val))

        if valid and len(feature_vector) == len(available_cols):
            feature_data.append(feature_vector)
            valid_indices.append(idx)
            tickers.append(row.get("–¢–∏–∫–µ—Ä", f"Row_{idx}"))

    if not feature_data:
        print("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞")
        return df, None, None

    X = np.array(feature_data)
    print(f"–û–±—É—á–∞–µ–º –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –Ω–∞ {len(feature_data)} –∞–∫—Ü–∏—è—Ö")

    feature_medians = np.median(X, axis=0)
    feature_means = np.mean(X, axis=0)

    print("\n–ú–µ–¥–∏–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for i, col in enumerate(available_cols):
        print(f"{col:<15}: –ú–µ–¥–∏–∞–Ω–∞ = {feature_medians[i]:.4f}")

    scaler = RobustScaler()
    X_scaled = scaler.fit_transform(X)

    input_size = len(available_cols)
    model = AnomalyDetectorAE(input_size)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=AE_ARCH.LEARNING_RATE)

    dataset = TensorDataset(torch.FloatTensor(X_scaled))
    dataloader = DataLoader(dataset, batch_size=AE_ARCH.BATCH_SIZE, shuffle=True)

    print("\n–û–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞...")
    for epoch in range(AE_ARCH.N_EPOCHS):
        total_loss = 0
        for batch in dataloader:
            inputs = batch[0]
            optimizer.zero_grad()
            _, reconstructed = model(inputs)
            loss = criterion(reconstructed, inputs)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        if epoch % AE_ARCH.EPOCH_LOG_INTERVAL == 0:
            print(f"Epoch {epoch}, Loss: {total_loss/len(dataloader):.6f}")

    model.eval()
    with torch.no_grad():
        X_tensor = torch.FloatTensor(X_scaled)
        _, reconstructed = model(X_tensor)
        reconstruction_errors = torch.mean((X_tensor - reconstructed) ** 2, dim=1)
        encoded, _ = model(X_tensor)
        encoded_features = encoded.numpy()

    errors_np = reconstruction_errors.numpy()

    error_median = np.median(errors_np)
    error_q1 = np.percentile(errors_np, AE_THRESHOLD.Q1_PERCENTILE)
    error_q3 = np.percentile(errors_np, AE_THRESHOLD.Q3_PERCENTILE)
    error_iqr = error_q3 - error_q1
    anomaly_threshold = error_q3 + AE_THRESHOLD.ANOMALY_IQR_MULTIPLIER * error_iqr
    strong_anomaly_threshold = (
        error_q3 + AE_THRESHOLD.STRONG_ANOMALY_IQR_MULTIPLIER * error_iqr
    )

    is_anomaly = errors_np > anomaly_threshold
    is_strong_anomaly = errors_np > strong_anomaly_threshold

    print(f"\n–ü–æ—Ä–æ–≥ –∞–Ω–æ–º–∞–ª–∏–π: {anomaly_threshold:.6f}")
    print(f"–ù–∞–π–¥–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π: {is_anomaly.sum()} –∏–∑ {len(errors_np)}")

    low_error_mask = errors_np < error_median
    if low_error_mask.sum() > AE_SCORING.GOOD_COMPANIES_MIN_COUNT:
        good_companies_features = X[low_error_mask]
        ideal_profile = np.median(good_companies_features, axis=0)
    else:
        ideal_profile = feature_medians

    undervalued_scores = []

    for i in range(len(X)):
        current_features = X[i]
        error_score = np.exp(-errors_np[i] / error_median)

        fundamental_score = 0
        for j, col in enumerate(available_cols):
            current_val = current_features[j]
            ideal_val = ideal_profile[j]

            if col in AE_FEATURE.LOWER_IS_BETTER_FEATURES:
                if (
                    0
                    < current_val
                    < ideal_val * AE_THRESHOLD.IDEAL_PROFILE_UNDERVALUED_FACTOR
                ):
                    fundamental_score += AE_SCORING.SCORE_STRONG_UNDERVALUED
                elif current_val < ideal_val:
                    fundamental_score += AE_SCORING.SCORE_UNDERVALUED
            elif col in AE_FEATURE.HIGHER_IS_BETTER_FEATURES:
                if (
                    current_val
                    > ideal_val * AE_THRESHOLD.IDEAL_PROFILE_OVERVAULED_FACTOR
                ):
                    fundamental_score += AE_SCORING.SCORE_STRONG_UNDERVALUED
                elif current_val > ideal_val:
                    fundamental_score += AE_SCORING.SCORE_UNDERVALUED

        combined_score = error_score * (
            1
            + fundamental_score
            / (len(available_cols) * AE_SCORING.FUNDAMENTAL_SCORE_FACTOR)
        )
        undervalued_scores.append(combined_score)

    df = AEDataUtils.add_ae_results_to_df(
        df,
        valid_indices,
        errors_np,
        is_anomaly,
        is_strong_anomaly,
        undervalued_scores,
        error_median,
    )

    AEDataUtils.print_top_undervalued(df)

    return df, model, scaler


class AEDataUtils:
    """–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""

    @staticmethod
    def add_ae_results_to_df(
        df,
        valid_indices,
        errors_np,
        is_anomaly,
        is_strong_anomaly,
        undervalued_scores,
        error_median,
    ):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –≤ DataFrame"""

        df["AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"] = np.nan
        df["AE_–û—à–∏–±–∫–∞_–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è"] = np.nan
        df["AE_–ê–Ω–æ–º–∞–ª–∏—è"] = False
        df["AE_–°–∏–ª—å–Ω–∞—è_–∞–Ω–æ–º–∞–ª–∏—è"] = False
        df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"] = np.nan
        df["AE_–†–∞–Ω–≥_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç–∏"] = np.nan
        df["AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] = False

        for i, idx in enumerate(valid_indices):
            df.at[idx, "AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"] = errors_np[i]
            df.at[idx, "AE_–û—à–∏–±–∫–∞_–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è"] = errors_np[i] / error_median
            df.at[idx, "AE_–ê–Ω–æ–º–∞–ª–∏—è"] = is_anomaly[i]
            df.at[idx, "AE_–°–∏–ª—å–Ω–∞—è_–∞–Ω–æ–º–∞–ª–∏—è"] = is_strong_anomaly[i]
            df.at[idx, "AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"] = undervalued_scores[i]

        if undervalued_scores:
            scores_array = np.array(undervalued_scores)
            for i, idx in enumerate(valid_indices):
                percentile = (
                    (scores_array <= scores_array[i]).sum() / len(scores_array) * 100
                )
                df.at[idx, "AE_–†–∞–Ω–≥_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç–∏"] = percentile

        if len(undervalued_scores) >= AE_PORTFOLIO.TOP_UNDERVALUED_N:
            top_indices = np.argsort(undervalued_scores)[
                -AE_PORTFOLIO.TOP_UNDERVALUED_N :
            ][::-1]
            filtered_top = []

            for i in top_indices:
                if not is_anomaly[i]:
                    filtered_top.append(i)
                if len(filtered_top) >= AE_PORTFOLIO.TOP_UNDERVALUED_N:
                    break

            if len(filtered_top) < AE_PORTFOLIO.TOP_UNDERVALUED_N:
                for i in top_indices:
                    if i not in filtered_top:
                        filtered_top.append(i)
                    if len(filtered_top) >= AE_PORTFOLIO.TOP_UNDERVALUED_N:
                        break

            for i in filtered_top:
                df.at[valid_indices[i], "AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"] = True

        return df

    @staticmethod
    def print_top_undervalued(df):
        """–í—ã–≤–æ–¥ —Ç–æ–ø-–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö –∞–∫—Ü–∏–π"""
        print("\n" + AE_FORMAT.SEPARATOR)
        print("–¢–û–ü-10 –ù–ï–î–û–û–¶–ï–ù–ï–ù–ù–´–• –ê–ö–¶–ò–ô:")
        print(AE_FORMAT.SEPARATOR)

        undervalued_df = df[df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"].notna()].copy()
        if not undervalued_df.empty:
            undervalued_df = undervalued_df.sort_values(
                "AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å", ascending=False
            )

            print(
                f"{'–¢–∏–∫–µ—Ä':<10} {'–ù–∞–∑–≤–∞–Ω–∏–µ':<25} {'P/E':<6} {'P/B':<6} {'–î–î,%':<6} "
                f"{'ROE,%':<7} {'–°–∫–æ—Ä':<8} {'–†–∞–Ω–≥':<6}"
            )
            print(AE_FORMAT.SUB_SEPARATOR)

            for _, row in undervalued_df.head(15).iterrows():
                is_top = (
                    AE_FORMAT.STAR_SYMBOL
                    if row.get("AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ", False)
                    else ""
                )
                print(
                    f"{row.get('–¢–∏–∫–µ—Ä', ''):<10} "
                    f"{str(row.get('–ù–∞–∑–≤–∞–Ω–∏–µ', ''))[:23]:<25} "
                    f"{row.get('P_E', 0):<6.1f} "
                    f"{row.get('P_B', 0):<6.2f} "
                    f"{row.get('dividend_yield', 0)*100:<6.1f} "
                    f"{row.get('ROE', 0):<7.1f} "
                    f"{row.get('AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å', 0):<8.3f} "
                    f"{row.get('AE_–†–∞–Ω–≥_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç–∏', 0):<6.1f} {is_top}"
                )


def create_portfolios_from_ae_results(df, ae_optimizer):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"""

    print("\n" + AE_FORMAT.SEPARATOR)
    print("üíº –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –ü–û–†–¢–§–ï–õ–ï–ô –ù–ê –û–°–ù–û–í–ï –ê–í–¢–û–≠–ù–ö–û–î–ï–†–ê")
    print(AE_FORMAT.SEPARATOR)

    candidates = df[
        (df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"].notna())
        & (df["AE_–û—à–∏–±–∫–∞_—Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"].notna())
        & (df["AE_–ê–Ω–æ–º–∞–ª–∏—è"] == False)
    ].copy()

    print(f"–ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π: {len(candidates)}")

    if len(candidates) < AE_PORTFOLIO.MIN_CANDIDATES:
        candidates = df[
            (df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"].notna())
            & (df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"] > df["AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"].median())
        ].copy()
        print(f"–ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ—Å–ª–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è: {len(candidates)}")

    candidates["AE_Expected_Return"] = candidates.apply(
        ae_optimizer.calculate_expected_return, axis=1
    )
    candidates["AE_Volatility"] = candidates.apply(
        ae_optimizer.calculate_volatility, axis=1
    )

    final_candidates = candidates[
        (candidates["AE_Expected_Return"] > AE_PORTFOLIO.MIN_EXPECTED_RETURN)
        & (candidates["AE_Volatility"] < AE_PORTFOLIO.MAX_VOLATILITY_THRESHOLD)
    ].copy()

    if len(final_candidates) > AE_PORTFOLIO.MAX_CANDIDATES:
        final_candidates = final_candidates.nlargest(
            AE_PORTFOLIO.MAX_CANDIDATES, "AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å"
        )

    print(f"–§–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(final_candidates)}")

    portfolios = {}

    if len(final_candidates) >= AE_PORTFOLIO.MIN_PORTFOLIO_SIZE:
        expected_returns = final_candidates["AE_Expected_Return"].values
        cov_matrix = ae_optimizer.create_covariance_matrix(final_candidates)
        opt_result = ae_optimizer.optimize_portfolio(
            expected_returns, cov_matrix, undervalued_boost=True
        )

        pm = AEPortfolioManager(
            "–ú–∞—Ä–∫–æ–≤–∏—Ü-–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π",
            final_candidates.reset_index(drop=True),
            opt_result["combined_weights"],
            ae_optimizer,
        )
        portfolios["–ú–∞—Ä–∫–æ–≤–∏—Ü-–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π"] = pm
        print(f"‚úÖ –ú–∞—Ä–∫–æ–≤–∏—Ü-–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π: –®–∞—Ä–ø={pm.metrics.sharpe_ratio:.2f}")

    ae_portfolios = ae_optimizer.create_ae_based_portfolios(final_candidates)

    for name, (df_port, weights) in ae_portfolios.items():
        if len(df_port) >= AE_PORTFOLIO.MIN_PORTFOLIO_SIZE:
            pm = AEPortfolioManager(
                name, df_port.reset_index(drop=True), weights, ae_optimizer
            )
            portfolios[name] = pm
            print(f"‚úÖ {name}: –®–∞—Ä–ø={pm.metrics.sharpe_ratio:.2f}")

    return portfolios, final_candidates


def save_portfolio_results(df, portfolios, candidates, output_path):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""

    with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name=AE_FILES.SHEET_AE_RESULTS, index=False)
        candidates.to_excel(writer, sheet_name=AE_FILES.SHEET_CANDIDATES, index=False)

        if portfolios:
            summary = []
            for name, pm in portfolios.items():
                summary.append(
                    {
                        "–ü–æ—Ä—Ç—Ñ–µ–ª—å": name,
                        "–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å": f"{pm.metrics.expected_return:.2%}",
                        "–†–∏—Å–∫": f"{pm.metrics.risk:.2%}",
                        "–®–∞—Ä–ø": f"{pm.metrics.sharpe_ratio:.2f}",
                        "VaR": f"{pm.metrics.var_95:.2%}",
                        "–î–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è": f"{pm.metrics.diversification_score:.1%}",
                        "–ü–æ–∑–∏—Ü–∏–π": len(pm.df),
                        "–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö": pm.df["AE_–¢–æ–ø_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ"].sum(),
                    }
                )
            pd.DataFrame(summary).to_excel(
                writer, sheet_name=AE_FILES.SHEET_PORTFOLIO_SUMMARY, index=False
            )

            best_portfolio = max(
                portfolios.values(), key=lambda p: p.metrics.sharpe_ratio
            )
            best_portfolio.df.to_excel(
                writer, sheet_name=AE_FILES.SHEET_BEST_PORTFOLIO, index=False
            )

    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""

    print(AE_FORMAT.SEPARATOR)
    print("üöÄ –ê–í–¢–û–≠–ù–ö–û–î–ï–† + –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–û–†–¢–§–ï–õ–Ø –ü–û –ú–ê–†–ö–û–í–ò–¶–£")
    print(AE_FORMAT.SEPARATOR)

    try:
        print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        df = AEDataLoader.load_and_prepare_excel_data(AE_PATHS["input_file"])
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∞–∫—Ü–∏–π")

        print("\nüß† –û–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞...")
        df_with_ae, model, scaler = detect_anomalies_with_ae(df)

        if model is None:
            print("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞")
            return

        print("\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –∞–Ω–æ–º–∞–ª–∏–π...")
        AEPortfolioVisualizer.plot_anomaly_analysis(
            df_with_ae, AE_PATHS["ae_anomaly_file"]
        )

        ae_optimizer = AEPortfolioOptimizer(
            min_weight=AE_PORTFOLIO.MIN_WEIGHT,
            max_weight=AE_PORTFOLIO.MAX_WEIGHT,
            risk_free_rate=AE_PORTFOLIO.RISK_FREE_RATE,
        )

        portfolios, candidates = create_portfolios_from_ae_results(
            df_with_ae, ae_optimizer
        )

        if portfolios:
            print("\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π...")

            AEPortfolioVisualizer.plot_portfolio_comparison(
                portfolios, AE_PATHS["ae_portfolio_comparison"]
            )

            best_portfolio = max(
                portfolios.values(), key=lambda p: p.metrics.sharpe_ratio
            )
            AEPortfolioVisualizer.plot_portfolio_summary(best_portfolio)

        save_portfolio_results(
            df_with_ae, portfolios, candidates, AE_PATHS["output_file"]
        )

        print("\n" + AE_FORMAT.SEPARATOR)
        print("üéØ –ò–¢–û–ì–û–í–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
        print(AE_FORMAT.SEPARATOR)

        if portfolios:
            best_portfolio = max(
                portfolios.values(), key=lambda p: p.metrics.sharpe_ratio
            )

            print(f"\nüèÜ –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ô –ü–û–†–¢–§–ï–õ–¨: {best_portfolio.name}")
            print(
                f"   –û–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {AE_FORMAT.PERCENT_FORMAT.format(best_portfolio.metrics.expected_return)}"
            )
            print(
                f"   –†–∏—Å–∫: {AE_FORMAT.PERCENT_FORMAT.format(best_portfolio.metrics.risk)}"
            )
            print(
                f"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {AE_FORMAT.FLOAT_FORMAT_2D.format(best_portfolio.metrics.sharpe_ratio)}"
            )

            print(f"\nüìà –¢–û–ü-5 –ü–û–ó–ò–¶–ò–ô –í –ü–û–†–¢–§–ï–õ–ï:")
            top_n = min(AE_FORMAT.TOP_POSITIONS_BEST, len(best_portfolio.df))
            top_5 = best_portfolio.get_top_positions(top_n)

            for _, row in top_5.iterrows():
                ticker = row.get("–¢–∏–∫–µ—Ä", "N/A")
                weight = row.get("Weight", 0)
                company = str(row.get("–ù–∞–∑–≤–∞–Ω–∏–µ", ""))[:30]
                score = row.get("AE_–ù–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç—å", 0)
                rank = row.get("AE_–†–∞–Ω–≥_–Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω–æ—Å—Ç–∏", 0)

                print(
                    f"   ‚Ä¢ {ticker}: {AE_FORMAT.PERCENT_FORMAT.format(weight)} - {company}"
                )
                print(f"     –°–∫–æ—Ä: {score:.3f}, –†–∞–Ω–≥: {rank:.1f}%")

            print(f"\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
            anomaly_alloc = best_portfolio.get_anomaly_allocation()
            for category, weight in anomaly_alloc.items():
                if weight > 0:
                    print(f"   ‚Ä¢ {category}: {AE_FORMAT.PERCENT_FORMAT.format(weight)}")

        print("\n" + AE_FORMAT.SEPARATOR)
        print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
        print(AE_FORMAT.SEPARATOR)

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
