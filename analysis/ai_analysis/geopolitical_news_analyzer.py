import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from transformers import pipeline
from bs4 import BeautifulSoup
import warnings
import time
import json
import re
warnings.filterwarnings('ignore')
from textblob import TextBlob
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# –°–∫–∞—á–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è nltk
try:
    nltk.data.find('sentiment/vader_lexicon.zip')
except:
    nltk.download('vader_lexicon')

class GeopoliticalNewsAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –∏—Ö –≤–ª–∏—è–Ω–∏—è –Ω–∞ –∞–∫—Ü–∏–∏ –ú–æ—Å–±–∏—Ä–∂–∏"""
    
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è NLP –º–æ–¥–µ–ª–µ–π
        self.sentiment_analyzer = SentimentIntensityAnalyzer()
        try:
            self.classifier = pipeline("zero-shot-classification", 
                                     model="facebook/bart-large-mnli")
        except:
            print("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            self.classifier = None
        
        # –ì–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        self.geopolitical_categories = [
            "—Å–∞–Ω–∫—Ü–∏–∏", "—Ç–æ—Ä–≥–æ–≤—ã–µ –≤–æ–π–Ω—ã", "–≤–∞–ª—é—Ç–Ω—ã–µ —Ä–∏—Å–∫–∏", 
            "–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å", "—Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è",
            "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã", "—ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å",
            "–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "—ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏", "—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è",
            "–Ω–µ—Ñ—Ç—å –∏ –≥–∞–∑", "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä—ã–Ω–∫–∏", "—Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏"
        ]
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å—Ç—Ä–∞–Ω—ã –∏ —Ä–µ–≥–∏–æ–Ω—ã
        self.key_regions = {
            '–†–æ—Å—Å–∏—è': ['—Ä–æ—Å—Å–∏', '—Ä—Ñ', '–º–æ—Å–∫–≤', '–∫—Ä–µ–º–ª', '–ø—É—Ç–∏–Ω'],
            '–°–®–ê': ['—Å—à–∞', '–∞–º–µ—Ä–∏–∫', '–≤–∞—à–∏–Ω–≥—Ç–æ–Ω', '–±–∞–π–¥–µ–Ω'],
            '–ï–°': ['–µ–≤—Ä–æ—Å–æ—é–∑', '–µ–≤—Ä–æ–ø', '–±—Ä—é—Å—Å–µ–ª', '–≥–µ—Ä–º–∞–Ω–∏', '—Ñ—Ä–∞–Ω—Ü'],
            '–ö–∏—Ç–∞–π': ['–∫–∏—Ç–∞', '–ø–µ–∫–∏–Ω', '—Å–∏ —Ü–∑–∏–Ω—å–ø–∏–Ω'],
            '–ë–ª–∏–∂–Ω–∏–π –í–æ—Å—Ç–æ–∫': ['–±–ª–∏–∂–Ω–∏–π –≤–æ—Å—Ç–æ–∫', '—Å–∞—É–¥', '–∏—Ä–∞–Ω', '—Å–∏—Ä–∏', '–∏–∑—Ä–∞–∏–ª'],
            '–£–∫—Ä–∞–∏–Ω–∞': ['—É–∫—Ä–∞–∏–Ω', '–∫–∏–µ–≤', '–∑–µ–ª–µ–Ω—Å–∫'],
            '–í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è': ['–≤–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω', '–ª–æ–Ω–¥–æ–Ω'],
            '–¢—É—Ä—Ü–∏—è': ['—Ç—É—Ä—Ü', '—ç—Ä–¥–æ–≥–∞–Ω'],
            '–ò–Ω–¥–∏—è': ['–∏–Ω–¥–∏', '–º–æ–¥–∏']
        }
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∞–∫—Ü–∏–∏ –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–±–∏—Ä–∂–∏
        self.moex_companies = {
            'SBER': {'name': '–°–±–µ—Ä–±–∞–Ω–∫', 'ticker': 'SBER', 'industry': '—Ñ–∏–Ω–∞–Ω—Å—ã'},
            'GAZP': {'name': '–ì–∞–∑–ø—Ä–æ–º', 'ticker': 'GAZP', 'industry': '–Ω–µ—Ñ—Ç–µ–≥–∞–∑'},
            'LKOH': {'name': '–õ—É–∫–æ–π–ª', 'ticker': 'LKOH', 'industry': '–Ω–µ—Ñ—Ç–µ–≥–∞–∑'},
            'GMKN': {'name': '–ù–æ—Ä–Ω–∏–∫–µ–ª—å', 'ticker': 'GMKN', 'industry': '–º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è'},
            'ROSN': {'name': '–†–æ—Å–Ω–µ—Ñ—Ç—å', 'ticker': 'ROSN', 'industry': '–Ω–µ—Ñ—Ç–µ–≥–∞–∑'},
            'MGNT': {'name': '–ú–∞–≥–Ω–∏—Ç', 'ticker': 'MGNT', 'industry': '—Ä–∏—Ç–µ–π–ª'},
            'YNDX': {'name': '–Ø–Ω–¥–µ–∫—Å', 'ticker': 'YNDX', 'industry': '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏'},
            'VTBR': {'name': '–ë–∞–Ω–∫ –í–¢–ë', 'ticker': 'VTBR', 'industry': '—Ñ–∏–Ω–∞–Ω—Å—ã'},
            'ALRS': {'name': '–ê–õ–†–û–°–ê', 'ticker': 'ALRS', 'industry': '–º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è'},
            'PLZL': {'name': '–ü–æ–ª—é—Å', 'ticker': 'PLZL', 'industry': '–º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è'},
            'NVTK': {'name': '–ù–æ–≤–∞—Ç—ç–∫', 'ticker': 'NVTK', 'industry': '–Ω–µ—Ñ—Ç–µ–≥–∞–∑'},
            'TATN': {'name': '–¢–∞—Ç–Ω–µ—Ñ—Ç—å', 'ticker': 'TATN', 'industry': '–Ω–µ—Ñ—Ç–µ–≥–∞–∑'},
            'MOEX': {'name': '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –ë–∏—Ä–∂–∞', 'ticker': 'MOEX', 'industry': '—Ñ–∏–Ω–∞–Ω—Å—ã'},
            'AFKS': {'name': '–ê–§–ö –°–∏—Å—Ç–µ–º–∞', 'ticker': 'AFKS', 'industry': '–∫–æ–Ω–≥–ª–æ–º–µ—Ä–∞—Ç'},
            'PHOR': {'name': '–§–æ—Å–ê–≥—Ä–æ', 'ticker': 'PHOR', 'industry': '—Ö–∏–º–∏—è'},
            'RUAL': {'name': '–†–£–°–ê–õ', 'ticker': 'RUAL', 'industry': '–º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è'},
            'MTSS': {'name': '–ú–¢–°', 'ticker': 'MTSS', 'industry': '—Ç–µ–ª–µ–∫–æ–º'},
            'AFLT': {'name': '–ê—ç—Ä–æ—Ñ–ª–æ—Ç', 'ticker': 'AFLT', 'industry': '—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç'},
            'IRAO': {'name': '–ò–Ω—Ç–µ—Ä –†–ê–û', 'ticker': 'IRAO', 'industry': '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞'},
            'RTKM': {'name': '–†–æ—Å—Ç–µ–ª–µ–∫–æ–º', 'ticker': 'RTKM', 'industry': '—Ç–µ–ª–µ–∫–æ–º'}
        }
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–π
        self.company_keywords = {
            'SBER': ['—Å–±–µ—Ä', '—Å–±–µ—Ä–±–∞–Ω–∫', '–≥–µ—Ä–º–∞–Ω –≥—Ä–µ—Ñ', '—Å–±'],
            'GAZP': ['–≥–∞–∑–ø—Ä–æ–º', '–≥–∞–∑', '–º–∏–ª–ª–µ—Ä', '–≥–ø'],
            'LKOH': ['–ª—É–∫–æ–π–ª', '–Ω–µ—Ñ—Ç—å', '–∞–ª–µ–∫–ø–µ—Ä–æ–≤', '–ª–∫'],
            'GMKN': ['–Ω–æ—Ä–Ω–∏–∫–µ–ª—å', '–Ω–∏–∫–µ–ª—å', '–ø–æ—Ç–∞–Ω–∏–Ω', '–Ω–Ω'],
            'ROSN': ['—Ä–æ—Å–Ω–µ—Ñ—Ç—å', '—Å–µ—á–∏–Ω', '—Ä–Ω'],
            'YNDX': ['—è–Ω–¥–µ–∫—Å', '–ø–æ–∏—Å–∫', '–∞—Ä–∫–∞–¥–∏–π –≤–æ–π—Ü', '—è'],
            'VTBR': ['–≤—Ç–±', '–±–∞–Ω–∫ –≤—Ç–±', '–∫–æ—Å—Ç–∏–Ω'],
            'NVTK': ['–Ω–æ–≤–∞—Ç—ç–∫', '–≥–ø–∑', '–º–∏—Ö–µ–µ–ª—å—Å–æ–Ω'],
            'MGNT': ['–º–∞–≥–Ω–∏—Ç', '—Ä–∏—Ç–µ–π–ª', '–≥–∞–ª—É–∑–∏—Ü–∞'],
            'TATN': ['—Ç–∞—Ç–Ω–µ—Ñ—Ç—å', '—Ç–∞—Ç–∞—Ä—Å—Ç–∞–Ω', '–Ω–µ—Ñ—Ç—å']
        }
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.finance_sources = {
            'moex': 'https://iss.moex.com/iss/engines/stock/markets/shares/boards/TQBR/securities.json',
            'investing': 'https://ru.investing.com/equities/',
            'finam': 'https://www.finam.ru/profile/mosbirzha-akcii/',
            'bcs': 'https://bcs-express.ru/kotirovki-i-grafiki/'
        }
        
    def fetch_real_news(self, days_back=7):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π —Å RSS-–ª–µ–Ω—Ç"""
        news_items = []
        
        try:
            # –°–ø–∏—Å–æ–∫ RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            rss_sources = [
                {
                    'name': '–†–ë–ö',
                    'url': 'https://rssexport.rbc.ru/rbcnews/news/30/full.rss',
                    'parser': 'rbc'
                },
                {
                    'name': '–ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å',
                    'url': 'https://www.interfax.ru/rss.asp',
                    'parser': 'interfax'
                },
                {
                    'name': '–í–µ–¥–æ–º–æ—Å—Ç–∏',
                    'url': 'https://www.vedomosti.ru/rss/news',
                    'parser': 'vedomosti'
                },
                {
                    'name': '–ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç',
                    'url': 'https://www.kommersant.ru/RSS/news.xml',
                    'parser': 'kommersant'
                },
                {
                    'name': '–¢–ê–°–°',
                    'url': 'https://tass.ru/rss/v2.xml',
                    'parser': 'tass'
                }
            ]
            
            for source in rss_sources:
                try:
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    }
                    response = requests.get(source['url'], headers=headers, timeout=10)
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.content, 'xml')
                        items = soup.find_all('item')
                        
                        for item in items[:15]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                            title = item.title.text.strip() if item.title else ''
                            description = item.description.text.strip() if item.description else ''
                            pub_date = item.pubDate.text if item.pubDate else ''
                            
                            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–º —Ç–µ–º–∞–º
                            text = f"{title} {description}".lower()
                            geo_keywords = ['—Å–∞–Ω–∫—Ü–∏', '–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '—Ä—É–±–ª', '–¥–æ–ª–ª–∞—Ä', 
                                          '–≤–æ–π–Ω', '–∫–æ–Ω—Ñ–ª–∏–∫—Ç', '—ç–∫–æ–Ω–æ–º–∏–∫', '—Ä—ã–Ω–æ–∫', '–∞–∫—Ü–∏',
                                          '–±–∏—Ä–∂', '–∏–Ω–≤–µ—Å—Ç', '—Ñ–æ–Ω–¥', '–±–∞–Ω–∫', '—Ñ–∏–Ω–∞–Ω—Å']
                            
                            if any(keyword in text for keyword in geo_keywords):
                                news_items.append({
                                    'title': title[:200],
                                    'summary': description[:300],
                                    'date': pub_date[:20],
                                    'source': source['name'],
                                    'raw_text': f"{title} {description}"
                                })
                    
                    time.sleep(1)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {source['name']}: {str(e)[:50]}")
                    continue
                    
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ
        if len(news_items) < 5:
            print("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            news_items.extend(self.generate_synthetic_news(days_back))
        
        return news_items[:20]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 20 –Ω–æ–≤–æ—Å—Ç—è–º–∏
    
    def generate_synthetic_news(self, days_back=7):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        synthetic_news = []
        
        news_templates = [
            {
                'title': '–ù–æ–≤—ã–µ —Å–∞–Ω–∫—Ü–∏–∏ –°–®–ê –ø—Ä–æ—Ç–∏–≤ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –±–∞–Ω–∫–æ–≤ –º–æ–≥—É—Ç —É–¥–∞—Ä–∏—Ç—å –ø–æ –°–±–µ—Ä–±–∞–Ω–∫—É –∏ –í–¢–ë',
                'summary': '–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è –°–®–ê —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ä—ã –ø—Ä–æ—Ç–∏–≤ –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∏–Ω—Å—Ç–∏—Ç—É—Ç–æ–≤, —á—Ç–æ –º–æ–∂–µ—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ –∏—Ö –∫–æ—Ç–∏—Ä–æ–≤–∫–∏',
                'category': '—Å–∞–Ω–∫—Ü–∏–∏',
                'impact': 0.8,
                'companies': ['SBER', 'VTBR', 'MOEX']
            },
            {
                'title': '–¶–µ–Ω—ã –Ω–∞ –Ω–µ—Ñ—Ç—å Brent –ø—Ä–µ–≤—ã—Å–∏–ª–∏ $85 –∑–∞ –±–∞—Ä—Ä–µ–ª—å –Ω–∞ —Ñ–æ–Ω–µ —Ä–µ—à–µ–Ω–∏—è –û–ü–ï–ö+',
                'summary': '–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ –¥–æ–±—ã—á–∏ —Å—Ç—Ä–∞–Ω–∞–º–∏ –û–ü–ï–ö+ –∏ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏–≤–µ–ª–∏ –∫ —Ä–æ—Å—Ç—É —Ü–µ–Ω –Ω–∞ –Ω–µ—Ñ—Ç—å –Ω–∞ 5%, —á—Ç–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ –¥–ª—è –ì–∞–∑–ø—Ä–æ–º–∞ –∏ –õ—É–∫–æ–π–ª–∞',
                'category': '—ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å',
                'impact': 0.7,
                'companies': ['GAZP', 'LKOH', 'ROSN', 'NVTK', 'TATN']
            },
            {
                'title': '–ï–¶–ë –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –¥–æ 4.5%, —Ä—É–±–ª—å –æ—Å–ª–∞–±–µ–≤–∞–µ—Ç',
                'summary': '–ï–≤—Ä–æ–ø–µ–π—Å–∫–∏–π —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –±–æ—Ä—å–±—É —Å –∏–Ω—Ñ–ª—è—Ü–∏–µ–π, —É–∂–µ—Å—Ç–æ—á–∞—è –¥–µ–Ω–µ–∂–Ω–æ-–∫—Ä–µ–¥–∏—Ç–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É, —á—Ç–æ –æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ —Ä—É–±–ª—å',
                'category': '–≤–∞–ª—é—Ç–Ω—ã–µ —Ä–∏—Å–∫–∏',
                'impact': 0.6,
                'companies': ['SBER', 'VTBR', 'MOEX']
            },
            {
                'title': '–ö–∏—Ç–∞–π –ø–æ–¥–ø–∏—Å–∞–ª –Ω–æ–≤—ã–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –Ω–∞ –ø–æ—Å—Ç–∞–≤–∫—É —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –°–ü–ì',
                'summary': '–ö–∏—Ç–∞–π—Å–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –∑–∞–∫–ª—é—á–∏–ª–∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è –Ω–∞ –ø–æ—Å—Ç–∞–≤–∫—É —Å–∂–∏–∂–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏—Ä–æ–¥–Ω–æ–≥–æ –≥–∞–∑–∞ –∏–∑ –†–æ—Å—Å–∏–∏',
                'category': '—Ç–æ—Ä–≥–æ–≤—ã–µ –≤–æ–π–Ω—ã',
                'impact': 0.5,
                'companies': ['GAZP', 'NVTK']
            },
            {
                'title': '–ú–∏–Ω—Ñ–∏–Ω –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É –¥–ª—è –≥–æ—Å–∫–æ–º–ø–∞–Ω–∏–π',
                'summary': '–†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–≤ –ø–æ –≤—ã–ø–ª–∞—Ç–µ –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤ –∫–æ–º–ø–∞–Ω–∏—è–º–∏ —Å –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–º —É—á–∞—Å—Ç–∏–µ–º',
                'category': '—Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è',
                'impact': 0.7,
                'companies': ['GAZP', 'ROSN', 'TATN', 'ALRS']
            },
            {
                'title': '–£—Å–∏–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—è –∑–∞ —Ç—Ä–∞–Ω—Å–≥—Ä–∞–Ω–∏—á–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏ –±–∏–∑–Ω–µ—Å–∞',
                'summary': '–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –∏ –†–æ—Å—Ñ–∏–Ω–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤–≤–æ–¥—è—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–Ω–æ-–∏–º–ø–æ—Ä—Ç–Ω—ã—Ö —Å–¥–µ–ª–æ–∫',
                'category': '—Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è',
                'impact': 0.6,
                'companies': ['GMKN', 'ALRS', 'PHOR', 'RUAL']
            },
            {
                'title': '–Ø–Ω–¥–µ–∫—Å —Å—Ç–æ–ª–∫–Ω—É–ª—Å—è —Å –Ω–æ–≤—ã–º–∏ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏',
                'summary': '–ö–æ–º–ø–∞–Ω–∏—è –¥–æ–ª–∂–Ω–∞ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–∏ —Å–µ—Ä–≤–∏—Å—ã –ø–æ–¥ –Ω–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ —Ä—ã–Ω–∫–∞',
                'category': '—Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è',
                'impact': 0.5,
                'companies': ['YNDX']
            },
            {
                'title': '–ú–∏—Ä–æ–≤—ã–µ —Ü–µ–Ω—ã –Ω–∞ –Ω–∏–∫–µ–ª—å –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 10% –∑–∞ –Ω–µ–¥–µ–ª—é',
                'summary': '–î–µ—Ñ–∏—Ü–∏—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Å–ø—Ä–æ—Å–∞ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã —ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª—å–Ω–æ–π –æ—Ç—Ä–∞—Å–ª–∏ –ø–æ–¥–Ω—è–ª–∏ —Ü–µ–Ω—ã –Ω–∞ –Ω–∏–∫–µ–ª—å',
                'category': '—Ç–æ—Ä–≥–æ–≤—ã–µ –≤–æ–π–Ω—ã',
                'impact': 0.6,
                'companies': ['GMKN', 'NVTK']
            }
        ]
        
        for i, template in enumerate(news_templates):
            synthetic_news.append({
                'title': template['title'],
                'summary': template['summary'],
                'date': (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d'),
                'source': '–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ',
                'raw_text': f"{template['title']} {template['summary']}",
                'template': template
            })
        
        return synthetic_news
    
    def analyze_news_sentiment(self, news_items):
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π"""
        analyzed_news = []
        
        print(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π...")
        
        for news in news_items:
            text = news['raw_text']
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
            sentiment = self.sentiment_analyzer.polarity_scores(text)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –µ—Å–ª–∏ –Ω–µ—Ç –º–æ–¥–µ–ª–∏)
            categories = []
            scores = []
            
            if self.classifier:
                try:
                    classification = self.classifier(
                        text, 
                        candidate_labels=self.geopolitical_categories,
                        multi_label=True
                    )
                    categories = classification['labels'][:2]
                    scores = classification['scores'][:2]
                except:
                    categories = self.simple_category_detection(text)
                    scores = [0.7, 0.5]
            else:
                categories = self.simple_category_detection(text)
                scores = [0.7, 0.5] if categories else [0.5]
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
            affected_regions = []
            for region, keywords in self.key_regions.items():
                if any(keyword in text.lower() for keyword in keywords):
                    affected_regions.append(region)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π
            affected_companies = self.detect_affected_companies(text)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —à–∞–±–ª–æ–Ω, –±–µ—Ä–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ –Ω–µ–≥–æ
            if 'template' in news:
                affected_companies = list(set(affected_companies + news['template'].get('companies', [])))
            
            analyzed_news.append({
                **news,
                'sentiment_negative': sentiment['neg'],
                'sentiment_neutral': sentiment['neu'],
                'sentiment_positive': sentiment['pos'],
                'sentiment_compound': sentiment['compound'],
                'categories': categories[:2],
                'category_scores': scores[:2],
                'affected_regions': affected_regions,
                'affected_companies': affected_companies,
                'impact_score': self.calculate_news_impact_score(
                    sentiment['compound'], 
                    len(affected_regions),
                    len(affected_companies)
                )
            })
        
        return analyzed_news
    
    def simple_category_detection(self, text):
        """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        text_lower = text.lower()
        categories = []
        
        category_keywords = {
            '—Å–∞–Ω–∫—Ü–∏–∏': ['—Å–∞–Ω–∫—Ü–∏', '–æ–≥—Ä–∞–Ω–∏—á–µ–Ω', '–∑–∞–ø—Ä–µ—Ç'],
            '–Ω–µ—Ñ—Ç—å –∏ –≥–∞–∑': ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '—ç–Ω–µ—Ä–≥', '–±–∞—Ä—Ä–µ–ª'],
            '–≤–∞–ª—é—Ç–Ω—ã–µ —Ä–∏—Å–∫–∏': ['–≤–∞–ª—é—Ç', '—Ä—É–±–ª', '–¥–æ–ª–ª–∞—Ä', '–∫—É—Ä—Å'],
            '—Ç–æ—Ä–≥–æ–≤—ã–µ –≤–æ–π–Ω—ã': ['—Ç–æ—Ä–≥–æ–≤', '–∏–º–ø–æ—Ä—Ç', '—ç–∫—Å–ø–æ—Ä—Ç', '–ø–æ—à–ª–∏–Ω'],
            '—Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è': ['—Ä–µ–≥—É–ª—è—Ç–æ—Ä', '–∑–∞–∫–æ–Ω', '–Ω–æ—Ä–º–∞—Ç–∏–≤', '—Ç—Ä–µ–±–æ–≤–∞–Ω'],
            '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä—ã–Ω–∫–∏': ['–±–∏—Ä–∂', '–∞–∫—Ü–∏', '—Ñ–æ–Ω–¥', '–∏–Ω–≤–µ—Å—Ç']
        }
        
        for category, keywords in category_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                categories.append(category)
        
        return categories[:2] if categories else ['–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ']
    
    def detect_affected_companies(self, text):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        text_lower = text.lower()
        affected = []
        
        for ticker, keywords in self.company_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                affected.append(ticker)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º
        industry_keywords = {
            'SBER': ['–±–∞–Ω–∫', '—Ñ–∏–Ω–∞–Ω—Å', '–∫—Ä–µ–¥–∏—Ç'],
            'GAZP': ['–≥–∞–∑', '—Ç—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥', '—ç–Ω–µ—Ä–≥'],
            'LKOH': ['–Ω–µ—Ñ—Ç', '–±–µ–Ω–∑–∏–Ω', '–∑–∞–ø—Ä–∞–≤–∫'],
            'YNDX': ['–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '–ø–æ–∏—Å–∫', '—Ç–∞–∫—Å–∏'],
            'MGNT': ['–º–∞–≥–∞–∑–∏–Ω', '–ø—Ä–æ–¥—É–∫—Ç', '—Å–µ—Ç—å']
        }
        
        for ticker, keywords in industry_keywords.items():
            if any(keyword in text_lower for keyword in keywords) and ticker not in affected:
                # –î–æ–±–∞–≤–ª—è–µ–º —Å –º–µ–Ω—å—à–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
                affected.append(ticker)
        
        return list(set(affected))
    
    def calculate_news_impact_score(self, sentiment, regions_count, companies_count):
        """–†–∞—Å—á–µ—Ç –æ—Ü–µ–Ω–∫–∏ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏"""
        # –ë–æ–ª–µ–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–º–µ—é—Ç –±–æ–ª—å—à–µ–µ –≤–ª–∏—è–Ω–∏–µ
        base_impact = (1 - sentiment) * 50  # sentiment –æ—Ç -1 –¥–æ 1
        
        # –£—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
        region_multiplier = 1 + (regions_count * 0.15)
        
        # –£—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π
        company_multiplier = 1 + (companies_count * 0.1)
        
        impact = base_impact * region_multiplier * company_multiplier
        
        return min(100, max(0, round(impact, 1)))
    
    def analyze_company_exposure(self, analyzed_news):
        """–ê–Ω–∞–ª–∏–∑ –ø–æ–¥–≤–µ—Ä–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–π –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–º —Ä–∏—Å–∫–∞–º"""
        company_exposure = {ticker: {
            'name': info['name'],
            'industry': info['industry'],
            'total_impact': 0,
            'news_count': 0,
            'average_impact': 0,
            'max_impact': 0,
            'risk_categories': [],
            'affected_regions': [],
            'related_news': []
        } for ticker, info in self.moex_companies.items()}
        
        for news in analyzed_news:
            impact = news['impact_score']
            
            # –ö–æ–º–ø–∞–Ω–∏–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö
            for ticker in news.get('affected_companies', []):
                if ticker in company_exposure:
                    company_exposure[ticker]['total_impact'] += impact
                    company_exposure[ticker]['news_count'] += 1
                    company_exposure[ticker]['max_impact'] = max(
                        company_exposure[ticker]['max_impact'], 
                        impact
                    )
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–∏—Å–∫–æ–≤
                    for category in news['categories']:
                        if category not in company_exposure[ticker]['risk_categories']:
                            company_exposure[ticker]['risk_categories'].append(category)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–≥–∏–æ–Ω—ã
                    for region in news['affected_regions']:
                        if region not in company_exposure[ticker]['affected_regions']:
                            company_exposure[ticker]['affected_regions'].append(region)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
                    company_exposure[ticker]['related_news'].append({
                        'title': news['title'][:100],
                        'impact': impact,
                        'sentiment': news['sentiment_compound'],
                        'date': news['date'],
                        'categories': news['categories']
                    })
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –æ—Ç—Ä–∞—Å–ª–µ–≤—ã–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            for ticker, info in self.moex_companies.items():
                if ticker in news.get('affected_companies', []):
                    continue  # –£–∂–µ —É—á–ª–∏ –≤—ã—à–µ
                    
                industry = info['industry']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–≤—è–∑–∞–Ω–∞ –ª–∏ –Ω–æ–≤–æ—Å—Ç—å —Å –æ—Ç—Ä–∞—Å–ª—å—é –∫–æ–º–ø–∞–Ω–∏–∏
                industry_keywords = {
                    '–Ω–µ—Ñ—Ç–µ–≥–∞–∑': ['–Ω–µ—Ñ—Ç', '–≥–∞–∑', '—ç–Ω–µ—Ä–≥', '–æ–ø–µ–∫', '–±–∞—Ä—Ä–µ–ª', '—Ç–æ–ø–ª–∏–≤'],
                    '–º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è': ['–º–µ—Ç–∞–ª', '—Å—Ç–∞–ª', '–Ω–∏–∫–µ–ª', '–∞–ª—é–º–∏–Ω', '–∑–æ–ª–æ—Ç', '–º–µ–¥'],
                    '—Ñ–∏–Ω–∞–Ω—Å—ã': ['–±–∞–Ω–∫', '—Ñ–∏–Ω–∞–Ω—Å', '—Å—Ç–∞–≤–∫', '—Ä—É–±–ª', '–≤–∞–ª—é—Ç', '–∫—Ä–µ–¥–∏—Ç'],
                    '—Ä–∏—Ç–µ–π–ª': ['–ø–æ—Ç—Ä–µ–±', '—Ä–∏—Ç–µ–π–ª', '–ø—Ä–æ–¥–∞–∂', '—Ç–æ–≤–∞—Ä', '–º–∞–≥–∞–∑–∏–Ω'],
                    '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏': ['—Ç–µ—Ö–Ω–æ–ª–æ–≥', '—Ü–∏—Ñ—Ä', '—Å–æ—Ñ—Ç', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', 'it'],
                    '—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç': ['—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–ª–æ–≥–∏—Å—Ç', '–¥–æ—Å—Ç–∞–≤–∫', '–∞–≤–∏–∞', '–ø–µ—Ä–µ–≤–æ–∑'],
                    '—Ç–µ–ª–µ–∫–æ–º': ['—Å–≤—è–∑—å', '—Ç–µ–ª–µ–∫–æ–º', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '–º–æ–±–∏–ª—å–Ω'],
                    '—Ö–∏–º–∏—è': ['—Ö–∏–º–∏', '—É–¥–æ–±—Ä–µ–Ω', '—Ñ–æ—Å—Ñ–∞—Ç']
                }
                
                if industry in industry_keywords:
                    if any(keyword in news['raw_text'].lower() 
                           for keyword in industry_keywords[industry]):
                        # –î–æ–±–∞–≤–ª—è–µ–º —Å –º–µ–Ω—å—à–∏–º –≤–µ—Å–æ–º
                        company_exposure[ticker]['total_impact'] += impact * 0.5
                        company_exposure[ticker]['news_count'] += 0.5
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ
        for ticker in company_exposure:
            if company_exposure[ticker]['news_count'] > 0:
                company_exposure[ticker]['average_impact'] = (
                    company_exposure[ticker]['total_impact'] / 
                    company_exposure[ticker]['news_count']
                )
        
        return company_exposure
    
    def parse_stock_data_moex(self, tickers):
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏ (MOEX API)"""
        price_data = {}
        
        try:
            # MOEX ISS API
            for ticker in tickers:
                try:
                    url = f"https://iss.moex.com/iss/engines/stock/markets/shares/boards/TQBR/securities/{ticker}.json"
                    response = requests.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        data = response.json()
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ä—ã–Ω–æ—á–Ω–æ–π —Ü–µ–Ω–µ
                        marketdata = data.get('marketdata', {}).get('data', [])
                        securities = data.get('securities', {}).get('data', [])
                        
                        if marketdata and securities:
                            # –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
                            last_price = marketdata[0][12] if marketdata[0][12] else marketdata[0][4]
                            
                            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ
                            change = marketdata[0][13] if marketdata[0][13] else 0
                            change_percent = marketdata[0][14] if marketdata[0][14] else 0
                            
                            # –û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤
                            volume = marketdata[0][9] if marketdata[0][9] else 0
                            
                            price_data[ticker] = {
                                'price': float(last_price) if last_price else 0,
                                'change': float(change) if change else 0,
                                'change_percent': float(change_percent) if change_percent else 0,
                                'volume': int(volume) if volume else 0,
                                'source': 'MOEX'
                            }
                    
                    time.sleep(0.5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {ticker}: {str(e)[:50]}")
                    continue
                    
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ MOEX: {e}")
        
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ —Å MOEX, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ
        if not price_data:
            price_data = self.generate_mock_price_data(tickers)
        
        return price_data
    
    def parse_stock_data_investing(self, tickers):
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å Investing.com (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫)"""
        price_data = {}
        
        try:
            # –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è investing.com
            ticker_map = {
                'SBER': 'sberbank',
                'GAZP': 'gazprom',
                'LKOH': 'lukoil',
                'GMKN': 'mmk-norilsk-nickel',
                'ROSN': 'rosneft'
            }
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            for ticker in tickers[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
                if ticker in ticker_map:
                    try:
                        url = f"https://ru.investing.com/equities/{ticker_map[ticker]}"
                        response = requests.get(url, headers=headers, timeout=10)
                        
                        if response.status_code == 200:
                            soup = BeautifulSoup(response.content, 'html.parser')
                            
                            # –ü–æ–∏—Å–∫ —Ü–µ–Ω—ã (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å—Å—è)
                            price_elem = soup.find('span', {'data-test': 'instrument-price-last'})
                            change_elem = soup.find('span', {'data-test': 'instrument-price-change'})
                            
                            if price_elem:
                                price_text = price_elem.text.replace(',', '.')
                                price = float(re.search(r'[\d.]+', price_text).group())
                                
                                change = 0
                                if change_elem:
                                    change_text = change_elem.text.replace(',', '.')
                                    change_match = re.search(r'([+-]?[\d.]+)', change_text)
                                    if change_match:
                                        change = float(change_match.group(1))
                                
                                price_data[ticker] = {
                                    'price': price,
                                    'change': change,
                                    'change_percent': round((change / price * 100), 2) if price > 0 else 0,
                                    'volume': 0,
                                    'source': 'Investing.com'
                                }
                        
                        time.sleep(1)
                        
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {ticker}: {str(e)[:50]}")
                        continue
                        
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Investing.com: {e}")
        
        return price_data
    
    def generate_mock_price_data(self, tickers):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–∞—Ö"""
        price_data = {}
        
        base_prices = {
            'SBER': 280.50,
            'GAZP': 165.30,
            'LKOH': 7100.80,
            'GMKN': 16750.40,
            'ROSN': 580.90,
            'MGNT': 5200.75,
            'YNDX': 2850.60,
            'VTBR': 0.0265,
            'ALRS': 79.40,
            'PLZL': 11700.25,
            'NVTK': 1645.80,
            'TATN': 630.45,
            'MOEX': 145.60,
            'AFKS': 17.85,
            'PHOR': 6800.90,
            'RUAL': 41.30,
            'MTSS': 270.45,
            'AFLT': 47.80,
            'IRAO': 2.45,
            'RTKM': 73.20
        }
        
        for ticker in tickers:
            base_price = base_prices.get(ticker, 100.0)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –æ—Ç -10% –¥–æ +10%
            import random
            change_percent = random.uniform(-10, 10)
            change = base_price * change_percent / 100
            price = base_price + change
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä–µ–º
            volume = random.randint(1000000, 10000000)
            
            price_data[ticker] = {
                'price': round(price, 2),
                'change': round(change, 2),
                'change_percent': round(change_percent, 2),
                'volume': volume,
                'source': '–ú–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ'
            }
        
        return price_data
    
    def get_stock_price_changes(self, tickers, days=5):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ü–µ–Ω –∞–∫—Ü–∏–π"""
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∞–∫—Ü–∏—è–º...")
        
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        price_data = self.parse_stock_data_moex(tickers)
        
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
        if len(price_data) < 5:
            investing_data = self.parse_stock_data_investing(tickers)
            price_data.update(investing_data)
        
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–∫–æ–≤—ã–µ
        if len(price_data) < len(tickers) / 2:
            mock_data = self.generate_mock_price_data(tickers)
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Ç–∏–∫–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç
            for ticker in tickers:
                if ticker not in price_data:
                    price_data[ticker] = mock_data.get(ticker, {
                        'price': 0,
                        'change': 0,
                        'change_percent': 0,
                        'volume': 0,
                        'source': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'
                    })
        
        return price_data
    
    def calculate_risk_levels(self, company_exposure):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π —Ä–∏—Å–∫–∞ –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–π"""
        risk_levels = {}
        
        for ticker, data in company_exposure.items():
            avg_impact = data['average_impact']
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞
            if avg_impact >= 70:
                risk_level = '–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô'
                color = 'üî¥'
                risk_value = 5
            elif avg_impact >= 50:
                risk_level = '–í–´–°–û–ö–ò–ô'
                color = 'üü†'
                risk_value = 4
            elif avg_impact >= 30:
                risk_level = '–°–†–ï–î–ù–ò–ô'
                color = 'üü°'
                risk_value = 3
            elif avg_impact >= 10:
                risk_level = '–ù–ò–ó–ö–ò–ô'
                color = 'üü¢'
                risk_value = 2
            else:
                risk_level = '–ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô'
                color = '‚ö™'
                risk_value = 1
            
            risk_levels[ticker] = {
                '–ù–∞–∑–≤–∞–Ω–∏–µ': data['name'],
                '–û—Ç—Ä–∞—Å–ª—å': data['industry'],
                '–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞': f"{color} {risk_level}",
                '–†–∏—Å–∫ (—á–∏—Å–ª–æ)': risk_value,
                '–°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ': round(avg_impact, 1),
                '–ú–∞–∫—Å –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ': round(data['max_impact'], 1),
                '–ö–æ–ª-–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π': int(data['news_count']),
                '–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∏—Å–∫–∏': ', '.join(data['risk_categories'][:3]),
                '–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ —Ä–µ–≥–∏–æ–Ω—ã': ', '.join(data['affected_regions'][:3])
            }
        
        return risk_levels
    
    def generate_report(self, analyzed_news, company_risk_levels, price_changes):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        report = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_news_analyzed': len(analyzed_news),
            'top_risks': self.get_top_risks(analyzed_news),
            'company_analysis': {},
            'sector_analysis': {},
            'recommendations': []
        }
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º
        for ticker, risk_data in company_risk_levels.items():
            company_info = {
                **risk_data,
                'price_data': price_changes.get(ticker, {})
            }
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            recommendation = self.generate_recommendation(ticker, risk_data, price_changes.get(ticker, {}))
            if recommendation:
                company_info['recommendation'] = recommendation
            
            report['company_analysis'][ticker] = company_info
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º
        report['sector_analysis'] = self.analyze_sectors(company_risk_levels)
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report['recommendations'] = self.generate_general_recommendations(company_risk_levels)
        
        return report
    
    def analyze_sectors(self, company_risk_levels):
        """–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        sector_risks = {}
        
        for ticker, data in company_risk_levels.items():
            sector = data['–û—Ç—Ä–∞—Å–ª—å']
            if sector not in sector_risks:
                sector_risks[sector] = {
                    'companies': [],
                    'avg_impact': 0,
                    'max_impact': 0,
                    'total_news': 0
                }
            
            sector_risks[sector]['companies'].append(ticker)
            sector_risks[sector]['avg_impact'] += data['–°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ']
            sector_risks[sector]['max_impact'] = max(sector_risks[sector]['max_impact'], 
                                                   data['–ú–∞–∫—Å –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ'])
            sector_risks[sector]['total_news'] += data['–ö–æ–ª-–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π']
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        for sector in sector_risks:
            count = len(sector_risks[sector]['companies'])
            if count > 0:
                sector_risks[sector]['avg_impact'] = round(sector_risks[sector]['avg_impact'] / count, 1)
        
        return sector_risks
    
    def get_top_risks(self, analyzed_news):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–ª–∞–≤–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤"""
        risk_counter = {}
        
        for news in analyzed_news:
            for category in news['categories']:
                risk_counter[category] = risk_counter.get(category, 0) + 1
        
        return sorted(risk_counter.items(), key=lambda x: x[1], reverse=True)[:5]
    
    def generate_recommendation(self, ticker, risk_data, price_data):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∞–∫—Ü–∏–∏"""
        avg_impact = risk_data['–°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ']
        risk_level = risk_data['–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞']
        price_change = price_data.get('change_percent', 0)
        
        recommendations = []
        
        if 'üî¥' in risk_level:
            if price_change < -5:
                recommendations.append("–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –†–ò–°–ö - –ø—Ä–æ–¥–∞–≤–∞—Ç—å –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ")
            else:
                recommendations.append("–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –†–ò–°–ö - –∏–∑–±–µ–≥–∞—Ç—å –ø–æ–∫—É–ø–∫–∏")
        elif 'üü†' in risk_level:
            if price_change < -3:
                recommendations.append("–í–´–°–û–ö–ò–ô –†–ò–°–ö - —Å–æ–∫—Ä–∞—â–∞—Ç—å –ø–æ–∑–∏—Ü–∏–∏")
            else:
                recommendations.append("–í–´–°–û–ö–ò–ô –†–ò–°–ö - –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å —ç–∫—Å–ø–æ–∑–∏—Ü–∏—é")
        elif 'üü°' in risk_level:
            recommendations.append("–°–†–ï–î–ù–ò–ô –†–ò–°–ö - –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Å–∏—Ç—É–∞—Ü–∏—é")
        elif 'üü¢' in risk_level:
            if price_change < -8:
                recommendations.append("–ù–ò–ó–ö–ò–ô –†–ò–°–ö - –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–∫—É–ø–∫–∏")
            else:
                recommendations.append("–ù–ò–ó–ö–ò–ô –†–ò–°–ö - —É–¥–µ—Ä–∂–∏–≤–∞—Ç—å –ø–æ–∑–∏—Ü–∏–∏")
        elif '‚ö™' in risk_level:
            recommendations.append("–ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô –†–ò–°–ö - —Å—Ç–∞–±–∏–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è")
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã
        if price_change < -10:
            recommendations.append("–°–∏–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ —Ü–µ–Ω—ã - –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å")
        elif price_change > 10:
            recommendations.append("–°–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç - —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–±—ã–ª—å")
        
        return "; ".join(recommendations) if recommendations else "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
    
    def generate_general_recommendations(self, company_risk_levels):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑ —Å–µ–∫—Ç–æ—Ä–æ–≤
        sector_analysis = {}
        for ticker, data in company_risk_levels.items():
            sector = data['–û—Ç—Ä–∞—Å–ª—å']
            if sector not in sector_analysis:
                sector_analysis[sector] = []
            sector_analysis[sector].append(data['–°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ'])
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º
        for sector, impacts in sector_analysis.items():
            avg_impact = np.mean(impacts)
            if avg_impact > 60:
                recommendations.append(f"‚ö†Ô∏è –ò–∑–±–µ–≥–∞—Ç—å –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤ —Å–µ–∫—Ç–æ—Ä {sector} (—Å—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫: {avg_impact:.1f})")
            elif avg_impact > 40:
                recommendations.append(f"‚ö° –û—Å—Ç–æ—Ä–æ–∂–Ω–æ –≤ —Å–µ–∫—Ç–æ—Ä–µ {sector} (—Å—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫: {avg_impact:.1f})")
            elif avg_impact < 20:
                recommendations.append(f"‚úÖ –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ —Å–µ–∫—Ç–æ—Ä–µ {sector} (–Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫: {avg_impact:.1f})")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–∏—Å–∫–æ–≤–∞–Ω–Ω—ã–º –∫–æ–º–ø–∞–Ω–∏—è–º
        high_risk_companies = [ticker for ticker, data in company_risk_levels.items() 
                              if data['–†–∏—Å–∫ (—á–∏—Å–ª–æ)'] >= 4]
        
        if high_risk_companies:
            recommendations.append(f"üö® –ù–∞–∏–±–æ–ª—å—à–µ–º—É —Ä–∏—Å–∫—É –ø–æ–¥–≤–µ—Ä–∂–µ–Ω—ã: {', '.join(high_risk_companies[:3])}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –∫–æ–º–ø–∞–Ω–∏—è–º
        safe_companies = [ticker for ticker, data in company_risk_levels.items() 
                         if data['–†–∏—Å–∫ (—á–∏—Å–ª–æ)'] <= 2]
        
        if safe_companies:
            recommendations.append(f"üõ°Ô∏è –ù–∞–∏–±–æ–ª–µ–µ –∑–∞—â–∏—â–µ–Ω—ã: {', '.join(safe_companies[:3])}")
        
        return recommendations[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
    
    def run_analysis(self, use_real_news=True):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        print("=" * 60)
        print("–ì–ï–û–ü–û–õ–ò–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –î–õ–Ø –ê–ö–¶–ò–ô –ú–û–°–ë–ò–†–ñ–ò")
        print("=" * 60)
        
        # 1. –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π
        print("\n1. –°–±–æ—Ä –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
        if use_real_news:
            news_items = self.fetch_real_news(days_back=7)
        else:
            news_items = self.generate_synthetic_news(days_back=7)
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news_items)}")
        
        # 2. –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
        print("2. –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è...")
        analyzed_news = self.analyze_news_sentiment(news_items)
        
        # 3. –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–≤–µ—Ä–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–π
        print("3. –û—Ü–µ–Ω–∫–∞ –ø–æ–¥–≤–µ—Ä–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–π —Ä–∏—Å–∫–∞–º...")
        company_exposure = self.analyze_company_exposure(analyzed_news)
        
        # 4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π —Ä–∏—Å–∫–∞
        print("4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π —Ä–∏—Å–∫–∞...")
        company_risk_levels = self.calculate_risk_levels(company_exposure)
        
        # 5. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ü–µ–Ω–∞–º
        print("5. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∞–∫—Ü–∏—è–º...")
        tickers = list(self.moex_companies.keys())
        price_changes = self.get_stock_price_changes(tickers, days=5)
        
        print(f"   –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(price_changes)} –∞–∫—Ü–∏–π")
        
        # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        print("6. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞...")
        report = self.generate_report(analyzed_news, company_risk_levels, price_changes)
        
        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        return report, analyzed_news, company_risk_levels, price_changes

# –¢–µ—Å—Ç–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞
def test_geopolitical_analyzer():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    
    print("üöÄ –ó–ê–ü–£–°–ö –¢–ï–°–¢–û–í–û–ì–û –ê–ù–ê–õ–ò–ó–ê")
    print("-" * 40)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = GeopoliticalNewsAnalyzer()
    
    # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞
    report, analyzed_news, risk_levels, price_changes = analyzer.run_analysis(
        use_real_news=False  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∞
    )
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {report['total_news_analyzed']}")
    print(f"   –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {report['timestamp']}")
    
    print(f"\nüìà –¢–û–ü-5 –ì–ï–û–ü–û–õ–ò–¢–ò–ß–ï–°–ö–ò–• –†–ò–°–ö–û–í:")
    for i, (risk, count) in enumerate(report['top_risks'], 1):
        print(f"   {i}. {risk}: {count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π")
    
    print(f"\nüè¢ –ê–ù–ê–õ–ò–ó –ö–û–ú–ü–ê–ù–ò–ô (–¢–û–ü-10 –ü–û –£–†–û–í–ù–Æ –†–ò–°–ö–ê):")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ —É—Ä–æ–≤–Ω—é —Ä–∏—Å–∫–∞
    sorted_companies = sorted(
        report['company_analysis'].items(),
        key=lambda x: x[1]['–†–∏—Å–∫ (—á–∏—Å–ª–æ)'],
        reverse=True
    )[:10]
    
    print(f"\n{'–¢–∏–∫–µ—Ä':<8} {'–ù–∞–∑–≤–∞–Ω–∏–µ':<20} {'–†–∏—Å–∫':<15} {'–í–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ':<12} {'–ò–∑–º–µ–Ω–µ–Ω–∏–µ':<10} {'–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è':<30}")
    print("-" * 95)
    
    for ticker, data in sorted_companies:
        price_data = data.get('price_data', {})
        change = price_data.get('change_percent', 0)
        change_str = f"{change:+.1f}%" if change else "N/A"
        
        # –°–æ–∫—Ä–∞—â–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        rec = data.get('recommendation', '')
        if len(rec) > 28:
            rec = rec[:25] + "..."
        
        print(f"{ticker:<8} {data['–ù–∞–∑–≤–∞–Ω–∏–µ'][:18]:<20} {data['–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞']:<15} "
              f"{data['–°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ']:<12.1f} {change_str:<10} {rec:<30}")
    
    print(f"\nüè≠ –ê–ù–ê–õ–ò–ó –°–ï–ö–¢–û–†–û–í:")
    for sector, stats in report['sector_analysis'].items():
        print(f"   {sector}: {stats['avg_impact']:.1f} (–∫–æ–º–ø–∞–Ω–∏–π: {len(stats['companies'])}, "
              f"–Ω–æ–≤–æ—Å—Ç–µ–π: {stats['total_news']})")
    
    print(f"\nüí° –û–°–ù–û–í–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    for i, rec in enumerate(report['recommendations'][:5], 1):
        print(f"   {i}. {rec}")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Ä–∏—Å–∫–æ–º
    if sorted_companies:
        top_risk_ticker = sorted_companies[0][0]
        top_risk_data = sorted_companies[0][1]
        
        print(f"\nüîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –î–õ–Ø {top_risk_ticker} ({top_risk_data['–ù–∞–∑–≤–∞–Ω–∏–µ']}):")
        print(f"   –û—Ç—Ä–∞—Å–ª—å: {top_risk_data['–û—Ç—Ä–∞—Å–ª—å']}")
        print(f"   –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {top_risk_data['–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞']}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ: {top_risk_data['–°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ']}")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ: {top_risk_data['–ú–∞–∫—Å –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ']}")
        print(f"   –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∏—Å–∫–∏: {top_risk_data['–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∏—Å–∫–∏']}")
        print(f"   –ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ —Ä–µ–≥–∏–æ–Ω—ã: {top_risk_data['–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ —Ä–µ–≥–∏–æ–Ω—ã']}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {top_risk_data['–ö–æ–ª-–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π']}")
        
        if top_risk_data.get('price_data'):
            price_info = top_risk_data['price_data']
            print(f"   –¶–µ–Ω–∞: {price_info.get('price', 'N/A')} ({price_info.get('change_percent', 0):+.2f}%)")
            print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö: {price_info.get('source', 'N/A')}")
        
        print(f"   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {top_risk_data.get('recommendation', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}")
        
        # –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
        company_exposure = analyzer.analyze_company_exposure(analyzed_news)
        related_news = company_exposure[top_risk_ticker]['related_news']
        
        if related_news:
            print(f"\n   üì∞ –°–í–Ø–ó–ê–ù–ù–´–ï –ù–û–í–û–°–¢–ò:")
            for i, news in enumerate(related_news[:3], 1):
                print(f"   {i}. {news['title']}")
                print(f"      –í–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ: {news['impact']:.1f}, "
                      f"–î–∞—Ç–∞: {news['date']}, "
                      f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(news.get('categories', []))}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–∞–π–ª
    try:
        with open('geopolitical_analysis_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: geopolitical_analysis_report.json")
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—É –≤ CSV
        df_data = []
        for ticker, data in report['company_analysis'].items():
            row = {
                '–¢–∏–∫–µ—Ä': ticker,
                '–ù–∞–∑–≤–∞–Ω–∏–µ': data['–ù–∞–∑–≤–∞–Ω–∏–µ'],
                '–û—Ç—Ä–∞—Å–ª—å': data['–û—Ç—Ä–∞—Å–ª—å'],
                '–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞': data['–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞'],
                '–†–∏—Å–∫ (—á–∏—Å–ª–æ)': data['–†–∏—Å–∫ (—á–∏—Å–ª–æ)'],
                '–°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ': data['–°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ'],
                '–ö–æ–ª-–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π': data['–ö–æ–ª-–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π'],
                '–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∏—Å–∫–∏': data['–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∏—Å–∫–∏'],
                '–¶–µ–Ω–∞': data.get('price_data', {}).get('price', 'N/A'),
                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ %': data.get('price_data', {}).get('change_percent', 'N/A'),
                '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è': data.get('recommendation', '')
            }
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        df.to_csv('geopolitical_analysis_table.csv', index=False, encoding='utf-8-sig')
        print(f"üìä –¢–∞–±–ª–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: geopolitical_analysis_table.csv")
        
    except Exception as e:
        print(f"\n‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
    
    return report

# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
def demonstrate_analyzer():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    
    analyzer = GeopoliticalNewsAnalyzer()
    
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –†–ê–ë–û–¢–´ –ì–ï–û–ü–û–õ–ò–¢–ò–ß–ï–°–ö–û–ì–û –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê")
    print("=" * 60)
    
    # 1. –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π
    print("\nüìã –ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú–´–ï –ö–û–ú–ü–ê–ù–ò–ò:")
    for ticker, info in analyzer.moex_companies.items():
        print(f"  {ticker}: {info['name']} ({info['industry']})")
    
    # 2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π
    print("\nüì∞ –¢–ï–°–¢ –ü–ê–†–°–ò–ù–ì–ê –ù–û–í–û–°–¢–ï–ô:")
    news_items = analyzer.generate_synthetic_news(days_back=3)
    print(f"  –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news_items)}")
    
    # 3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
    print("\nüß† –¢–ï–°–¢ –ê–ù–ê–õ–ò–ó–ê –ù–û–í–û–°–¢–ï–ô:")
    analyzed = analyzer.analyze_news_sentiment(news_items[:3])
    for i, news in enumerate(analyzed[:2], 1):
        print(f"  –ù–æ–≤–æ—Å—Ç—å {i}: {news['title'][:50]}...")
        print(f"    –í–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ: {news['impact_score']:.1f}, "
              f"–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {news['sentiment_compound']:.2f}")
        print(f"    –ö–æ–º–ø–∞–Ω–∏–∏: {', '.join(news.get('affected_companies', []))}")
    
    # 4. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –∫–æ–º–ø–∞–Ω–∏–∏
    print("\nüè¢ –¢–ï–°–¢ –ê–ù–ê–õ–ò–ó–ê –ö–û–ú–ü–ê–ù–ò–ò:")
    company_exposure = analyzer.analyze_company_exposure(analyzed)
    test_ticker = 'SBER'
    if test_ticker in company_exposure:
        data = company_exposure[test_ticker]
        print(f"  {test_ticker}: {data['name']}")
        print(f"    –°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ: {data['average_impact']:.1f}")
        print(f"    –ù–æ–≤–æ—Å—Ç–µ–π: {data['news_count']}")
        print(f"    –†–∏—Å–∫–∏: {', '.join(data['risk_categories'])}")
    
    print("\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ test_geopolitical_analyzer()")

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
if __name__ == "__main__":
    print("–ù–∞—á–∞–ª–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞...\n")
    
    try:
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
        demonstrate_analyzer()
        
        print("\n" + "="*60)
        
        # –ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç
        report = test_geopolitical_analyzer()
        print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        print("\nüìã –ü–†–û–í–ï–†–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
        print(f"1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {len(report['company_analysis'])}")
        print(f"2. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–∫—Ç–æ—Ä–æ–≤: {len(report['sector_analysis'])}")
        
        impacts = [d['–°—Ä–µ–¥–Ω–µ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ'] for d in report['company_analysis'].values()]
        print(f"3. –î–∏–∞–ø–∞–∑–æ–Ω –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è: {min(impacts):.1f} - {max(impacts):.1f}")
        
        risk_distribution = {}
        for data in report['company_analysis'].values():
            risk = data['–†–∏—Å–∫ (—á–∏—Å–ª–æ)']
            risk_distribution[risk] = risk_distribution.get(risk, 0) + 1
        
        print(f"4. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤:")
        for risk_level in sorted(risk_distribution.keys()):
            count = risk_distribution[risk_level]
            print(f"   –£—Ä–æ–≤–µ–Ω—å {risk_level}: {count} –∫–æ–º–ø–∞–Ω–∏–π")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()